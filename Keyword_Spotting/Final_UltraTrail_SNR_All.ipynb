{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a58be89",
   "metadata": {},
   "source": [
    "<font size=\"5\">Third UltraTrail Run</font>\n",
    "\n",
    "In this notebook the performance of an Akida model is evaluated on a data set according to the UltraTrail\n",
    "experimental setup. The noise in the test set is fixed to a certain SNR. In this case the whole Google Speech Command data set was used, including recordings shorter than one second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d98b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and dependencies\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "import akida\n",
    "from akida import FullyConnected\n",
    "from akida import evaluate_sparsity\n",
    "import cnn2snn\n",
    "from cnn2snn import check_model_compatibility\n",
    "from cnn2snn import quantize\n",
    "from cnn2snn import quantize_layer\n",
    "from cnn2snn import convert\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import (Input, Reshape, Activation, Flatten, Rescaling, Add, Dropout)\n",
    "\n",
    "import akida_models\n",
    "from akida_models import layer_blocks\n",
    "from akida_models.layer_blocks import conv_block, separable_conv_block, dense_block\n",
    "\n",
    "\n",
    "from math import ceil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004de406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, set seed for experiment reproducibility\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b195b02b",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 1. Load the Data Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7801fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory\n",
    "\n",
    "data_dir = pathlib.Path('data/Modded_Google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c09dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known and unknown commands: ['off' 'up' 'down' 'on' 'stop' 'yes' 'right' 'unknown' 'left' 'go' 'no'\n",
      " 'silence']\n"
     ]
    }
   ],
   "source": [
    "# Check commands\n",
    "targets = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "targets = targets[targets != 'README.md']\n",
    "\n",
    "print('Known and unknown commands:', targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf58b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading preprocessed Data\n",
    "\n",
    "feature_sets_path = '/home/sebastian/Schreibtisch/Masterarbeit/Audio/'\n",
    "feature_sets_filename = 'all_final_SNR_audio.npz'\n",
    "\n",
    "CNN_model_filename = 'final_CNN_ultratrail_all_SNR_model.h5'\n",
    "Quantized_model_filename = 'final_quantized_ultratrail_all_SNR_model.h5'\n",
    "Akida_model_filename = 'final_akida_ultratrail_all_SNR_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7da8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Sets:  ['x_train', 'y_train', 'x_val', 'y_val', 'x_test1', 'y_test1', 'x_test10', 'y_test10', 'x_test20', 'y_test20', 'x_test100', 'y_test100', 'x_test1000', 'y_test1000']\n"
     ]
    }
   ],
   "source": [
    "# Load feature sets\n",
    "\n",
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "\n",
    "print('Feature Sets: ', feature_sets.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d22817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets\n",
    "\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "\n",
    "x_test1 = feature_sets['x_test1']\n",
    "y_test1 = feature_sets['y_test1']\n",
    "x_test10 = feature_sets['x_test10']\n",
    "y_test10 = feature_sets['y_test10']\n",
    "x_test20 = feature_sets['x_test20']\n",
    "y_test20 = feature_sets['y_test20']\n",
    "x_test100 = feature_sets['x_test100']\n",
    "y_test100 = feature_sets['y_test100']\n",
    "x_test1000 = feature_sets['x_test1000']\n",
    "y_test1000 = feature_sets['y_test1000']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3614c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (38546, 40, 101)\n",
      "x_val shape:  (4818, 40, 101)\n",
      "x_test shape:  (4818, 40, 101)\n"
     ]
    }
   ],
   "source": [
    "# Look at tensor dimensions\n",
    "\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('x_val shape: ', x_val.shape)\n",
    "print('x_test shape: ', x_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834f237",
   "metadata": {},
   "source": [
    "Check the dimensions of the data set. \n",
    "Is the unknown and silence category roughly 10% (Category 7 and 11)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7391d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 3044,\n",
       " 1.0: 2990,\n",
       " 2.0: 3128,\n",
       " 3.0: 3112,\n",
       " 4.0: 3114,\n",
       " 5.0: 3221,\n",
       " 6.0: 3034,\n",
       " 7.0: 3864,\n",
       " 8.0: 3016,\n",
       " 9.0: 3091,\n",
       " 10.0: 3121,\n",
       " 11.0: 3811}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e59bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 342,\n",
       " 1.0: 373,\n",
       " 2.0: 374,\n",
       " 3.0: 375,\n",
       " 4.0: 359,\n",
       " 5.0: 424,\n",
       " 6.0: 387,\n",
       " 7.0: 466,\n",
       " 8.0: 389,\n",
       " 9.0: 402,\n",
       " 10.0: 412,\n",
       " 11.0: 515}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4a5de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 359,\n",
       " 1.0: 360,\n",
       " 2.0: 415,\n",
       " 3.0: 358,\n",
       " 4.0: 399,\n",
       " 5.0: 399,\n",
       " 6.0: 357,\n",
       " 7.0: 488,\n",
       " 8.0: 396,\n",
       " 9.0: 387,\n",
       " 10.0: 408,\n",
       " 11.0: 492}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test1, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe971e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels:  12\n"
     ]
    }
   ],
   "source": [
    "# Define the number of labels\n",
    "\n",
    "num_labels = len(unique)\n",
    "print('number of labels: ', num_labels)\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc71662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add dimension to all data: Order Train, Val, Test\n",
      "(38546, 40, 101, 1)\n",
      "(4818, 40, 101, 1)\n",
      "(4818, 40, 101, 1)\n",
      "(4818, 40, 101, 1)\n",
      "(4818, 40, 101, 1)\n",
      "(4818, 40, 101, 1)\n",
      "(4818, 40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN for conversion expects (batch, height, width, channels)\n",
    "# The channels can either be 1 for gray-scaled images or 3 for RGB-images\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "x_val = x_val.reshape(x_val.shape[0], \n",
    "                      x_val.shape[1], \n",
    "                      x_val.shape[2], \n",
    "                      1)\n",
    "\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0], \n",
    "                        x_test1.shape[1], \n",
    "                        x_test1.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_test10 = x_test10.reshape(x_test10.shape[0], \n",
    "                        x_test10.shape[1], \n",
    "                        x_test10.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_test20 = x_test20.reshape(x_test20.shape[0], \n",
    "                        x_test20.shape[1], \n",
    "                        x_test20.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_test100 = x_test100.reshape(x_test100.shape[0], \n",
    "                        x_test100.shape[1], \n",
    "                        x_test100.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_test1000 = x_test1000.reshape(x_test1000.shape[0], \n",
    "                        x_test1000.shape[1], \n",
    "                        x_test1000.shape[2], \n",
    "                        1)\n",
    "\n",
    "\n",
    "print('Add dimension to all data: Order Train, Val, Test')\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test1.shape)\n",
    "print(x_test10.shape)\n",
    "print(x_test20.shape)\n",
    "print(x_test100.shape)\n",
    "print(x_test1000.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ffeac8",
   "metadata": {},
   "source": [
    "<font size=\"5\">2. Train and Save the CNN-Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0476781a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of 1 Tensor/MFCC:  (40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape for the CNN, namely the dimension of 1 MFCC\n",
    "\n",
    "input_shape = x_test1.shape[1:]\n",
    "print('Input shape of 1 Tensor/MFCC: ', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e285a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 10:56:43.837238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:43.915142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:43.915410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:43.916175: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 10:56:43.917266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:43.917518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:43.917732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:44.250642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:44.250792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:44.250899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 10:56:44.250995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9687 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 20, 51, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_0_BN (BatchNormalizatio (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ReLU)           (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (SeparableConv2D (None, 20, 51, 32)        1312      \n",
      "_________________________________________________________________\n",
      "separable_1_BN (BatchNormali (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "separable_1_relu (ReLU)      (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (SeparableConv2D (None, 10, 26, 64)        2336      \n",
      "_________________________________________________________________\n",
      "separable_2_BN (BatchNormali (None, 10, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_2_relu (ReLU)      (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (SeparableConv2D (None, 10, 26, 128)       8768      \n",
      "_________________________________________________________________\n",
      "separable_3_BN (BatchNormali (None, 10, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_3_relu (ReLU)      (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (SeparableConv2D (None, 5, 13, 128)        17536     \n",
      "_________________________________________________________________\n",
      "separable_4_BN (BatchNormali (None, 5, 13, 128)        512       \n",
      "_________________________________________________________________\n",
      "separable_4_relu (ReLU)      (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (SeparableConv2D (None, 5, 13, 256)        33920     \n",
      "_________________________________________________________________\n",
      "separable_5_BN (BatchNormali (None, 5, 13, 256)        1024      \n",
      "_________________________________________________________________\n",
      "separable_5_relu (ReLU)      (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (SeparableConv2D (None, 3, 7, 256)         67840     \n",
      "_________________________________________________________________\n",
      "separable_6_BN (BatchNormali (None, 3, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "separable_6_relu (ReLU)      (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (SeparableConv2D (None, 2, 4, 512)         133376    \n",
      "_________________________________________________________________\n",
      "separable_7_BN (BatchNormali (None, 2, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "separable_7_relu (ReLU)      (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (SeparableConv2D (None, 2, 4, 1024)        528896    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_BN (BatchNormali (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "separable_8_relu (ReLU)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 816,348\n",
      "Trainable params: 811,460\n",
      "Non-trainable params: 4,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN created with the functional API and from akida_models layer_blocks\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Rescaling(1. / 255)(inputs)\n",
    "x = conv_block(x,\n",
    "               filters=32,\n",
    "               kernel_size=(3, 3),\n",
    "               padding='same',\n",
    "               strides=(2, 2),\n",
    "               use_bias=False,\n",
    "               name='conv_0',\n",
    "               add_batchnorm=True)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=32,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_1',\n",
    "                         add_batchnorm=True)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=64,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_2',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=128,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_3',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=128,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_4',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=256,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_5',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=256,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_6',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=512,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_7',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=1024,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_8',\n",
    "                         pooling='global_avg',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "shape = (1, 1, int(1024))\n",
    "x = Reshape(shape, name='reshape_1')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = layers.Dense(units = 12, activation='linear', use_bias = True)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "outputs = layers.Activation('softmax')(x)\n",
    "\n",
    "CNN_model = keras.Model(inputs=inputs, outputs=outputs, name='CNN_model')\n",
    "\n",
    "CNN_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a1e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compatible for Akida conversion: True\n"
     ]
    }
   ],
   "source": [
    "# Check if model is compatible\n",
    "\n",
    "print(\"Model compatible for Akida conversion:\", check_model_compatibility(CNN_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208c5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN model\n",
    "\n",
    "CNN_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25eb38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 10:57:06.226570: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 10:57:09.777096: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8301\n",
      "2022-04-24 10:57:12.245509: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-24 10:57:12.740978: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 21s 11ms/step - loss: 2.1050 - accuracy: 0.2774 - val_loss: 1.3716 - val_accuracy: 0.5509\n",
      "Epoch 2/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 1.2011 - accuracy: 0.6270 - val_loss: 0.8504 - val_accuracy: 0.7267\n",
      "Epoch 3/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.9129 - accuracy: 0.7176 - val_loss: 0.6686 - val_accuracy: 0.7850\n",
      "Epoch 4/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.7940 - accuracy: 0.7577 - val_loss: 0.6390 - val_accuracy: 0.8101\n",
      "Epoch 5/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.7134 - accuracy: 0.7822 - val_loss: 0.6091 - val_accuracy: 0.8115\n",
      "Epoch 6/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.6537 - accuracy: 0.7989 - val_loss: 0.5731 - val_accuracy: 0.8223\n",
      "Epoch 7/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.6135 - accuracy: 0.8111 - val_loss: 0.4525 - val_accuracy: 0.8599\n",
      "Epoch 8/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.5835 - accuracy: 0.8214 - val_loss: 0.4496 - val_accuracy: 0.8605\n",
      "Epoch 9/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.5467 - accuracy: 0.8333 - val_loss: 0.4202 - val_accuracy: 0.8692\n",
      "Epoch 10/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.5217 - accuracy: 0.8419 - val_loss: 0.4358 - val_accuracy: 0.8659\n",
      "Epoch 11/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.5025 - accuracy: 0.8452 - val_loss: 0.3948 - val_accuracy: 0.8784\n",
      "Epoch 12/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.4858 - accuracy: 0.8501 - val_loss: 0.3669 - val_accuracy: 0.8904\n",
      "Epoch 13/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.4621 - accuracy: 0.8564 - val_loss: 0.3178 - val_accuracy: 0.9020\n",
      "Epoch 14/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.4427 - accuracy: 0.8643 - val_loss: 0.3445 - val_accuracy: 0.8985\n",
      "Epoch 15/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.4344 - accuracy: 0.8656 - val_loss: 0.3617 - val_accuracy: 0.8885\n",
      "Epoch 16/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.4169 - accuracy: 0.8714 - val_loss: 0.3447 - val_accuracy: 0.8971\n",
      "Epoch 17/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.4137 - accuracy: 0.8725 - val_loss: 0.3470 - val_accuracy: 0.8946\n",
      "Epoch 18/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3943 - accuracy: 0.8764 - val_loss: 0.3388 - val_accuracy: 0.8929\n",
      "Epoch 19/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3879 - accuracy: 0.8792 - val_loss: 0.3259 - val_accuracy: 0.8979\n",
      "Epoch 20/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.3786 - accuracy: 0.8808 - val_loss: 0.3382 - val_accuracy: 0.8919\n",
      "Epoch 21/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.3720 - accuracy: 0.8822 - val_loss: 0.2848 - val_accuracy: 0.9108\n",
      "Epoch 22/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3625 - accuracy: 0.8860 - val_loss: 0.3069 - val_accuracy: 0.9020\n",
      "Epoch 23/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3543 - accuracy: 0.8897 - val_loss: 0.2905 - val_accuracy: 0.9093\n",
      "Epoch 24/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3549 - accuracy: 0.8888 - val_loss: 0.2884 - val_accuracy: 0.9062\n",
      "Epoch 25/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3441 - accuracy: 0.8922 - val_loss: 0.2645 - val_accuracy: 0.9157\n",
      "Epoch 26/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.3385 - accuracy: 0.8927 - val_loss: 0.2809 - val_accuracy: 0.9153\n",
      "Epoch 27/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.3357 - accuracy: 0.8939 - val_loss: 0.2778 - val_accuracy: 0.9114\n",
      "Epoch 28/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.3273 - accuracy: 0.8957 - val_loss: 0.2751 - val_accuracy: 0.9170\n",
      "Epoch 29/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.3280 - accuracy: 0.8959 - val_loss: 0.2813 - val_accuracy: 0.9118\n",
      "Epoch 30/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3211 - accuracy: 0.8975 - val_loss: 0.2736 - val_accuracy: 0.9141\n",
      "Epoch 31/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.3162 - accuracy: 0.9004 - val_loss: 0.2946 - val_accuracy: 0.9081\n",
      "Epoch 32/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3098 - accuracy: 0.9010 - val_loss: 0.2753 - val_accuracy: 0.9159\n",
      "Epoch 33/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.3033 - accuracy: 0.9027 - val_loss: 0.2581 - val_accuracy: 0.9205\n",
      "Epoch 34/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.3056 - accuracy: 0.9025 - val_loss: 0.2803 - val_accuracy: 0.9078\n",
      "Epoch 35/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2983 - accuracy: 0.9058 - val_loss: 0.2494 - val_accuracy: 0.9224\n",
      "Epoch 36/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2946 - accuracy: 0.9055 - val_loss: 0.2643 - val_accuracy: 0.9193\n",
      "Epoch 37/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2833 - accuracy: 0.9084 - val_loss: 0.2646 - val_accuracy: 0.9145\n",
      "Epoch 38/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2930 - accuracy: 0.9048 - val_loss: 0.2488 - val_accuracy: 0.9203\n",
      "Epoch 39/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2891 - accuracy: 0.9065 - val_loss: 0.2987 - val_accuracy: 0.9081\n",
      "Epoch 40/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.2765 - accuracy: 0.9125 - val_loss: 0.2748 - val_accuracy: 0.9159\n",
      "Epoch 41/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.2792 - accuracy: 0.9098 - val_loss: 0.2548 - val_accuracy: 0.9191\n",
      "Epoch 42/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2765 - accuracy: 0.9116 - val_loss: 0.2742 - val_accuracy: 0.9222\n",
      "Epoch 43/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2734 - accuracy: 0.9120 - val_loss: 0.2629 - val_accuracy: 0.9197\n",
      "Epoch 44/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2742 - accuracy: 0.9121 - val_loss: 0.2465 - val_accuracy: 0.9244\n",
      "Epoch 45/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2662 - accuracy: 0.9138 - val_loss: 0.2485 - val_accuracy: 0.9218\n",
      "Epoch 46/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2631 - accuracy: 0.9137 - val_loss: 0.2457 - val_accuracy: 0.9247\n",
      "Epoch 47/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2584 - accuracy: 0.9163 - val_loss: 0.2771 - val_accuracy: 0.9174\n",
      "Epoch 48/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2613 - accuracy: 0.9148 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 49/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2580 - accuracy: 0.9156 - val_loss: 0.2588 - val_accuracy: 0.9186\n",
      "Epoch 50/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2568 - accuracy: 0.9174 - val_loss: 0.2810 - val_accuracy: 0.9197\n",
      "Epoch 51/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2524 - accuracy: 0.9183 - val_loss: 0.2486 - val_accuracy: 0.9257\n",
      "Epoch 52/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2533 - accuracy: 0.9185 - val_loss: 0.2473 - val_accuracy: 0.9244\n",
      "Epoch 53/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2480 - accuracy: 0.9199 - val_loss: 0.2447 - val_accuracy: 0.9215\n",
      "Epoch 54/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2515 - accuracy: 0.9183 - val_loss: 0.2403 - val_accuracy: 0.9257\n",
      "Epoch 55/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2488 - accuracy: 0.9185 - val_loss: 0.2639 - val_accuracy: 0.9228\n",
      "Epoch 56/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2451 - accuracy: 0.9210 - val_loss: 0.2543 - val_accuracy: 0.9186\n",
      "Epoch 57/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2406 - accuracy: 0.9211 - val_loss: 0.2724 - val_accuracy: 0.9145\n",
      "Epoch 58/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.2391 - accuracy: 0.9205 - val_loss: 0.2388 - val_accuracy: 0.9301\n",
      "Epoch 59/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2375 - accuracy: 0.9221 - val_loss: 0.2540 - val_accuracy: 0.9247\n",
      "Epoch 60/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.2338 - accuracy: 0.9221 - val_loss: 0.2465 - val_accuracy: 0.9224\n",
      "Epoch 61/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.2348 - accuracy: 0.9222 - val_loss: 0.2305 - val_accuracy: 0.9319\n",
      "Epoch 62/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2329 - accuracy: 0.9222 - val_loss: 0.2339 - val_accuracy: 0.9257\n",
      "Epoch 63/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2307 - accuracy: 0.9250 - val_loss: 0.2687 - val_accuracy: 0.9226\n",
      "Epoch 64/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2268 - accuracy: 0.9248 - val_loss: 0.2383 - val_accuracy: 0.9288\n",
      "Epoch 65/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2295 - accuracy: 0.9252 - val_loss: 0.2525 - val_accuracy: 0.9253\n",
      "Epoch 66/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.2260 - accuracy: 0.9255 - val_loss: 0.2560 - val_accuracy: 0.9195\n",
      "Epoch 67/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2296 - accuracy: 0.9250 - val_loss: 0.2504 - val_accuracy: 0.9257\n",
      "Epoch 68/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2194 - accuracy: 0.9281 - val_loss: 0.2514 - val_accuracy: 0.9191\n",
      "Epoch 69/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2245 - accuracy: 0.9274 - val_loss: 0.2500 - val_accuracy: 0.9228\n",
      "Epoch 70/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2212 - accuracy: 0.9267 - val_loss: 0.2485 - val_accuracy: 0.9205\n",
      "Epoch 71/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2212 - accuracy: 0.9265 - val_loss: 0.2428 - val_accuracy: 0.9261\n",
      "Epoch 72/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2169 - accuracy: 0.9274 - val_loss: 0.2433 - val_accuracy: 0.9278\n",
      "Epoch 73/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2136 - accuracy: 0.9297 - val_loss: 0.2367 - val_accuracy: 0.9263\n",
      "Epoch 74/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2200 - accuracy: 0.9277 - val_loss: 0.2380 - val_accuracy: 0.9286\n",
      "Epoch 75/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2079 - accuracy: 0.9306 - val_loss: 0.2505 - val_accuracy: 0.9251\n",
      "Epoch 76/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2133 - accuracy: 0.9306 - val_loss: 0.2388 - val_accuracy: 0.9274\n",
      "Epoch 77/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2073 - accuracy: 0.9315 - val_loss: 0.2375 - val_accuracy: 0.9271\n",
      "Epoch 78/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2071 - accuracy: 0.9321 - val_loss: 0.2579 - val_accuracy: 0.9242\n",
      "Epoch 79/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2093 - accuracy: 0.9313 - val_loss: 0.2489 - val_accuracy: 0.9222\n",
      "Epoch 80/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.2046 - accuracy: 0.9324 - val_loss: 0.2629 - val_accuracy: 0.9226\n",
      "Epoch 81/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2041 - accuracy: 0.9343 - val_loss: 0.2452 - val_accuracy: 0.9259\n",
      "Epoch 82/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.2043 - accuracy: 0.9310 - val_loss: 0.2503 - val_accuracy: 0.9238\n",
      "Epoch 83/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2015 - accuracy: 0.9349 - val_loss: 0.2358 - val_accuracy: 0.9278\n",
      "Epoch 84/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1989 - accuracy: 0.9341 - val_loss: 0.2437 - val_accuracy: 0.9247\n",
      "Epoch 85/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2007 - accuracy: 0.9329 - val_loss: 0.2356 - val_accuracy: 0.9292\n",
      "Epoch 86/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.2015 - accuracy: 0.9314 - val_loss: 0.2426 - val_accuracy: 0.9278\n",
      "Epoch 87/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1964 - accuracy: 0.9346 - val_loss: 0.2796 - val_accuracy: 0.9205\n",
      "Epoch 88/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1937 - accuracy: 0.9360 - val_loss: 0.2519 - val_accuracy: 0.9257\n",
      "Epoch 89/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1953 - accuracy: 0.9357 - val_loss: 0.2449 - val_accuracy: 0.9271\n",
      "Epoch 90/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1925 - accuracy: 0.9358 - val_loss: 0.2382 - val_accuracy: 0.9257\n",
      "Epoch 91/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1925 - accuracy: 0.9355 - val_loss: 0.2396 - val_accuracy: 0.9240\n",
      "Epoch 92/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1970 - accuracy: 0.9356 - val_loss: 0.2510 - val_accuracy: 0.9228\n",
      "Epoch 93/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1940 - accuracy: 0.9362 - val_loss: 0.2545 - val_accuracy: 0.9203\n",
      "Epoch 94/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1905 - accuracy: 0.9358 - val_loss: 0.2407 - val_accuracy: 0.9263\n",
      "Epoch 95/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1868 - accuracy: 0.9386 - val_loss: 0.2482 - val_accuracy: 0.9242\n",
      "Epoch 96/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1869 - accuracy: 0.9377 - val_loss: 0.2471 - val_accuracy: 0.9259\n",
      "Epoch 97/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1867 - accuracy: 0.9375 - val_loss: 0.2374 - val_accuracy: 0.9292\n",
      "Epoch 98/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1823 - accuracy: 0.9393 - val_loss: 0.2494 - val_accuracy: 0.9282\n",
      "Epoch 99/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1852 - accuracy: 0.9377 - val_loss: 0.2856 - val_accuracy: 0.9147\n",
      "Epoch 100/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1842 - accuracy: 0.9365 - val_loss: 0.2584 - val_accuracy: 0.9274\n",
      "Epoch 101/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1807 - accuracy: 0.9400 - val_loss: 0.2433 - val_accuracy: 0.9274\n",
      "Epoch 102/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1858 - accuracy: 0.9374 - val_loss: 0.2366 - val_accuracy: 0.9301\n",
      "Epoch 103/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1832 - accuracy: 0.9392 - val_loss: 0.2470 - val_accuracy: 0.9288\n",
      "Epoch 104/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1814 - accuracy: 0.9398 - val_loss: 0.2497 - val_accuracy: 0.9278\n",
      "Epoch 105/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1801 - accuracy: 0.9382 - val_loss: 0.2516 - val_accuracy: 0.9249\n",
      "Epoch 106/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1795 - accuracy: 0.9405 - val_loss: 0.2468 - val_accuracy: 0.9274\n",
      "Epoch 107/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1772 - accuracy: 0.9405 - val_loss: 0.2438 - val_accuracy: 0.9269\n",
      "Epoch 108/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1756 - accuracy: 0.9396 - val_loss: 0.2542 - val_accuracy: 0.9247\n",
      "Epoch 109/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1741 - accuracy: 0.9421 - val_loss: 0.2422 - val_accuracy: 0.9278\n",
      "Epoch 110/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1776 - accuracy: 0.9401 - val_loss: 0.2428 - val_accuracy: 0.9284\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1765 - accuracy: 0.9413 - val_loss: 0.2419 - val_accuracy: 0.9265\n",
      "Epoch 112/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1739 - accuracy: 0.9423 - val_loss: 0.2462 - val_accuracy: 0.9269\n",
      "Epoch 113/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1736 - accuracy: 0.9420 - val_loss: 0.2506 - val_accuracy: 0.9253\n",
      "Epoch 114/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1695 - accuracy: 0.9430 - val_loss: 0.2428 - val_accuracy: 0.9280\n",
      "Epoch 115/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1670 - accuracy: 0.9440 - val_loss: 0.2469 - val_accuracy: 0.9286\n",
      "Epoch 116/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1739 - accuracy: 0.9425 - val_loss: 0.2554 - val_accuracy: 0.9251\n",
      "Epoch 117/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1723 - accuracy: 0.9425 - val_loss: 0.2380 - val_accuracy: 0.9307\n",
      "Epoch 118/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1679 - accuracy: 0.9434 - val_loss: 0.2442 - val_accuracy: 0.9288\n",
      "Epoch 119/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1648 - accuracy: 0.9440 - val_loss: 0.2546 - val_accuracy: 0.9257\n",
      "Epoch 120/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1707 - accuracy: 0.9428 - val_loss: 0.2392 - val_accuracy: 0.9307\n",
      "Epoch 121/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1687 - accuracy: 0.9432 - val_loss: 0.2399 - val_accuracy: 0.9253\n",
      "Epoch 122/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1674 - accuracy: 0.9444 - val_loss: 0.2575 - val_accuracy: 0.9230\n",
      "Epoch 123/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1676 - accuracy: 0.9430 - val_loss: 0.2605 - val_accuracy: 0.9224\n",
      "Epoch 124/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1680 - accuracy: 0.9425 - val_loss: 0.2434 - val_accuracy: 0.9290\n",
      "Epoch 125/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1668 - accuracy: 0.9449 - val_loss: 0.2513 - val_accuracy: 0.9263\n",
      "Epoch 126/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1621 - accuracy: 0.9438 - val_loss: 0.2485 - val_accuracy: 0.9253\n",
      "Epoch 127/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1661 - accuracy: 0.9452 - val_loss: 0.2459 - val_accuracy: 0.9309\n",
      "Epoch 128/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1652 - accuracy: 0.9458 - val_loss: 0.2517 - val_accuracy: 0.9259\n",
      "Epoch 129/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1590 - accuracy: 0.9463 - val_loss: 0.2660 - val_accuracy: 0.9271\n",
      "Epoch 130/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1646 - accuracy: 0.9447 - val_loss: 0.2502 - val_accuracy: 0.9276\n",
      "Epoch 131/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1602 - accuracy: 0.9465 - val_loss: 0.2582 - val_accuracy: 0.9265\n",
      "Epoch 132/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1612 - accuracy: 0.9456 - val_loss: 0.2484 - val_accuracy: 0.9265\n",
      "Epoch 133/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1641 - accuracy: 0.9441 - val_loss: 0.2511 - val_accuracy: 0.9288\n",
      "Epoch 134/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1594 - accuracy: 0.9483 - val_loss: 0.2514 - val_accuracy: 0.9269\n",
      "Epoch 135/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1605 - accuracy: 0.9466 - val_loss: 0.2400 - val_accuracy: 0.9301\n",
      "Epoch 136/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1540 - accuracy: 0.9480 - val_loss: 0.2462 - val_accuracy: 0.9288\n",
      "Epoch 137/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1548 - accuracy: 0.9475 - val_loss: 0.2568 - val_accuracy: 0.9247\n",
      "Epoch 138/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1592 - accuracy: 0.9470 - val_loss: 0.2475 - val_accuracy: 0.9255\n",
      "Epoch 139/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1521 - accuracy: 0.9498 - val_loss: 0.2479 - val_accuracy: 0.9305\n",
      "Epoch 140/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1532 - accuracy: 0.9477 - val_loss: 0.2643 - val_accuracy: 0.9232\n",
      "Epoch 141/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1561 - accuracy: 0.9475 - val_loss: 0.2610 - val_accuracy: 0.9265\n",
      "Epoch 142/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1515 - accuracy: 0.9488 - val_loss: 0.2504 - val_accuracy: 0.9298\n",
      "Epoch 143/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1569 - accuracy: 0.9471 - val_loss: 0.2514 - val_accuracy: 0.9259\n",
      "Epoch 144/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1549 - accuracy: 0.9471 - val_loss: 0.2508 - val_accuracy: 0.9274\n",
      "Epoch 145/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1556 - accuracy: 0.9457 - val_loss: 0.2455 - val_accuracy: 0.9305\n",
      "Epoch 146/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1545 - accuracy: 0.9478 - val_loss: 0.2492 - val_accuracy: 0.9282\n",
      "Epoch 147/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1547 - accuracy: 0.9481 - val_loss: 0.2603 - val_accuracy: 0.9276\n",
      "Epoch 148/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1493 - accuracy: 0.9500 - val_loss: 0.2522 - val_accuracy: 0.9261\n",
      "Epoch 149/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1493 - accuracy: 0.9495 - val_loss: 0.2553 - val_accuracy: 0.9274\n",
      "Epoch 150/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1465 - accuracy: 0.9507 - val_loss: 0.2509 - val_accuracy: 0.9292\n",
      "Epoch 151/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1497 - accuracy: 0.9495 - val_loss: 0.2631 - val_accuracy: 0.9247\n",
      "Epoch 152/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1500 - accuracy: 0.9503 - val_loss: 0.2513 - val_accuracy: 0.9259\n",
      "Epoch 153/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1513 - accuracy: 0.9489 - val_loss: 0.2502 - val_accuracy: 0.9244\n",
      "Epoch 154/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1455 - accuracy: 0.9513 - val_loss: 0.2580 - val_accuracy: 0.9267\n",
      "Epoch 155/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1427 - accuracy: 0.9517 - val_loss: 0.2647 - val_accuracy: 0.9271\n",
      "Epoch 156/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1438 - accuracy: 0.9516 - val_loss: 0.2600 - val_accuracy: 0.9288\n",
      "Epoch 157/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1423 - accuracy: 0.9513 - val_loss: 0.2741 - val_accuracy: 0.9261\n",
      "Epoch 158/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1477 - accuracy: 0.9507 - val_loss: 0.2555 - val_accuracy: 0.9313\n",
      "Epoch 159/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1448 - accuracy: 0.9510 - val_loss: 0.2633 - val_accuracy: 0.9259\n",
      "Epoch 160/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1454 - accuracy: 0.9500 - val_loss: 0.2674 - val_accuracy: 0.9265\n",
      "Epoch 161/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1426 - accuracy: 0.9507 - val_loss: 0.2593 - val_accuracy: 0.9276\n",
      "Epoch 162/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1472 - accuracy: 0.9503 - val_loss: 0.2586 - val_accuracy: 0.9282\n",
      "Epoch 163/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1429 - accuracy: 0.9515 - val_loss: 0.2529 - val_accuracy: 0.9288\n",
      "Epoch 164/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1438 - accuracy: 0.9513 - val_loss: 0.2719 - val_accuracy: 0.9247\n",
      "Epoch 165/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1397 - accuracy: 0.9524 - val_loss: 0.2633 - val_accuracy: 0.9276\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1395 - accuracy: 0.9538 - val_loss: 0.2531 - val_accuracy: 0.9307\n",
      "Epoch 167/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1423 - accuracy: 0.9523 - val_loss: 0.2499 - val_accuracy: 0.9280\n",
      "Epoch 168/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1424 - accuracy: 0.9529 - val_loss: 0.2631 - val_accuracy: 0.9240\n",
      "Epoch 169/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1393 - accuracy: 0.9533 - val_loss: 0.2897 - val_accuracy: 0.9201\n",
      "Epoch 170/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1409 - accuracy: 0.9525 - val_loss: 0.2677 - val_accuracy: 0.9257\n",
      "Epoch 171/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1422 - accuracy: 0.9530 - val_loss: 0.2705 - val_accuracy: 0.9257\n",
      "Epoch 172/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1422 - accuracy: 0.9520 - val_loss: 0.2552 - val_accuracy: 0.9288\n",
      "Epoch 173/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1403 - accuracy: 0.9526 - val_loss: 0.2637 - val_accuracy: 0.9244\n",
      "Epoch 174/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1390 - accuracy: 0.9541 - val_loss: 0.2506 - val_accuracy: 0.9292\n",
      "Epoch 175/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1370 - accuracy: 0.9536 - val_loss: 0.2587 - val_accuracy: 0.9255\n",
      "Epoch 176/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1405 - accuracy: 0.9516 - val_loss: 0.2485 - val_accuracy: 0.9267\n",
      "Epoch 177/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1329 - accuracy: 0.9546 - val_loss: 0.2481 - val_accuracy: 0.9319\n",
      "Epoch 178/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1324 - accuracy: 0.9551 - val_loss: 0.2694 - val_accuracy: 0.9226\n",
      "Epoch 179/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1360 - accuracy: 0.9528 - val_loss: 0.2552 - val_accuracy: 0.9317\n",
      "Epoch 180/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1374 - accuracy: 0.9534 - val_loss: 0.2593 - val_accuracy: 0.9292\n",
      "Epoch 181/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1357 - accuracy: 0.9538 - val_loss: 0.2597 - val_accuracy: 0.9282\n",
      "Epoch 182/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1376 - accuracy: 0.9540 - val_loss: 0.2450 - val_accuracy: 0.9296\n",
      "Epoch 183/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1390 - accuracy: 0.9536 - val_loss: 0.2644 - val_accuracy: 0.9236\n",
      "Epoch 184/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1325 - accuracy: 0.9552 - val_loss: 0.2685 - val_accuracy: 0.9259\n",
      "Epoch 185/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1336 - accuracy: 0.9550 - val_loss: 0.2601 - val_accuracy: 0.9263\n",
      "Epoch 186/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1326 - accuracy: 0.9558 - val_loss: 0.2699 - val_accuracy: 0.9280\n",
      "Epoch 187/500\n",
      "1205/1205 [==============================] - 14s 12ms/step - loss: 0.1312 - accuracy: 0.9554 - val_loss: 0.2565 - val_accuracy: 0.9286\n",
      "Epoch 188/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1294 - accuracy: 0.9564 - val_loss: 0.2597 - val_accuracy: 0.9288\n",
      "Epoch 189/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1306 - accuracy: 0.9555 - val_loss: 0.2682 - val_accuracy: 0.9267\n",
      "Epoch 190/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1305 - accuracy: 0.9549 - val_loss: 0.2564 - val_accuracy: 0.9269\n",
      "Epoch 191/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1333 - accuracy: 0.9558 - val_loss: 0.2619 - val_accuracy: 0.9236\n",
      "Epoch 192/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1314 - accuracy: 0.9558 - val_loss: 0.2618 - val_accuracy: 0.9278\n",
      "Epoch 193/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1329 - accuracy: 0.9549 - val_loss: 0.2540 - val_accuracy: 0.9282\n",
      "Epoch 194/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1279 - accuracy: 0.9573 - val_loss: 0.2709 - val_accuracy: 0.9288\n",
      "Epoch 195/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1307 - accuracy: 0.9551 - val_loss: 0.2587 - val_accuracy: 0.9274\n",
      "Epoch 196/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1304 - accuracy: 0.9559 - val_loss: 0.2676 - val_accuracy: 0.9296\n",
      "Epoch 197/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1291 - accuracy: 0.9560 - val_loss: 0.2588 - val_accuracy: 0.9309\n",
      "Epoch 198/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1271 - accuracy: 0.9572 - val_loss: 0.2695 - val_accuracy: 0.9251\n",
      "Epoch 199/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1297 - accuracy: 0.9556 - val_loss: 0.2621 - val_accuracy: 0.9282\n",
      "Epoch 200/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1281 - accuracy: 0.9561 - val_loss: 0.2612 - val_accuracy: 0.9267\n",
      "Epoch 201/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1322 - accuracy: 0.9562 - val_loss: 0.2561 - val_accuracy: 0.9290\n",
      "Epoch 202/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1286 - accuracy: 0.9567 - val_loss: 0.2613 - val_accuracy: 0.9319\n",
      "Epoch 203/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1294 - accuracy: 0.9563 - val_loss: 0.2565 - val_accuracy: 0.9305\n",
      "Epoch 204/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1260 - accuracy: 0.9565 - val_loss: 0.2733 - val_accuracy: 0.9276\n",
      "Epoch 205/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1256 - accuracy: 0.9577 - val_loss: 0.2707 - val_accuracy: 0.9236\n",
      "Epoch 206/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1261 - accuracy: 0.9565 - val_loss: 0.2678 - val_accuracy: 0.9292\n",
      "Epoch 207/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1274 - accuracy: 0.9574 - val_loss: 0.2674 - val_accuracy: 0.9313\n",
      "Epoch 208/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1262 - accuracy: 0.9567 - val_loss: 0.2743 - val_accuracy: 0.9269\n",
      "Epoch 209/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1265 - accuracy: 0.9566 - val_loss: 0.2765 - val_accuracy: 0.9253\n",
      "Epoch 210/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1236 - accuracy: 0.9589 - val_loss: 0.2598 - val_accuracy: 0.9321\n",
      "Epoch 211/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1244 - accuracy: 0.9586 - val_loss: 0.2731 - val_accuracy: 0.9290\n",
      "Epoch 212/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1244 - accuracy: 0.9584 - val_loss: 0.2600 - val_accuracy: 0.9292\n",
      "Epoch 213/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1247 - accuracy: 0.9568 - val_loss: 0.2868 - val_accuracy: 0.9188\n",
      "Epoch 214/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1224 - accuracy: 0.9593 - val_loss: 0.2748 - val_accuracy: 0.9244\n",
      "Epoch 215/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1251 - accuracy: 0.9571 - val_loss: 0.2608 - val_accuracy: 0.9313\n",
      "Epoch 216/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1211 - accuracy: 0.9585 - val_loss: 0.2690 - val_accuracy: 0.9274\n",
      "Epoch 217/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1211 - accuracy: 0.9600 - val_loss: 0.2600 - val_accuracy: 0.9296\n",
      "Epoch 218/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1223 - accuracy: 0.9589 - val_loss: 0.2640 - val_accuracy: 0.9292\n",
      "Epoch 219/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1224 - accuracy: 0.9591 - val_loss: 0.2747 - val_accuracy: 0.9290\n",
      "Epoch 220/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1211 - accuracy: 0.9590 - val_loss: 0.2737 - val_accuracy: 0.9290\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1253 - accuracy: 0.9578 - val_loss: 0.2563 - val_accuracy: 0.9292\n",
      "Epoch 222/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1177 - accuracy: 0.9599 - val_loss: 0.2596 - val_accuracy: 0.9330\n",
      "Epoch 223/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1227 - accuracy: 0.9579 - val_loss: 0.2631 - val_accuracy: 0.9307\n",
      "Epoch 224/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1207 - accuracy: 0.9584 - val_loss: 0.2661 - val_accuracy: 0.9294\n",
      "Epoch 225/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1214 - accuracy: 0.9587 - val_loss: 0.2589 - val_accuracy: 0.9305\n",
      "Epoch 226/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1206 - accuracy: 0.9594 - val_loss: 0.2754 - val_accuracy: 0.9292\n",
      "Epoch 227/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1185 - accuracy: 0.9594 - val_loss: 0.2762 - val_accuracy: 0.9294\n",
      "Epoch 228/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1191 - accuracy: 0.9597 - val_loss: 0.2749 - val_accuracy: 0.9317\n",
      "Epoch 229/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1230 - accuracy: 0.9578 - val_loss: 0.2708 - val_accuracy: 0.9249\n",
      "Epoch 230/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1162 - accuracy: 0.9616 - val_loss: 0.2817 - val_accuracy: 0.9271\n",
      "Epoch 231/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1171 - accuracy: 0.9606 - val_loss: 0.2642 - val_accuracy: 0.9323\n",
      "Epoch 232/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1169 - accuracy: 0.9604 - val_loss: 0.2679 - val_accuracy: 0.9313\n",
      "Epoch 233/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1167 - accuracy: 0.9608 - val_loss: 0.2716 - val_accuracy: 0.9278\n",
      "Epoch 234/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1130 - accuracy: 0.9618 - val_loss: 0.2658 - val_accuracy: 0.9305\n",
      "Epoch 235/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1172 - accuracy: 0.9605 - val_loss: 0.2732 - val_accuracy: 0.9294\n",
      "Epoch 236/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1168 - accuracy: 0.9607 - val_loss: 0.2760 - val_accuracy: 0.9232\n",
      "Epoch 237/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1142 - accuracy: 0.9611 - val_loss: 0.2754 - val_accuracy: 0.9282\n",
      "Epoch 238/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1136 - accuracy: 0.9605 - val_loss: 0.2690 - val_accuracy: 0.9274\n",
      "Epoch 239/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1203 - accuracy: 0.9605 - val_loss: 0.2856 - val_accuracy: 0.9263\n",
      "Epoch 240/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1168 - accuracy: 0.9604 - val_loss: 0.2718 - val_accuracy: 0.9290\n",
      "Epoch 241/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1153 - accuracy: 0.9609 - val_loss: 0.2709 - val_accuracy: 0.9267\n",
      "Epoch 242/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1164 - accuracy: 0.9598 - val_loss: 0.2687 - val_accuracy: 0.9271\n",
      "Epoch 243/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1190 - accuracy: 0.9604 - val_loss: 0.2661 - val_accuracy: 0.9298\n",
      "Epoch 244/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1120 - accuracy: 0.9621 - val_loss: 0.2719 - val_accuracy: 0.9301\n",
      "Epoch 245/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1149 - accuracy: 0.9600 - val_loss: 0.2691 - val_accuracy: 0.9292\n",
      "Epoch 246/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1159 - accuracy: 0.9598 - val_loss: 0.2781 - val_accuracy: 0.9234\n",
      "Epoch 247/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1112 - accuracy: 0.9619 - val_loss: 0.2698 - val_accuracy: 0.9278\n",
      "Epoch 248/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1098 - accuracy: 0.9627 - val_loss: 0.2706 - val_accuracy: 0.9284\n",
      "Epoch 249/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1119 - accuracy: 0.9619 - val_loss: 0.2622 - val_accuracy: 0.9298\n",
      "Epoch 250/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1142 - accuracy: 0.9607 - val_loss: 0.2768 - val_accuracy: 0.9267\n",
      "Epoch 251/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1132 - accuracy: 0.9618 - val_loss: 0.2740 - val_accuracy: 0.9288\n",
      "Epoch 252/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1132 - accuracy: 0.9615 - val_loss: 0.2697 - val_accuracy: 0.9292\n",
      "Epoch 253/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1125 - accuracy: 0.9611 - val_loss: 0.2866 - val_accuracy: 0.9253\n",
      "Epoch 254/500\n",
      "1205/1205 [==============================] - 15s 12ms/step - loss: 0.1121 - accuracy: 0.9619 - val_loss: 0.2739 - val_accuracy: 0.9284\n",
      "Epoch 255/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1104 - accuracy: 0.9626 - val_loss: 0.2703 - val_accuracy: 0.9288\n",
      "Epoch 256/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1116 - accuracy: 0.9633 - val_loss: 0.2741 - val_accuracy: 0.9271\n",
      "Epoch 257/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1091 - accuracy: 0.9625 - val_loss: 0.2786 - val_accuracy: 0.9238\n",
      "Epoch 258/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1100 - accuracy: 0.9620 - val_loss: 0.2687 - val_accuracy: 0.9263\n",
      "Epoch 259/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1140 - accuracy: 0.9615 - val_loss: 0.2805 - val_accuracy: 0.9257\n",
      "Epoch 260/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1099 - accuracy: 0.9625 - val_loss: 0.2683 - val_accuracy: 0.9290\n",
      "Epoch 261/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1109 - accuracy: 0.9621 - val_loss: 0.2734 - val_accuracy: 0.9259\n",
      "Epoch 262/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1084 - accuracy: 0.9637 - val_loss: 0.2869 - val_accuracy: 0.9253\n",
      "Epoch 263/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1100 - accuracy: 0.9620 - val_loss: 0.2803 - val_accuracy: 0.9257\n",
      "Epoch 264/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1088 - accuracy: 0.9641 - val_loss: 0.2875 - val_accuracy: 0.9244\n",
      "Epoch 265/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1079 - accuracy: 0.9629 - val_loss: 0.2727 - val_accuracy: 0.9280\n",
      "Epoch 266/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1140 - accuracy: 0.9620 - val_loss: 0.2720 - val_accuracy: 0.9276\n",
      "Epoch 267/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1075 - accuracy: 0.9643 - val_loss: 0.2723 - val_accuracy: 0.9296\n",
      "Epoch 268/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1068 - accuracy: 0.9631 - val_loss: 0.2862 - val_accuracy: 0.9280\n",
      "Epoch 269/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1057 - accuracy: 0.9646 - val_loss: 0.3073 - val_accuracy: 0.9203\n",
      "Epoch 270/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1081 - accuracy: 0.9635 - val_loss: 0.2777 - val_accuracy: 0.9280\n",
      "Epoch 271/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1040 - accuracy: 0.9640 - val_loss: 0.2826 - val_accuracy: 0.9294\n",
      "Epoch 272/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1066 - accuracy: 0.9646 - val_loss: 0.2758 - val_accuracy: 0.9294\n",
      "Epoch 273/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1082 - accuracy: 0.9638 - val_loss: 0.2739 - val_accuracy: 0.9274\n",
      "Epoch 274/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1078 - accuracy: 0.9632 - val_loss: 0.2802 - val_accuracy: 0.9267\n",
      "Epoch 275/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1126 - accuracy: 0.9628 - val_loss: 0.2741 - val_accuracy: 0.9271\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1044 - accuracy: 0.9639 - val_loss: 0.2937 - val_accuracy: 0.9253\n",
      "Epoch 277/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1092 - accuracy: 0.9628 - val_loss: 0.2842 - val_accuracy: 0.9271\n",
      "Epoch 278/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1057 - accuracy: 0.9644 - val_loss: 0.2724 - val_accuracy: 0.9288\n",
      "Epoch 279/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1055 - accuracy: 0.9637 - val_loss: 0.2747 - val_accuracy: 0.9255\n",
      "Epoch 280/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1026 - accuracy: 0.9648 - val_loss: 0.2830 - val_accuracy: 0.9265\n",
      "Epoch 281/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1035 - accuracy: 0.9646 - val_loss: 0.2729 - val_accuracy: 0.9290\n",
      "Epoch 282/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1041 - accuracy: 0.9650 - val_loss: 0.2759 - val_accuracy: 0.9286\n",
      "Epoch 283/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1081 - accuracy: 0.9634 - val_loss: 0.2707 - val_accuracy: 0.9290\n",
      "Epoch 284/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1042 - accuracy: 0.9649 - val_loss: 0.2745 - val_accuracy: 0.9269\n",
      "Epoch 285/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1047 - accuracy: 0.9658 - val_loss: 0.2691 - val_accuracy: 0.9286\n",
      "Epoch 286/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1068 - accuracy: 0.9625 - val_loss: 0.2704 - val_accuracy: 0.9292\n",
      "Epoch 287/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1032 - accuracy: 0.9649 - val_loss: 0.2803 - val_accuracy: 0.9261\n",
      "Epoch 288/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1051 - accuracy: 0.9643 - val_loss: 0.2765 - val_accuracy: 0.9317\n",
      "Epoch 289/500\n",
      "1205/1205 [==============================] - 14s 12ms/step - loss: 0.1034 - accuracy: 0.9645 - val_loss: 0.2817 - val_accuracy: 0.9263\n",
      "Epoch 290/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1021 - accuracy: 0.9650 - val_loss: 0.2862 - val_accuracy: 0.9257\n",
      "Epoch 291/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1060 - accuracy: 0.9623 - val_loss: 0.2763 - val_accuracy: 0.9269\n",
      "Epoch 292/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1028 - accuracy: 0.9651 - val_loss: 0.2776 - val_accuracy: 0.9280\n",
      "Epoch 293/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1058 - accuracy: 0.9636 - val_loss: 0.2770 - val_accuracy: 0.9282\n",
      "Epoch 294/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0989 - accuracy: 0.9671 - val_loss: 0.2825 - val_accuracy: 0.9259\n",
      "Epoch 295/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.1047 - accuracy: 0.9641 - val_loss: 0.2664 - val_accuracy: 0.9288\n",
      "Epoch 296/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1037 - accuracy: 0.9648 - val_loss: 0.2868 - val_accuracy: 0.9236\n",
      "Epoch 297/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1029 - accuracy: 0.9639 - val_loss: 0.2889 - val_accuracy: 0.9259\n",
      "Epoch 298/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1013 - accuracy: 0.9658 - val_loss: 0.2802 - val_accuracy: 0.9290\n",
      "Epoch 299/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0972 - accuracy: 0.9679 - val_loss: 0.2969 - val_accuracy: 0.9267\n",
      "Epoch 300/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1019 - accuracy: 0.9651 - val_loss: 0.2955 - val_accuracy: 0.9280\n",
      "Epoch 301/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0979 - accuracy: 0.9661 - val_loss: 0.3150 - val_accuracy: 0.9247\n",
      "Epoch 302/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1001 - accuracy: 0.9664 - val_loss: 0.2825 - val_accuracy: 0.9247\n",
      "Epoch 303/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1047 - accuracy: 0.9640 - val_loss: 0.2880 - val_accuracy: 0.9271\n",
      "Epoch 304/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0977 - accuracy: 0.9666 - val_loss: 0.2787 - val_accuracy: 0.9286\n",
      "Epoch 305/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1035 - accuracy: 0.9654 - val_loss: 0.2742 - val_accuracy: 0.9259\n",
      "Epoch 306/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1010 - accuracy: 0.9654 - val_loss: 0.2693 - val_accuracy: 0.9288\n",
      "Epoch 307/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0983 - accuracy: 0.9654 - val_loss: 0.2689 - val_accuracy: 0.9284\n",
      "Epoch 308/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0979 - accuracy: 0.9660 - val_loss: 0.2926 - val_accuracy: 0.9253\n",
      "Epoch 309/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1058 - accuracy: 0.9644 - val_loss: 0.2816 - val_accuracy: 0.9271\n",
      "Epoch 310/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0987 - accuracy: 0.9665 - val_loss: 0.2738 - val_accuracy: 0.9325\n",
      "Epoch 311/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0987 - accuracy: 0.9656 - val_loss: 0.2842 - val_accuracy: 0.9296\n",
      "Epoch 312/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1008 - accuracy: 0.9664 - val_loss: 0.2824 - val_accuracy: 0.9288\n",
      "Epoch 313/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1009 - accuracy: 0.9660 - val_loss: 0.2739 - val_accuracy: 0.9313\n",
      "Epoch 314/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1001 - accuracy: 0.9655 - val_loss: 0.2731 - val_accuracy: 0.9319\n",
      "Epoch 315/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0998 - accuracy: 0.9660 - val_loss: 0.2836 - val_accuracy: 0.9298\n",
      "Epoch 316/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1003 - accuracy: 0.9654 - val_loss: 0.2661 - val_accuracy: 0.9296\n",
      "Epoch 317/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0936 - accuracy: 0.9679 - val_loss: 0.2835 - val_accuracy: 0.9267\n",
      "Epoch 318/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0995 - accuracy: 0.9657 - val_loss: 0.2872 - val_accuracy: 0.9286\n",
      "Epoch 319/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0989 - accuracy: 0.9665 - val_loss: 0.2971 - val_accuracy: 0.9242\n",
      "Epoch 320/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0981 - accuracy: 0.9667 - val_loss: 0.2859 - val_accuracy: 0.9255\n",
      "Epoch 321/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.1003 - accuracy: 0.9660 - val_loss: 0.2822 - val_accuracy: 0.9274\n",
      "Epoch 322/500\n",
      "1205/1205 [==============================] - 14s 12ms/step - loss: 0.0925 - accuracy: 0.9686 - val_loss: 0.2787 - val_accuracy: 0.9301\n",
      "Epoch 323/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0965 - accuracy: 0.9673 - val_loss: 0.2805 - val_accuracy: 0.9267\n",
      "Epoch 324/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0971 - accuracy: 0.9673 - val_loss: 0.2734 - val_accuracy: 0.9288\n",
      "Epoch 325/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0979 - accuracy: 0.9662 - val_loss: 0.2924 - val_accuracy: 0.9249\n",
      "Epoch 326/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0960 - accuracy: 0.9674 - val_loss: 0.2795 - val_accuracy: 0.9276\n",
      "Epoch 327/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0960 - accuracy: 0.9680 - val_loss: 0.2938 - val_accuracy: 0.9261\n",
      "Epoch 328/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.1010 - accuracy: 0.9656 - val_loss: 0.2875 - val_accuracy: 0.9259\n",
      "Epoch 329/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0954 - accuracy: 0.9669 - val_loss: 0.2756 - val_accuracy: 0.9290\n",
      "Epoch 330/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.2794 - val_accuracy: 0.9271\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0960 - accuracy: 0.9672 - val_loss: 0.2802 - val_accuracy: 0.9280\n",
      "Epoch 332/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0954 - accuracy: 0.9672 - val_loss: 0.2896 - val_accuracy: 0.9240\n",
      "Epoch 333/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0982 - accuracy: 0.9666 - val_loss: 0.2765 - val_accuracy: 0.9278\n",
      "Epoch 334/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0938 - accuracy: 0.9682 - val_loss: 0.2968 - val_accuracy: 0.9269\n",
      "Epoch 335/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0955 - accuracy: 0.9668 - val_loss: 0.2880 - val_accuracy: 0.9274\n",
      "Epoch 336/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0949 - accuracy: 0.9680 - val_loss: 0.2804 - val_accuracy: 0.9274\n",
      "Epoch 337/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0990 - accuracy: 0.9661 - val_loss: 0.2971 - val_accuracy: 0.9240\n",
      "Epoch 338/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0978 - accuracy: 0.9665 - val_loss: 0.2790 - val_accuracy: 0.9294\n",
      "Epoch 339/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0924 - accuracy: 0.9681 - val_loss: 0.2838 - val_accuracy: 0.9286\n",
      "Epoch 340/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0938 - accuracy: 0.9682 - val_loss: 0.2960 - val_accuracy: 0.9274\n",
      "Epoch 341/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0922 - accuracy: 0.9677 - val_loss: 0.2918 - val_accuracy: 0.9276\n",
      "Epoch 342/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0913 - accuracy: 0.9676 - val_loss: 0.2942 - val_accuracy: 0.9278\n",
      "Epoch 343/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0953 - accuracy: 0.9683 - val_loss: 0.2800 - val_accuracy: 0.9323\n",
      "Epoch 344/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0932 - accuracy: 0.9673 - val_loss: 0.2726 - val_accuracy: 0.9309\n",
      "Epoch 345/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0936 - accuracy: 0.9676 - val_loss: 0.2850 - val_accuracy: 0.9323\n",
      "Epoch 346/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0900 - accuracy: 0.9702 - val_loss: 0.2839 - val_accuracy: 0.9313\n",
      "Epoch 347/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0952 - accuracy: 0.9681 - val_loss: 0.2886 - val_accuracy: 0.9274\n",
      "Epoch 348/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0930 - accuracy: 0.9673 - val_loss: 0.2826 - val_accuracy: 0.9307\n",
      "Epoch 349/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0956 - accuracy: 0.9680 - val_loss: 0.2721 - val_accuracy: 0.9313\n",
      "Epoch 350/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0930 - accuracy: 0.9682 - val_loss: 0.2967 - val_accuracy: 0.9244\n",
      "Epoch 351/500\n",
      "1205/1205 [==============================] - 14s 12ms/step - loss: 0.0936 - accuracy: 0.9681 - val_loss: 0.2829 - val_accuracy: 0.9294\n",
      "Epoch 352/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0928 - accuracy: 0.9685 - val_loss: 0.2727 - val_accuracy: 0.9346\n",
      "Epoch 353/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0970 - accuracy: 0.9669 - val_loss: 0.2758 - val_accuracy: 0.9307\n",
      "Epoch 354/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0909 - accuracy: 0.9704 - val_loss: 0.2837 - val_accuracy: 0.9267\n",
      "Epoch 355/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0938 - accuracy: 0.9692 - val_loss: 0.2850 - val_accuracy: 0.9319\n",
      "Epoch 356/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0896 - accuracy: 0.9690 - val_loss: 0.2921 - val_accuracy: 0.9284\n",
      "Epoch 357/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0974 - accuracy: 0.9668 - val_loss: 0.2804 - val_accuracy: 0.9280\n",
      "Epoch 358/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0903 - accuracy: 0.9700 - val_loss: 0.2947 - val_accuracy: 0.9255\n",
      "Epoch 359/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0912 - accuracy: 0.9705 - val_loss: 0.2988 - val_accuracy: 0.9259\n",
      "Epoch 360/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0928 - accuracy: 0.9686 - val_loss: 0.2782 - val_accuracy: 0.9247\n",
      "Epoch 361/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0917 - accuracy: 0.9692 - val_loss: 0.2835 - val_accuracy: 0.9247\n",
      "Epoch 362/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0907 - accuracy: 0.9696 - val_loss: 0.2997 - val_accuracy: 0.9282\n",
      "Epoch 363/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0930 - accuracy: 0.9683 - val_loss: 0.2792 - val_accuracy: 0.9269\n",
      "Epoch 364/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0914 - accuracy: 0.9691 - val_loss: 0.2901 - val_accuracy: 0.9249\n",
      "Epoch 365/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0919 - accuracy: 0.9682 - val_loss: 0.2840 - val_accuracy: 0.9315\n",
      "Epoch 366/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0896 - accuracy: 0.9701 - val_loss: 0.3039 - val_accuracy: 0.9286\n",
      "Epoch 367/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0913 - accuracy: 0.9680 - val_loss: 0.2766 - val_accuracy: 0.9303\n",
      "Epoch 368/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0892 - accuracy: 0.9697 - val_loss: 0.2970 - val_accuracy: 0.9269\n",
      "Epoch 369/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0936 - accuracy: 0.9689 - val_loss: 0.2793 - val_accuracy: 0.9298\n",
      "Epoch 370/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0893 - accuracy: 0.9703 - val_loss: 0.2917 - val_accuracy: 0.9278\n",
      "Epoch 371/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0912 - accuracy: 0.9690 - val_loss: 0.3023 - val_accuracy: 0.9269\n",
      "Epoch 372/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0879 - accuracy: 0.9701 - val_loss: 0.2975 - val_accuracy: 0.9278\n",
      "Epoch 373/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0882 - accuracy: 0.9699 - val_loss: 0.2878 - val_accuracy: 0.9309\n",
      "Epoch 374/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0918 - accuracy: 0.9690 - val_loss: 0.3009 - val_accuracy: 0.9274\n",
      "Epoch 375/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0879 - accuracy: 0.9704 - val_loss: 0.2885 - val_accuracy: 0.9290\n",
      "Epoch 376/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0921 - accuracy: 0.9693 - val_loss: 0.2819 - val_accuracy: 0.9292\n",
      "Epoch 377/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0861 - accuracy: 0.9709 - val_loss: 0.2876 - val_accuracy: 0.9307\n",
      "Epoch 378/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0890 - accuracy: 0.9699 - val_loss: 0.2993 - val_accuracy: 0.9301\n",
      "Epoch 379/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0867 - accuracy: 0.9710 - val_loss: 0.3122 - val_accuracy: 0.9282\n",
      "Epoch 380/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0884 - accuracy: 0.9698 - val_loss: 0.2874 - val_accuracy: 0.9294\n",
      "Epoch 381/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0869 - accuracy: 0.9704 - val_loss: 0.3032 - val_accuracy: 0.9290\n",
      "Epoch 382/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0844 - accuracy: 0.9719 - val_loss: 0.2960 - val_accuracy: 0.9298\n",
      "Epoch 383/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0875 - accuracy: 0.9696 - val_loss: 0.2952 - val_accuracy: 0.9284\n",
      "Epoch 384/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0915 - accuracy: 0.9683 - val_loss: 0.2843 - val_accuracy: 0.9325\n",
      "Epoch 385/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0901 - accuracy: 0.9697 - val_loss: 0.2811 - val_accuracy: 0.9328\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0890 - accuracy: 0.9713 - val_loss: 0.2981 - val_accuracy: 0.9276\n",
      "Epoch 387/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0875 - accuracy: 0.9702 - val_loss: 0.3196 - val_accuracy: 0.9255\n",
      "Epoch 388/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0855 - accuracy: 0.9704 - val_loss: 0.2946 - val_accuracy: 0.9271\n",
      "Epoch 389/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0857 - accuracy: 0.9704 - val_loss: 0.2988 - val_accuracy: 0.9276\n",
      "Epoch 390/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0837 - accuracy: 0.9716 - val_loss: 0.2967 - val_accuracy: 0.9286\n",
      "Epoch 391/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0863 - accuracy: 0.9724 - val_loss: 0.2856 - val_accuracy: 0.9317\n",
      "Epoch 392/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0897 - accuracy: 0.9699 - val_loss: 0.2817 - val_accuracy: 0.9319\n",
      "Epoch 393/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0852 - accuracy: 0.9715 - val_loss: 0.2856 - val_accuracy: 0.9298\n",
      "Epoch 394/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0843 - accuracy: 0.9721 - val_loss: 0.2833 - val_accuracy: 0.9301\n",
      "Epoch 395/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0883 - accuracy: 0.9710 - val_loss: 0.2837 - val_accuracy: 0.9296\n",
      "Epoch 396/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0839 - accuracy: 0.9720 - val_loss: 0.2716 - val_accuracy: 0.9338\n",
      "Epoch 397/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0836 - accuracy: 0.9712 - val_loss: 0.2922 - val_accuracy: 0.9276\n",
      "Epoch 398/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0902 - accuracy: 0.9693 - val_loss: 0.2840 - val_accuracy: 0.9259\n",
      "Epoch 399/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0848 - accuracy: 0.9716 - val_loss: 0.2919 - val_accuracy: 0.9286\n",
      "Epoch 400/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0874 - accuracy: 0.9709 - val_loss: 0.2806 - val_accuracy: 0.9276\n",
      "Epoch 401/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0871 - accuracy: 0.9701 - val_loss: 0.2977 - val_accuracy: 0.9222\n",
      "Epoch 402/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0825 - accuracy: 0.9726 - val_loss: 0.2980 - val_accuracy: 0.9278\n",
      "Epoch 403/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0815 - accuracy: 0.9726 - val_loss: 0.2998 - val_accuracy: 0.9263\n",
      "Epoch 404/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0845 - accuracy: 0.9712 - val_loss: 0.2918 - val_accuracy: 0.9286\n",
      "Epoch 405/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0869 - accuracy: 0.9708 - val_loss: 0.2782 - val_accuracy: 0.9271\n",
      "Epoch 406/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0845 - accuracy: 0.9708 - val_loss: 0.2776 - val_accuracy: 0.9290\n",
      "Epoch 407/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0830 - accuracy: 0.9725 - val_loss: 0.2924 - val_accuracy: 0.9286\n",
      "Epoch 408/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0856 - accuracy: 0.9708 - val_loss: 0.2777 - val_accuracy: 0.9330\n",
      "Epoch 409/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0844 - accuracy: 0.9699 - val_loss: 0.2853 - val_accuracy: 0.9301\n",
      "Epoch 410/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0837 - accuracy: 0.9715 - val_loss: 0.2887 - val_accuracy: 0.9294\n",
      "Epoch 411/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0828 - accuracy: 0.9717 - val_loss: 0.2873 - val_accuracy: 0.9303\n",
      "Epoch 412/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0856 - accuracy: 0.9702 - val_loss: 0.2915 - val_accuracy: 0.9301\n",
      "Epoch 413/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0858 - accuracy: 0.9707 - val_loss: 0.2884 - val_accuracy: 0.9298\n",
      "Epoch 414/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0871 - accuracy: 0.9706 - val_loss: 0.2951 - val_accuracy: 0.9271\n",
      "Epoch 415/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0857 - accuracy: 0.9704 - val_loss: 0.2846 - val_accuracy: 0.9274\n",
      "Epoch 416/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0857 - accuracy: 0.9716 - val_loss: 0.2708 - val_accuracy: 0.9280\n",
      "Epoch 417/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0834 - accuracy: 0.9712 - val_loss: 0.2969 - val_accuracy: 0.9303\n",
      "Epoch 418/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0864 - accuracy: 0.9706 - val_loss: 0.2863 - val_accuracy: 0.9315\n",
      "Epoch 419/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0817 - accuracy: 0.9725 - val_loss: 0.2875 - val_accuracy: 0.9303\n",
      "Epoch 420/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0835 - accuracy: 0.9713 - val_loss: 0.2826 - val_accuracy: 0.9313\n",
      "Epoch 421/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0824 - accuracy: 0.9718 - val_loss: 0.2856 - val_accuracy: 0.9319\n",
      "Epoch 422/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0844 - accuracy: 0.9704 - val_loss: 0.2895 - val_accuracy: 0.9288\n",
      "Epoch 423/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0835 - accuracy: 0.9709 - val_loss: 0.2847 - val_accuracy: 0.9301\n",
      "Epoch 424/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0829 - accuracy: 0.9718 - val_loss: 0.2897 - val_accuracy: 0.9282\n",
      "Epoch 425/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0840 - accuracy: 0.9721 - val_loss: 0.2879 - val_accuracy: 0.9290\n",
      "Epoch 426/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0818 - accuracy: 0.9731 - val_loss: 0.3140 - val_accuracy: 0.9255\n",
      "Epoch 427/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0828 - accuracy: 0.9725 - val_loss: 0.2865 - val_accuracy: 0.9288\n",
      "Epoch 428/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0800 - accuracy: 0.9726 - val_loss: 0.2983 - val_accuracy: 0.9280\n",
      "Epoch 429/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0823 - accuracy: 0.9711 - val_loss: 0.2956 - val_accuracy: 0.9305\n",
      "Epoch 430/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0831 - accuracy: 0.9720 - val_loss: 0.2945 - val_accuracy: 0.9292\n",
      "Epoch 431/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0825 - accuracy: 0.9722 - val_loss: 0.3031 - val_accuracy: 0.9286\n",
      "Epoch 432/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0817 - accuracy: 0.9728 - val_loss: 0.2903 - val_accuracy: 0.9294\n",
      "Epoch 433/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0828 - accuracy: 0.9726 - val_loss: 0.2908 - val_accuracy: 0.9288\n",
      "Epoch 434/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0798 - accuracy: 0.9729 - val_loss: 0.2994 - val_accuracy: 0.9294\n",
      "Epoch 435/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0840 - accuracy: 0.9705 - val_loss: 0.2855 - val_accuracy: 0.9269\n",
      "Epoch 436/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0857 - accuracy: 0.9721 - val_loss: 0.2865 - val_accuracy: 0.9284\n",
      "Epoch 437/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0843 - accuracy: 0.9709 - val_loss: 0.3248 - val_accuracy: 0.9240\n",
      "Epoch 438/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0787 - accuracy: 0.9730 - val_loss: 0.3002 - val_accuracy: 0.9259\n",
      "Epoch 439/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0788 - accuracy: 0.9729 - val_loss: 0.3068 - val_accuracy: 0.9255\n",
      "Epoch 440/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0847 - accuracy: 0.9714 - val_loss: 0.2768 - val_accuracy: 0.9296\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0824 - accuracy: 0.9719 - val_loss: 0.2865 - val_accuracy: 0.9271\n",
      "Epoch 442/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0820 - accuracy: 0.9720 - val_loss: 0.2954 - val_accuracy: 0.9263\n",
      "Epoch 443/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0802 - accuracy: 0.9723 - val_loss: 0.2847 - val_accuracy: 0.9288\n",
      "Epoch 444/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0827 - accuracy: 0.9718 - val_loss: 0.2940 - val_accuracy: 0.9286\n",
      "Epoch 445/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0820 - accuracy: 0.9718 - val_loss: 0.2874 - val_accuracy: 0.9296\n",
      "Epoch 446/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0796 - accuracy: 0.9735 - val_loss: 0.2912 - val_accuracy: 0.9257\n",
      "Epoch 447/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0790 - accuracy: 0.9736 - val_loss: 0.2974 - val_accuracy: 0.9271\n",
      "Epoch 448/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0811 - accuracy: 0.9729 - val_loss: 0.2930 - val_accuracy: 0.9257\n",
      "Epoch 449/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0808 - accuracy: 0.9730 - val_loss: 0.2927 - val_accuracy: 0.9251\n",
      "Epoch 450/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0783 - accuracy: 0.9734 - val_loss: 0.2881 - val_accuracy: 0.9292\n",
      "Epoch 451/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0796 - accuracy: 0.9735 - val_loss: 0.2979 - val_accuracy: 0.9282\n",
      "Epoch 452/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0785 - accuracy: 0.9733 - val_loss: 0.3022 - val_accuracy: 0.9278\n",
      "Epoch 453/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0808 - accuracy: 0.9727 - val_loss: 0.2862 - val_accuracy: 0.9276\n",
      "Epoch 454/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0806 - accuracy: 0.9717 - val_loss: 0.2870 - val_accuracy: 0.9271\n",
      "Epoch 455/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0787 - accuracy: 0.9740 - val_loss: 0.3075 - val_accuracy: 0.9296\n",
      "Epoch 456/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.2989 - val_accuracy: 0.9257\n",
      "Epoch 457/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0785 - accuracy: 0.9736 - val_loss: 0.2925 - val_accuracy: 0.9296\n",
      "Epoch 458/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0796 - accuracy: 0.9729 - val_loss: 0.2827 - val_accuracy: 0.9313\n",
      "Epoch 459/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0817 - accuracy: 0.9715 - val_loss: 0.3027 - val_accuracy: 0.9276\n",
      "Epoch 460/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0802 - accuracy: 0.9730 - val_loss: 0.2814 - val_accuracy: 0.9284\n",
      "Epoch 461/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0798 - accuracy: 0.9728 - val_loss: 0.2856 - val_accuracy: 0.9298\n",
      "Epoch 462/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0788 - accuracy: 0.9733 - val_loss: 0.2886 - val_accuracy: 0.9286\n",
      "Epoch 463/500\n",
      "1205/1205 [==============================] - 14s 12ms/step - loss: 0.0795 - accuracy: 0.9742 - val_loss: 0.2989 - val_accuracy: 0.9265\n",
      "Epoch 464/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0791 - accuracy: 0.9733 - val_loss: 0.3002 - val_accuracy: 0.9276\n",
      "Epoch 465/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0778 - accuracy: 0.9735 - val_loss: 0.2843 - val_accuracy: 0.9292\n",
      "Epoch 466/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0798 - accuracy: 0.9724 - val_loss: 0.2906 - val_accuracy: 0.9301\n",
      "Epoch 467/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0787 - accuracy: 0.9734 - val_loss: 0.2883 - val_accuracy: 0.9280\n",
      "Epoch 468/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 0.2849 - val_accuracy: 0.9286\n",
      "Epoch 469/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0756 - accuracy: 0.9735 - val_loss: 0.2952 - val_accuracy: 0.9290\n",
      "Epoch 470/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0798 - accuracy: 0.9733 - val_loss: 0.2913 - val_accuracy: 0.9305\n",
      "Epoch 471/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0752 - accuracy: 0.9732 - val_loss: 0.3046 - val_accuracy: 0.9274\n",
      "Epoch 472/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0803 - accuracy: 0.9724 - val_loss: 0.2951 - val_accuracy: 0.9269\n",
      "Epoch 473/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0797 - accuracy: 0.9736 - val_loss: 0.2907 - val_accuracy: 0.9271\n",
      "Epoch 474/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0762 - accuracy: 0.9742 - val_loss: 0.3005 - val_accuracy: 0.9247\n",
      "Epoch 475/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0799 - accuracy: 0.9735 - val_loss: 0.3018 - val_accuracy: 0.9274\n",
      "Epoch 476/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0760 - accuracy: 0.9748 - val_loss: 0.3068 - val_accuracy: 0.9292\n",
      "Epoch 477/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0806 - accuracy: 0.9729 - val_loss: 0.2951 - val_accuracy: 0.9251\n",
      "Epoch 478/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0771 - accuracy: 0.9749 - val_loss: 0.2965 - val_accuracy: 0.9253\n",
      "Epoch 479/500\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.0726 - accuracy: 0.9742 - val_loss: 0.3060 - val_accuracy: 0.9265\n",
      "Epoch 480/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0819 - accuracy: 0.9728 - val_loss: 0.2924 - val_accuracy: 0.9278\n",
      "Epoch 481/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0788 - accuracy: 0.9737 - val_loss: 0.2875 - val_accuracy: 0.9280\n",
      "Epoch 482/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0754 - accuracy: 0.9738 - val_loss: 0.2936 - val_accuracy: 0.9278\n",
      "Epoch 483/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0750 - accuracy: 0.9735 - val_loss: 0.2874 - val_accuracy: 0.9269\n",
      "Epoch 484/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0774 - accuracy: 0.9729 - val_loss: 0.2920 - val_accuracy: 0.9305\n",
      "Epoch 485/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0745 - accuracy: 0.9758 - val_loss: 0.2982 - val_accuracy: 0.9298\n",
      "Epoch 486/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0781 - accuracy: 0.9734 - val_loss: 0.2948 - val_accuracy: 0.9294\n",
      "Epoch 487/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.2939 - val_accuracy: 0.9286\n",
      "Epoch 488/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0783 - accuracy: 0.9738 - val_loss: 0.2933 - val_accuracy: 0.9274\n",
      "Epoch 489/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0775 - accuracy: 0.9735 - val_loss: 0.2906 - val_accuracy: 0.9323\n",
      "Epoch 490/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0766 - accuracy: 0.9741 - val_loss: 0.3000 - val_accuracy: 0.9278\n",
      "Epoch 491/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0746 - accuracy: 0.9745 - val_loss: 0.2908 - val_accuracy: 0.9259\n",
      "Epoch 492/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0778 - accuracy: 0.9729 - val_loss: 0.2908 - val_accuracy: 0.9267\n",
      "Epoch 493/500\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.0766 - accuracy: 0.9749 - val_loss: 0.3012 - val_accuracy: 0.9269\n",
      "Epoch 494/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0737 - accuracy: 0.9757 - val_loss: 0.2971 - val_accuracy: 0.9249\n",
      "Epoch 495/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0743 - accuracy: 0.9746 - val_loss: 0.2971 - val_accuracy: 0.9274\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 14s 12ms/step - loss: 0.0720 - accuracy: 0.9754 - val_loss: 0.2920 - val_accuracy: 0.9267\n",
      "Epoch 497/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0769 - accuracy: 0.9729 - val_loss: 0.2975 - val_accuracy: 0.9282\n",
      "Epoch 498/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0758 - accuracy: 0.9748 - val_loss: 0.2967 - val_accuracy: 0.9311\n",
      "Epoch 499/500\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.0724 - accuracy: 0.9754 - val_loss: 0.2998 - val_accuracy: 0.9284\n",
      "Epoch 500/500\n",
      "1205/1205 [==============================] - 13s 10ms/step - loss: 0.0757 - accuracy: 0.9747 - val_loss: 0.2916 - val_accuracy: 0.9290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0e603757f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model for 500 epochs and keep the best model measured on the validation accuracy. \n",
    "\n",
    "EPOCHS = 500\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = CNN_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),  \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "CNN_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5747703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6418/897927363.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
      "/tmp/ipykernel_6418/897927363.py:11: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
      "/tmp/ipykernel_6418/897927363.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
      "/tmp/ipykernel_6418/897927363.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "172d89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNN-Model\n",
    "\n",
    "models.save_model(CNN_model, CNN_model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8dd616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of CNN: 99.96627569198608 %\n",
      "Accuracy on validation set of CNN: 93.4620201587677 %\n",
      "Accuracy on test set with SNR of 1 of CNN: 75.98588466644287 %\n",
      "Accuracy on test set with SNR of 10 of CNN: 90.2034044265747 %\n",
      "Accuracy on test set with SNR of 20 of CNN: 93.48277449607849 %\n",
      "Accuracy on test set with SNR of 100 of CNN: 93.98090243339539 %\n",
      "Accuracy on test set with SNR of 1000 of CNN: 93.75259280204773 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the CNN model \n",
    "\n",
    "score = CNN_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of CNN:', score[1] * 100,'%')\n",
    "\n",
    "score = CNN_model.evaluate(x_test1, y_test1, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1 of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test10, y_test10, verbose=0)\n",
    "print('Accuracy on test set with SNR of 10 of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test20, y_test20, verbose=0)\n",
    "print('Accuracy on test set with SNR of 20 of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test100, y_test100, verbose=0)\n",
    "print('Accuracy on test set with SNR of 100 of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test1000, y_test1000, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1000 of CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ed9b8",
   "metadata": {},
   "source": [
    "<font size=\"5\">3. Quantize the CNN-Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf0883cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (QuantizedConv2D)     (None, 20, 51, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ActivationDiscr (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (QuantizedSepara (None, 20, 51, 32)        1344      \n",
      "_________________________________________________________________\n",
      "separable_1_relu (Activation (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (QuantizedSepara (None, 10, 26, 64)        2400      \n",
      "_________________________________________________________________\n",
      "separable_2_relu (Activation (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (QuantizedSepara (None, 10, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "separable_3_relu (Activation (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (QuantizedSepara (None, 5, 13, 128)        17664     \n",
      "_________________________________________________________________\n",
      "separable_4_relu (Activation (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (QuantizedSepara (None, 5, 13, 256)        34176     \n",
      "_________________________________________________________________\n",
      "separable_5_relu (Activation (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (QuantizedSepara (None, 3, 7, 256)         68096     \n",
      "_________________________________________________________________\n",
      "separable_6_relu (Activation (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (QuantizedSepara (None, 2, 4, 512)         133888    \n",
      "_________________________________________________________________\n",
      "separable_7_relu (Activation (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (QuantizedSepara (None, 2, 4, 1024)        529920    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_relu (Activation (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (QuantizedDense)       (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "re_lu (ActivationDiscreteRel (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 809,004\n",
      "Trainable params: 809,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Quantize the CNN-model\n",
    "\n",
    "quantized_model = quantize(CNN_model,\n",
    "                           input_weight_quantization=8,\n",
    "                           weight_quantization=4,\n",
    "                           activ_quantization=4)\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0300370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy after quantization\n",
    "\n",
    "quantized_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab6dfa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of quantized CNN: 64.31536078453064 %\n",
      "Accuracy on validation set of quantized CNN: 57.72104859352112 %\n",
      "Accuracy on test set with SNR of 1 of quantized CNN: 47.820672392845154 %\n",
      "Accuracy on test set with SNR of 10 of quantized CNN: 54.877543449401855 %\n",
      "Accuracy on test set with SNR of 20 of quantized CNN: 57.65877962112427 %\n",
      "Accuracy on test set with SNR of 100 of quantized CNN: 59.132421016693115 %\n",
      "Accuracy on test set with SNR of 1000 of quantized CNN: 59.132421016693115 %\n"
     ]
    }
   ],
   "source": [
    "score = quantized_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of quantized CNN:', score[1] * 100,'%')\n",
    "\n",
    "score = quantized_model.evaluate(x_test1, y_test1, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test10, y_test10, verbose=0)\n",
    "print('Accuracy on test set with SNR of 10 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test20, y_test20, verbose=0)\n",
    "print('Accuracy on test set with SNR of 20 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test100, y_test100, verbose=0)\n",
    "print('Accuracy on test set with SNR of 100 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test1000, y_test1000, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1000 of quantized CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "043b41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1205/1205 [==============================] - 20s 15ms/step - loss: 0.4077 - accuracy: 0.8605 - val_loss: 0.3253 - val_accuracy: 0.9108\n",
      "Epoch 2/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1922 - accuracy: 0.9460 - val_loss: 0.2863 - val_accuracy: 0.9257\n",
      "Epoch 3/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1651 - accuracy: 0.9552 - val_loss: 0.2818 - val_accuracy: 0.9247\n",
      "Epoch 4/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1556 - accuracy: 0.9581 - val_loss: 0.2772 - val_accuracy: 0.9253\n",
      "Epoch 5/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1476 - accuracy: 0.9594 - val_loss: 0.2750 - val_accuracy: 0.9290\n",
      "Epoch 6/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1439 - accuracy: 0.9619 - val_loss: 0.2666 - val_accuracy: 0.9298\n",
      "Epoch 7/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1381 - accuracy: 0.9631 - val_loss: 0.2688 - val_accuracy: 0.9301\n",
      "Epoch 8/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1361 - accuracy: 0.9641 - val_loss: 0.2792 - val_accuracy: 0.9278\n",
      "Epoch 9/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1339 - accuracy: 0.9636 - val_loss: 0.2736 - val_accuracy: 0.9294\n",
      "Epoch 10/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1309 - accuracy: 0.9663 - val_loss: 0.2715 - val_accuracy: 0.9301\n",
      "Epoch 11/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1296 - accuracy: 0.9651 - val_loss: 0.2783 - val_accuracy: 0.9298\n",
      "Epoch 12/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1244 - accuracy: 0.9678 - val_loss: 0.2708 - val_accuracy: 0.9294\n",
      "Epoch 13/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1304 - accuracy: 0.9657 - val_loss: 0.2706 - val_accuracy: 0.9313\n",
      "Epoch 14/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1242 - accuracy: 0.9671 - val_loss: 0.2727 - val_accuracy: 0.9328\n",
      "Epoch 15/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1226 - accuracy: 0.9682 - val_loss: 0.2699 - val_accuracy: 0.9317\n",
      "Epoch 16/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1222 - accuracy: 0.9683 - val_loss: 0.2720 - val_accuracy: 0.9286\n",
      "Epoch 17/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1216 - accuracy: 0.9684 - val_loss: 0.2701 - val_accuracy: 0.9296\n",
      "Epoch 18/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1213 - accuracy: 0.9674 - val_loss: 0.2764 - val_accuracy: 0.9288\n",
      "Epoch 19/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1235 - accuracy: 0.9678 - val_loss: 0.2750 - val_accuracy: 0.9301\n",
      "Epoch 20/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1201 - accuracy: 0.9684 - val_loss: 0.2784 - val_accuracy: 0.9315\n",
      "Epoch 21/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1181 - accuracy: 0.9690 - val_loss: 0.2725 - val_accuracy: 0.9328\n",
      "Epoch 22/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1198 - accuracy: 0.9690 - val_loss: 0.2755 - val_accuracy: 0.9296\n",
      "Epoch 23/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1200 - accuracy: 0.9689 - val_loss: 0.2770 - val_accuracy: 0.9313\n",
      "Epoch 24/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1193 - accuracy: 0.9694 - val_loss: 0.2741 - val_accuracy: 0.9317\n",
      "Epoch 25/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1173 - accuracy: 0.9695 - val_loss: 0.2766 - val_accuracy: 0.9309\n",
      "Epoch 26/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1164 - accuracy: 0.9692 - val_loss: 0.2802 - val_accuracy: 0.9301\n",
      "Epoch 27/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1155 - accuracy: 0.9693 - val_loss: 0.2809 - val_accuracy: 0.9313\n",
      "Epoch 28/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1167 - accuracy: 0.9692 - val_loss: 0.2793 - val_accuracy: 0.9317\n",
      "Epoch 29/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1157 - accuracy: 0.9701 - val_loss: 0.2750 - val_accuracy: 0.9301\n",
      "Epoch 30/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1168 - accuracy: 0.9685 - val_loss: 0.2741 - val_accuracy: 0.9321\n",
      "Epoch 31/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1131 - accuracy: 0.9710 - val_loss: 0.2826 - val_accuracy: 0.9282\n",
      "Epoch 32/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1188 - accuracy: 0.9682 - val_loss: 0.2739 - val_accuracy: 0.9294\n",
      "Epoch 33/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1150 - accuracy: 0.9704 - val_loss: 0.2747 - val_accuracy: 0.9301\n",
      "Epoch 34/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1172 - accuracy: 0.9696 - val_loss: 0.2778 - val_accuracy: 0.9311\n",
      "Epoch 35/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1134 - accuracy: 0.9707 - val_loss: 0.2677 - val_accuracy: 0.9328\n",
      "Epoch 36/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1134 - accuracy: 0.9712 - val_loss: 0.2749 - val_accuracy: 0.9296\n",
      "Epoch 37/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1088 - accuracy: 0.9722 - val_loss: 0.2743 - val_accuracy: 0.9294\n",
      "Epoch 38/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1120 - accuracy: 0.9710 - val_loss: 0.2815 - val_accuracy: 0.9309\n",
      "Epoch 39/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1135 - accuracy: 0.9705 - val_loss: 0.2775 - val_accuracy: 0.9305\n",
      "Epoch 40/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1118 - accuracy: 0.9709 - val_loss: 0.2756 - val_accuracy: 0.9303\n",
      "Epoch 41/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1123 - accuracy: 0.9709 - val_loss: 0.2787 - val_accuracy: 0.9294\n",
      "Epoch 42/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1141 - accuracy: 0.9707 - val_loss: 0.2779 - val_accuracy: 0.9267\n",
      "Epoch 43/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1135 - accuracy: 0.9708 - val_loss: 0.2779 - val_accuracy: 0.9288\n",
      "Epoch 44/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1102 - accuracy: 0.9718 - val_loss: 0.2759 - val_accuracy: 0.9305\n",
      "Epoch 45/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1085 - accuracy: 0.9719 - val_loss: 0.2799 - val_accuracy: 0.9290\n",
      "Epoch 46/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1129 - accuracy: 0.9710 - val_loss: 0.2789 - val_accuracy: 0.9288\n",
      "Epoch 47/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1109 - accuracy: 0.9715 - val_loss: 0.2737 - val_accuracy: 0.9309\n",
      "Epoch 48/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1100 - accuracy: 0.9730 - val_loss: 0.2746 - val_accuracy: 0.9309\n",
      "Epoch 49/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1061 - accuracy: 0.9718 - val_loss: 0.2772 - val_accuracy: 0.9311\n",
      "Epoch 50/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1122 - accuracy: 0.9715 - val_loss: 0.2767 - val_accuracy: 0.9257\n",
      "Epoch 51/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1088 - accuracy: 0.9719 - val_loss: 0.2845 - val_accuracy: 0.9278\n",
      "Epoch 52/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1085 - accuracy: 0.9719 - val_loss: 0.2794 - val_accuracy: 0.9286\n",
      "Epoch 53/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1096 - accuracy: 0.9714 - val_loss: 0.2801 - val_accuracy: 0.9290\n",
      "Epoch 54/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1074 - accuracy: 0.9729 - val_loss: 0.2762 - val_accuracy: 0.9284\n",
      "Epoch 55/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1062 - accuracy: 0.9731 - val_loss: 0.2789 - val_accuracy: 0.9305\n",
      "Epoch 56/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1067 - accuracy: 0.9727 - val_loss: 0.2796 - val_accuracy: 0.9325\n",
      "Epoch 57/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1123 - accuracy: 0.9715 - val_loss: 0.2848 - val_accuracy: 0.9263\n",
      "Epoch 58/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1084 - accuracy: 0.9715 - val_loss: 0.2791 - val_accuracy: 0.9323\n",
      "Epoch 59/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1099 - accuracy: 0.9722 - val_loss: 0.2745 - val_accuracy: 0.9325\n",
      "Epoch 60/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1080 - accuracy: 0.9716 - val_loss: 0.2892 - val_accuracy: 0.9282\n",
      "Epoch 61/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1096 - accuracy: 0.9722 - val_loss: 0.2826 - val_accuracy: 0.9292\n",
      "Epoch 62/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1079 - accuracy: 0.9719 - val_loss: 0.2689 - val_accuracy: 0.9309\n",
      "Epoch 63/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1100 - accuracy: 0.9722 - val_loss: 0.2745 - val_accuracy: 0.9305\n",
      "Epoch 64/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1105 - accuracy: 0.9728 - val_loss: 0.2743 - val_accuracy: 0.9301\n",
      "Epoch 65/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1085 - accuracy: 0.9733 - val_loss: 0.2791 - val_accuracy: 0.9296\n",
      "Epoch 66/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1067 - accuracy: 0.9729 - val_loss: 0.2784 - val_accuracy: 0.9298\n",
      "Epoch 67/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1089 - accuracy: 0.9732 - val_loss: 0.2754 - val_accuracy: 0.9284\n",
      "Epoch 68/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1061 - accuracy: 0.9732 - val_loss: 0.2765 - val_accuracy: 0.9301\n",
      "Epoch 69/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1080 - accuracy: 0.9723 - val_loss: 0.2767 - val_accuracy: 0.9288\n",
      "Epoch 70/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1075 - accuracy: 0.9733 - val_loss: 0.2707 - val_accuracy: 0.9294\n",
      "Epoch 71/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1066 - accuracy: 0.9734 - val_loss: 0.2793 - val_accuracy: 0.9290\n",
      "Epoch 72/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1060 - accuracy: 0.9736 - val_loss: 0.2782 - val_accuracy: 0.9288\n",
      "Epoch 73/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1095 - accuracy: 0.9722 - val_loss: 0.2689 - val_accuracy: 0.9325\n",
      "Epoch 74/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1077 - accuracy: 0.9728 - val_loss: 0.2764 - val_accuracy: 0.9280\n",
      "Epoch 75/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1018 - accuracy: 0.9749 - val_loss: 0.2746 - val_accuracy: 0.9303\n",
      "Epoch 76/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1019 - accuracy: 0.9747 - val_loss: 0.2799 - val_accuracy: 0.9290\n",
      "Epoch 77/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1036 - accuracy: 0.9741 - val_loss: 0.2722 - val_accuracy: 0.9303\n",
      "Epoch 78/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1069 - accuracy: 0.9727 - val_loss: 0.2778 - val_accuracy: 0.9274\n",
      "Epoch 79/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1083 - accuracy: 0.9727 - val_loss: 0.2783 - val_accuracy: 0.9288\n",
      "Epoch 80/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1088 - accuracy: 0.9719 - val_loss: 0.2784 - val_accuracy: 0.9317\n",
      "Epoch 81/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1012 - accuracy: 0.9741 - val_loss: 0.2756 - val_accuracy: 0.9284\n",
      "Epoch 82/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1056 - accuracy: 0.9733 - val_loss: 0.2768 - val_accuracy: 0.9294\n",
      "Epoch 83/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1035 - accuracy: 0.9742 - val_loss: 0.2787 - val_accuracy: 0.9292\n",
      "Epoch 84/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1025 - accuracy: 0.9744 - val_loss: 0.2781 - val_accuracy: 0.9282\n",
      "Epoch 85/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 0.2816 - val_accuracy: 0.9267\n",
      "Epoch 86/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1064 - accuracy: 0.9718 - val_loss: 0.2748 - val_accuracy: 0.9298\n",
      "Epoch 87/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1037 - accuracy: 0.9742 - val_loss: 0.2788 - val_accuracy: 0.9276\n",
      "Epoch 88/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1050 - accuracy: 0.9732 - val_loss: 0.2877 - val_accuracy: 0.9265\n",
      "Epoch 89/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1038 - accuracy: 0.9742 - val_loss: 0.2731 - val_accuracy: 0.9292\n",
      "Epoch 90/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1041 - accuracy: 0.9728 - val_loss: 0.2800 - val_accuracy: 0.9288\n",
      "Epoch 91/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 0.2812 - val_accuracy: 0.9296\n",
      "Epoch 92/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1046 - accuracy: 0.9726 - val_loss: 0.2758 - val_accuracy: 0.9286\n",
      "Epoch 93/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1028 - accuracy: 0.9745 - val_loss: 0.2792 - val_accuracy: 0.9305\n",
      "Epoch 94/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1027 - accuracy: 0.9741 - val_loss: 0.2865 - val_accuracy: 0.9249\n",
      "Epoch 95/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1031 - accuracy: 0.9741 - val_loss: 0.2831 - val_accuracy: 0.9271\n",
      "Epoch 96/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1004 - accuracy: 0.9743 - val_loss: 0.2824 - val_accuracy: 0.9261\n",
      "Epoch 97/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1031 - accuracy: 0.9742 - val_loss: 0.2817 - val_accuracy: 0.9274\n",
      "Epoch 98/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1038 - accuracy: 0.9740 - val_loss: 0.2767 - val_accuracy: 0.9309\n",
      "Epoch 99/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1014 - accuracy: 0.9760 - val_loss: 0.2835 - val_accuracy: 0.9280\n",
      "Epoch 100/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1065 - accuracy: 0.9721 - val_loss: 0.2826 - val_accuracy: 0.9257\n",
      "Epoch 101/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1022 - accuracy: 0.9746 - val_loss: 0.2784 - val_accuracy: 0.9307\n",
      "Epoch 102/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1041 - accuracy: 0.9746 - val_loss: 0.2865 - val_accuracy: 0.9267\n",
      "Epoch 103/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1013 - accuracy: 0.9749 - val_loss: 0.2819 - val_accuracy: 0.9282\n",
      "Epoch 104/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1018 - accuracy: 0.9742 - val_loss: 0.2811 - val_accuracy: 0.9303\n",
      "Epoch 105/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1041 - accuracy: 0.9740 - val_loss: 0.2793 - val_accuracy: 0.9309\n",
      "Epoch 106/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1010 - accuracy: 0.9737 - val_loss: 0.2831 - val_accuracy: 0.9294\n",
      "Epoch 107/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0998 - accuracy: 0.9749 - val_loss: 0.2814 - val_accuracy: 0.9284\n",
      "Epoch 108/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1000 - accuracy: 0.9754 - val_loss: 0.2835 - val_accuracy: 0.9307\n",
      "Epoch 109/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1006 - accuracy: 0.9751 - val_loss: 0.2861 - val_accuracy: 0.9290\n",
      "Epoch 110/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1030 - accuracy: 0.9744 - val_loss: 0.2797 - val_accuracy: 0.9303\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1042 - accuracy: 0.9741 - val_loss: 0.2893 - val_accuracy: 0.9271\n",
      "Epoch 112/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1016 - accuracy: 0.9744 - val_loss: 0.2884 - val_accuracy: 0.9259\n",
      "Epoch 113/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1039 - accuracy: 0.9739 - val_loss: 0.2888 - val_accuracy: 0.9274\n",
      "Epoch 114/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1054 - accuracy: 0.9734 - val_loss: 0.2721 - val_accuracy: 0.9303\n",
      "Epoch 115/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0980 - accuracy: 0.9757 - val_loss: 0.2869 - val_accuracy: 0.9303\n",
      "Epoch 116/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1029 - accuracy: 0.9742 - val_loss: 0.2880 - val_accuracy: 0.9276\n",
      "Epoch 117/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1031 - accuracy: 0.9736 - val_loss: 0.2890 - val_accuracy: 0.9288\n",
      "Epoch 118/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1025 - accuracy: 0.9744 - val_loss: 0.2779 - val_accuracy: 0.9290\n",
      "Epoch 119/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1001 - accuracy: 0.9758 - val_loss: 0.2905 - val_accuracy: 0.9292\n",
      "Epoch 120/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1014 - accuracy: 0.9743 - val_loss: 0.2834 - val_accuracy: 0.9282\n",
      "Epoch 121/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1015 - accuracy: 0.9751 - val_loss: 0.2923 - val_accuracy: 0.9288\n",
      "Epoch 122/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1040 - accuracy: 0.9745 - val_loss: 0.2863 - val_accuracy: 0.9269\n",
      "Epoch 123/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1048 - accuracy: 0.9736 - val_loss: 0.2804 - val_accuracy: 0.9303\n",
      "Epoch 124/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1036 - accuracy: 0.9735 - val_loss: 0.2795 - val_accuracy: 0.9315\n",
      "Epoch 125/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1038 - accuracy: 0.9739 - val_loss: 0.2782 - val_accuracy: 0.9296\n",
      "Epoch 126/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1014 - accuracy: 0.9743 - val_loss: 0.2806 - val_accuracy: 0.9282\n",
      "Epoch 127/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1010 - accuracy: 0.9737 - val_loss: 0.2840 - val_accuracy: 0.9282\n",
      "Epoch 128/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1026 - accuracy: 0.9740 - val_loss: 0.2809 - val_accuracy: 0.9288\n",
      "Epoch 129/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0995 - accuracy: 0.9756 - val_loss: 0.2927 - val_accuracy: 0.9278\n",
      "Epoch 130/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1031 - accuracy: 0.9742 - val_loss: 0.2839 - val_accuracy: 0.9271\n",
      "Epoch 131/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1005 - accuracy: 0.9743 - val_loss: 0.2780 - val_accuracy: 0.9313\n",
      "Epoch 132/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.1016 - accuracy: 0.9740 - val_loss: 0.2938 - val_accuracy: 0.9253\n",
      "Epoch 133/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1002 - accuracy: 0.9754 - val_loss: 0.2864 - val_accuracy: 0.9274\n",
      "Epoch 134/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0997 - accuracy: 0.9762 - val_loss: 0.2891 - val_accuracy: 0.9271\n",
      "Epoch 135/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1003 - accuracy: 0.9752 - val_loss: 0.2905 - val_accuracy: 0.9276\n",
      "Epoch 136/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0980 - accuracy: 0.9763 - val_loss: 0.2857 - val_accuracy: 0.9276\n",
      "Epoch 137/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1009 - accuracy: 0.9750 - val_loss: 0.2849 - val_accuracy: 0.9280\n",
      "Epoch 138/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0960 - accuracy: 0.9767 - val_loss: 0.2881 - val_accuracy: 0.9290\n",
      "Epoch 139/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0976 - accuracy: 0.9750 - val_loss: 0.2835 - val_accuracy: 0.9298\n",
      "Epoch 140/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0994 - accuracy: 0.9756 - val_loss: 0.2857 - val_accuracy: 0.9269\n",
      "Epoch 141/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0975 - accuracy: 0.9759 - val_loss: 0.2790 - val_accuracy: 0.9305\n",
      "Epoch 142/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0988 - accuracy: 0.9757 - val_loss: 0.2887 - val_accuracy: 0.9282\n",
      "Epoch 143/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1006 - accuracy: 0.9749 - val_loss: 0.2850 - val_accuracy: 0.9286\n",
      "Epoch 144/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0989 - accuracy: 0.9752 - val_loss: 0.2864 - val_accuracy: 0.9305\n",
      "Epoch 145/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0993 - accuracy: 0.9751 - val_loss: 0.2807 - val_accuracy: 0.9303\n",
      "Epoch 146/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0972 - accuracy: 0.9761 - val_loss: 0.2785 - val_accuracy: 0.9323\n",
      "Epoch 147/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0973 - accuracy: 0.9765 - val_loss: 0.2855 - val_accuracy: 0.9313\n",
      "Epoch 148/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0942 - accuracy: 0.9772 - val_loss: 0.2851 - val_accuracy: 0.9284\n",
      "Epoch 149/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0965 - accuracy: 0.9770 - val_loss: 0.2871 - val_accuracy: 0.9276\n",
      "Epoch 150/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0972 - accuracy: 0.9763 - val_loss: 0.2773 - val_accuracy: 0.9303\n",
      "Epoch 151/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0989 - accuracy: 0.9745 - val_loss: 0.2821 - val_accuracy: 0.9282\n",
      "Epoch 152/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0969 - accuracy: 0.9769 - val_loss: 0.2898 - val_accuracy: 0.9288\n",
      "Epoch 153/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.1019 - accuracy: 0.9753 - val_loss: 0.2839 - val_accuracy: 0.9301\n",
      "Epoch 154/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0990 - accuracy: 0.9759 - val_loss: 0.2866 - val_accuracy: 0.9288\n",
      "Epoch 155/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0955 - accuracy: 0.9772 - val_loss: 0.2858 - val_accuracy: 0.9286\n",
      "Epoch 156/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0970 - accuracy: 0.9766 - val_loss: 0.2880 - val_accuracy: 0.9296\n",
      "Epoch 157/500\n",
      "1205/1205 [==============================] - 17s 14ms/step - loss: 0.0979 - accuracy: 0.9764 - val_loss: 0.2809 - val_accuracy: 0.9265\n",
      "Epoch 158/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0977 - accuracy: 0.9756 - val_loss: 0.2818 - val_accuracy: 0.9311\n",
      "Epoch 159/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0976 - accuracy: 0.9763 - val_loss: 0.2776 - val_accuracy: 0.9311\n",
      "Epoch 160/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0994 - accuracy: 0.9751 - val_loss: 0.2813 - val_accuracy: 0.9294\n",
      "Epoch 161/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0954 - accuracy: 0.9771 - val_loss: 0.2871 - val_accuracy: 0.9303\n",
      "Epoch 162/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.1001 - accuracy: 0.9743 - val_loss: 0.2839 - val_accuracy: 0.9280\n",
      "Epoch 163/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0953 - accuracy: 0.9764 - val_loss: 0.2815 - val_accuracy: 0.9305\n",
      "Epoch 164/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0957 - accuracy: 0.9766 - val_loss: 0.2804 - val_accuracy: 0.9303\n",
      "Epoch 165/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0969 - accuracy: 0.9756 - val_loss: 0.2804 - val_accuracy: 0.9305\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0965 - accuracy: 0.9764 - val_loss: 0.2844 - val_accuracy: 0.9303\n",
      "Epoch 167/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0953 - accuracy: 0.9761 - val_loss: 0.2849 - val_accuracy: 0.9286\n",
      "Epoch 168/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0961 - accuracy: 0.9768 - val_loss: 0.2879 - val_accuracy: 0.9267\n",
      "Epoch 169/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0956 - accuracy: 0.9764 - val_loss: 0.2820 - val_accuracy: 0.9319\n",
      "Epoch 170/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0969 - accuracy: 0.9769 - val_loss: 0.2854 - val_accuracy: 0.9301\n",
      "Epoch 171/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0972 - accuracy: 0.9767 - val_loss: 0.2864 - val_accuracy: 0.9296\n",
      "Epoch 172/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0989 - accuracy: 0.9751 - val_loss: 0.2864 - val_accuracy: 0.9280\n",
      "Epoch 173/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0947 - accuracy: 0.9768 - val_loss: 0.2891 - val_accuracy: 0.9278\n",
      "Epoch 174/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0963 - accuracy: 0.9762 - val_loss: 0.2870 - val_accuracy: 0.9271\n",
      "Epoch 175/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0929 - accuracy: 0.9774 - val_loss: 0.2899 - val_accuracy: 0.9276\n",
      "Epoch 176/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0989 - accuracy: 0.9754 - val_loss: 0.2819 - val_accuracy: 0.9288\n",
      "Epoch 177/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0971 - accuracy: 0.9759 - val_loss: 0.2767 - val_accuracy: 0.9309\n",
      "Epoch 178/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0936 - accuracy: 0.9774 - val_loss: 0.2909 - val_accuracy: 0.9234\n",
      "Epoch 179/500\n",
      "1205/1205 [==============================] - 17s 15ms/step - loss: 0.0971 - accuracy: 0.9754 - val_loss: 0.2826 - val_accuracy: 0.9274\n",
      "Epoch 180/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0969 - accuracy: 0.9764 - val_loss: 0.2853 - val_accuracy: 0.9267\n",
      "Epoch 181/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0958 - accuracy: 0.9765 - val_loss: 0.2823 - val_accuracy: 0.9296\n",
      "Epoch 182/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0974 - accuracy: 0.9760 - val_loss: 0.2846 - val_accuracy: 0.9303\n",
      "Epoch 183/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0969 - accuracy: 0.9756 - val_loss: 0.2832 - val_accuracy: 0.9265\n",
      "Epoch 184/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0932 - accuracy: 0.9773 - val_loss: 0.2815 - val_accuracy: 0.9276\n",
      "Epoch 185/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0972 - accuracy: 0.9762 - val_loss: 0.2800 - val_accuracy: 0.9313\n",
      "Epoch 186/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0942 - accuracy: 0.9771 - val_loss: 0.2890 - val_accuracy: 0.9301\n",
      "Epoch 187/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0946 - accuracy: 0.9771 - val_loss: 0.2888 - val_accuracy: 0.9271\n",
      "Epoch 188/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0922 - accuracy: 0.9781 - val_loss: 0.2819 - val_accuracy: 0.9286\n",
      "Epoch 189/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0960 - accuracy: 0.9769 - val_loss: 0.2878 - val_accuracy: 0.9288\n",
      "Epoch 190/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0971 - accuracy: 0.9764 - val_loss: 0.2844 - val_accuracy: 0.9294\n",
      "Epoch 191/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0954 - accuracy: 0.9763 - val_loss: 0.2805 - val_accuracy: 0.9296\n",
      "Epoch 192/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0928 - accuracy: 0.9781 - val_loss: 0.2815 - val_accuracy: 0.9309\n",
      "Epoch 193/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0954 - accuracy: 0.9765 - val_loss: 0.2781 - val_accuracy: 0.9305\n",
      "Epoch 194/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0963 - accuracy: 0.9770 - val_loss: 0.2833 - val_accuracy: 0.9315\n",
      "Epoch 195/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0940 - accuracy: 0.9772 - val_loss: 0.2777 - val_accuracy: 0.9286\n",
      "Epoch 196/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0931 - accuracy: 0.9771 - val_loss: 0.2883 - val_accuracy: 0.9294\n",
      "Epoch 197/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0914 - accuracy: 0.9778 - val_loss: 0.2876 - val_accuracy: 0.9292\n",
      "Epoch 198/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0921 - accuracy: 0.9770 - val_loss: 0.2911 - val_accuracy: 0.9303\n",
      "Epoch 199/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0928 - accuracy: 0.9780 - val_loss: 0.2867 - val_accuracy: 0.9269\n",
      "Epoch 200/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0961 - accuracy: 0.9762 - val_loss: 0.2838 - val_accuracy: 0.9288\n",
      "Epoch 201/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0928 - accuracy: 0.9773 - val_loss: 0.2802 - val_accuracy: 0.9292\n",
      "Epoch 202/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0946 - accuracy: 0.9770 - val_loss: 0.2866 - val_accuracy: 0.9298\n",
      "Epoch 203/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0950 - accuracy: 0.9773 - val_loss: 0.2846 - val_accuracy: 0.9278\n",
      "Epoch 204/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0941 - accuracy: 0.9764 - val_loss: 0.2812 - val_accuracy: 0.9284\n",
      "Epoch 205/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0947 - accuracy: 0.9777 - val_loss: 0.2869 - val_accuracy: 0.9280\n",
      "Epoch 206/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0958 - accuracy: 0.9773 - val_loss: 0.2909 - val_accuracy: 0.9276\n",
      "Epoch 207/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0949 - accuracy: 0.9768 - val_loss: 0.2785 - val_accuracy: 0.9319\n",
      "Epoch 208/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0935 - accuracy: 0.9772 - val_loss: 0.2775 - val_accuracy: 0.9311\n",
      "Epoch 209/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0937 - accuracy: 0.9774 - val_loss: 0.2859 - val_accuracy: 0.9292\n",
      "Epoch 210/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0913 - accuracy: 0.9785 - val_loss: 0.2808 - val_accuracy: 0.9313\n",
      "Epoch 211/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0938 - accuracy: 0.9770 - val_loss: 0.2800 - val_accuracy: 0.9282\n",
      "Epoch 212/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0927 - accuracy: 0.9776 - val_loss: 0.2816 - val_accuracy: 0.9286\n",
      "Epoch 213/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0939 - accuracy: 0.9773 - val_loss: 0.2790 - val_accuracy: 0.9296\n",
      "Epoch 214/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0943 - accuracy: 0.9771 - val_loss: 0.2826 - val_accuracy: 0.9276\n",
      "Epoch 215/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0923 - accuracy: 0.9781 - val_loss: 0.2880 - val_accuracy: 0.9276\n",
      "Epoch 216/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0923 - accuracy: 0.9778 - val_loss: 0.2870 - val_accuracy: 0.9292\n",
      "Epoch 217/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0954 - accuracy: 0.9764 - val_loss: 0.2865 - val_accuracy: 0.9313\n",
      "Epoch 218/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0917 - accuracy: 0.9775 - val_loss: 0.2913 - val_accuracy: 0.9280\n",
      "Epoch 219/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0942 - accuracy: 0.9765 - val_loss: 0.2900 - val_accuracy: 0.9276\n",
      "Epoch 220/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0921 - accuracy: 0.9781 - val_loss: 0.2731 - val_accuracy: 0.9305\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0967 - accuracy: 0.9768 - val_loss: 0.2850 - val_accuracy: 0.9286\n",
      "Epoch 222/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0947 - accuracy: 0.9772 - val_loss: 0.2841 - val_accuracy: 0.9301\n",
      "Epoch 223/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0940 - accuracy: 0.9767 - val_loss: 0.2813 - val_accuracy: 0.9325\n",
      "Epoch 224/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0919 - accuracy: 0.9780 - val_loss: 0.2885 - val_accuracy: 0.9294\n",
      "Epoch 225/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0936 - accuracy: 0.9768 - val_loss: 0.2905 - val_accuracy: 0.9280\n",
      "Epoch 226/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0935 - accuracy: 0.9783 - val_loss: 0.2902 - val_accuracy: 0.9282\n",
      "Epoch 227/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0960 - accuracy: 0.9766 - val_loss: 0.2842 - val_accuracy: 0.9288\n",
      "Epoch 228/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0906 - accuracy: 0.9785 - val_loss: 0.2922 - val_accuracy: 0.9276\n",
      "Epoch 229/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0925 - accuracy: 0.9781 - val_loss: 0.2930 - val_accuracy: 0.9263\n",
      "Epoch 230/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0932 - accuracy: 0.9771 - val_loss: 0.2853 - val_accuracy: 0.9288\n",
      "Epoch 231/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0881 - accuracy: 0.9797 - val_loss: 0.2927 - val_accuracy: 0.9269\n",
      "Epoch 232/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0934 - accuracy: 0.9774 - val_loss: 0.2844 - val_accuracy: 0.9274\n",
      "Epoch 233/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0921 - accuracy: 0.9774 - val_loss: 0.2839 - val_accuracy: 0.9284\n",
      "Epoch 234/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0916 - accuracy: 0.9785 - val_loss: 0.2876 - val_accuracy: 0.9315\n",
      "Epoch 235/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0920 - accuracy: 0.9778 - val_loss: 0.2916 - val_accuracy: 0.9263\n",
      "Epoch 236/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0920 - accuracy: 0.9783 - val_loss: 0.2895 - val_accuracy: 0.9274\n",
      "Epoch 237/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0892 - accuracy: 0.9790 - val_loss: 0.2786 - val_accuracy: 0.9296\n",
      "Epoch 238/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0898 - accuracy: 0.9779 - val_loss: 0.2816 - val_accuracy: 0.9292\n",
      "Epoch 239/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0917 - accuracy: 0.9782 - val_loss: 0.2825 - val_accuracy: 0.9307\n",
      "Epoch 240/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0923 - accuracy: 0.9779 - val_loss: 0.2909 - val_accuracy: 0.9271\n",
      "Epoch 241/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0935 - accuracy: 0.9772 - val_loss: 0.2934 - val_accuracy: 0.9259\n",
      "Epoch 242/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0913 - accuracy: 0.9780 - val_loss: 0.2806 - val_accuracy: 0.9298\n",
      "Epoch 243/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0911 - accuracy: 0.9782 - val_loss: 0.2856 - val_accuracy: 0.9284\n",
      "Epoch 244/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0923 - accuracy: 0.9780 - val_loss: 0.2875 - val_accuracy: 0.9282\n",
      "Epoch 245/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0907 - accuracy: 0.9786 - val_loss: 0.2914 - val_accuracy: 0.9267\n",
      "Epoch 246/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0908 - accuracy: 0.9780 - val_loss: 0.2921 - val_accuracy: 0.9263\n",
      "Epoch 247/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0884 - accuracy: 0.9794 - val_loss: 0.2844 - val_accuracy: 0.9274\n",
      "Epoch 248/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0908 - accuracy: 0.9791 - val_loss: 0.2870 - val_accuracy: 0.9280\n",
      "Epoch 249/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0917 - accuracy: 0.9784 - val_loss: 0.2943 - val_accuracy: 0.9284\n",
      "Epoch 250/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0925 - accuracy: 0.9776 - val_loss: 0.2902 - val_accuracy: 0.9288\n",
      "Epoch 251/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0930 - accuracy: 0.9773 - val_loss: 0.2805 - val_accuracy: 0.9311\n",
      "Epoch 252/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0923 - accuracy: 0.9777 - val_loss: 0.2789 - val_accuracy: 0.9313\n",
      "Epoch 253/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0930 - accuracy: 0.9770 - val_loss: 0.2815 - val_accuracy: 0.9288\n",
      "Epoch 254/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0913 - accuracy: 0.9783 - val_loss: 0.2844 - val_accuracy: 0.9298\n",
      "Epoch 255/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0866 - accuracy: 0.9799 - val_loss: 0.2906 - val_accuracy: 0.9292\n",
      "Epoch 256/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0912 - accuracy: 0.9777 - val_loss: 0.2889 - val_accuracy: 0.9290\n",
      "Epoch 257/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0881 - accuracy: 0.9795 - val_loss: 0.2905 - val_accuracy: 0.9290\n",
      "Epoch 258/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0902 - accuracy: 0.9789 - val_loss: 0.2907 - val_accuracy: 0.9278\n",
      "Epoch 259/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0902 - accuracy: 0.9791 - val_loss: 0.2893 - val_accuracy: 0.9288\n",
      "Epoch 260/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0920 - accuracy: 0.9777 - val_loss: 0.2943 - val_accuracy: 0.9288\n",
      "Epoch 261/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0904 - accuracy: 0.9784 - val_loss: 0.2857 - val_accuracy: 0.9255\n",
      "Epoch 262/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0888 - accuracy: 0.9790 - val_loss: 0.2851 - val_accuracy: 0.9305\n",
      "Epoch 263/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0879 - accuracy: 0.9799 - val_loss: 0.2894 - val_accuracy: 0.9292\n",
      "Epoch 264/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0892 - accuracy: 0.9790 - val_loss: 0.2891 - val_accuracy: 0.9280\n",
      "Epoch 265/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0915 - accuracy: 0.9780 - val_loss: 0.2905 - val_accuracy: 0.9282\n",
      "Epoch 266/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0922 - accuracy: 0.9775 - val_loss: 0.2815 - val_accuracy: 0.9332\n",
      "Epoch 267/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0881 - accuracy: 0.9800 - val_loss: 0.2785 - val_accuracy: 0.9303\n",
      "Epoch 268/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0922 - accuracy: 0.9777 - val_loss: 0.2941 - val_accuracy: 0.9280\n",
      "Epoch 269/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0886 - accuracy: 0.9788 - val_loss: 0.2928 - val_accuracy: 0.9271\n",
      "Epoch 270/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0884 - accuracy: 0.9789 - val_loss: 0.2862 - val_accuracy: 0.9298\n",
      "Epoch 271/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0885 - accuracy: 0.9794 - val_loss: 0.2792 - val_accuracy: 0.9301\n",
      "Epoch 272/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0858 - accuracy: 0.9792 - val_loss: 0.2844 - val_accuracy: 0.9298\n",
      "Epoch 273/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0872 - accuracy: 0.9799 - val_loss: 0.2864 - val_accuracy: 0.9301\n",
      "Epoch 274/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0874 - accuracy: 0.9794 - val_loss: 0.2965 - val_accuracy: 0.9280\n",
      "Epoch 275/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0887 - accuracy: 0.9781 - val_loss: 0.2896 - val_accuracy: 0.9282\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0889 - accuracy: 0.9786 - val_loss: 0.2792 - val_accuracy: 0.9296\n",
      "Epoch 277/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0899 - accuracy: 0.9789 - val_loss: 0.2788 - val_accuracy: 0.9307\n",
      "Epoch 278/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0858 - accuracy: 0.9795 - val_loss: 0.2814 - val_accuracy: 0.9290\n",
      "Epoch 279/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0858 - accuracy: 0.9793 - val_loss: 0.2931 - val_accuracy: 0.9267\n",
      "Epoch 280/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0875 - accuracy: 0.9790 - val_loss: 0.2903 - val_accuracy: 0.9301\n",
      "Epoch 281/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0886 - accuracy: 0.9783 - val_loss: 0.2813 - val_accuracy: 0.9309\n",
      "Epoch 282/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0873 - accuracy: 0.9792 - val_loss: 0.2884 - val_accuracy: 0.9294\n",
      "Epoch 283/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0904 - accuracy: 0.9789 - val_loss: 0.2897 - val_accuracy: 0.9301\n",
      "Epoch 284/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0875 - accuracy: 0.9790 - val_loss: 0.2865 - val_accuracy: 0.9280\n",
      "Epoch 285/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0868 - accuracy: 0.9797 - val_loss: 0.2835 - val_accuracy: 0.9276\n",
      "Epoch 286/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0898 - accuracy: 0.9781 - val_loss: 0.2926 - val_accuracy: 0.9244\n",
      "Epoch 287/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0897 - accuracy: 0.9785 - val_loss: 0.2895 - val_accuracy: 0.9280\n",
      "Epoch 288/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0885 - accuracy: 0.9786 - val_loss: 0.2864 - val_accuracy: 0.9309\n",
      "Epoch 289/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0873 - accuracy: 0.9793 - val_loss: 0.2847 - val_accuracy: 0.9294\n",
      "Epoch 290/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0866 - accuracy: 0.9796 - val_loss: 0.2935 - val_accuracy: 0.9259\n",
      "Epoch 291/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0885 - accuracy: 0.9788 - val_loss: 0.2863 - val_accuracy: 0.9282\n",
      "Epoch 292/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0872 - accuracy: 0.9796 - val_loss: 0.2872 - val_accuracy: 0.9288\n",
      "Epoch 293/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0877 - accuracy: 0.9784 - val_loss: 0.2924 - val_accuracy: 0.9278\n",
      "Epoch 294/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0881 - accuracy: 0.9795 - val_loss: 0.2945 - val_accuracy: 0.9290\n",
      "Epoch 295/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0883 - accuracy: 0.9793 - val_loss: 0.2905 - val_accuracy: 0.9290\n",
      "Epoch 296/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0863 - accuracy: 0.9802 - val_loss: 0.2949 - val_accuracy: 0.9249\n",
      "Epoch 297/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0867 - accuracy: 0.9796 - val_loss: 0.2879 - val_accuracy: 0.9294\n",
      "Epoch 298/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0878 - accuracy: 0.9799 - val_loss: 0.2871 - val_accuracy: 0.9301\n",
      "Epoch 299/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0841 - accuracy: 0.9810 - val_loss: 0.2840 - val_accuracy: 0.9311\n",
      "Epoch 300/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0867 - accuracy: 0.9788 - val_loss: 0.2900 - val_accuracy: 0.9274\n",
      "Epoch 301/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0862 - accuracy: 0.9801 - val_loss: 0.2961 - val_accuracy: 0.9282\n",
      "Epoch 302/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0848 - accuracy: 0.9810 - val_loss: 0.2882 - val_accuracy: 0.9282\n",
      "Epoch 303/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0878 - accuracy: 0.9801 - val_loss: 0.2951 - val_accuracy: 0.9286\n",
      "Epoch 304/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0861 - accuracy: 0.9795 - val_loss: 0.2857 - val_accuracy: 0.9290\n",
      "Epoch 305/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0890 - accuracy: 0.9788 - val_loss: 0.2896 - val_accuracy: 0.9290\n",
      "Epoch 306/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0851 - accuracy: 0.9803 - val_loss: 0.2861 - val_accuracy: 0.9290\n",
      "Epoch 307/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0833 - accuracy: 0.9813 - val_loss: 0.2942 - val_accuracy: 0.9274\n",
      "Epoch 308/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0848 - accuracy: 0.9809 - val_loss: 0.2930 - val_accuracy: 0.9269\n",
      "Epoch 309/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0908 - accuracy: 0.9778 - val_loss: 0.2943 - val_accuracy: 0.9251\n",
      "Epoch 310/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0847 - accuracy: 0.9816 - val_loss: 0.2946 - val_accuracy: 0.9278\n",
      "Epoch 311/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0871 - accuracy: 0.9796 - val_loss: 0.2934 - val_accuracy: 0.9276\n",
      "Epoch 312/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0852 - accuracy: 0.9805 - val_loss: 0.3006 - val_accuracy: 0.9263\n",
      "Epoch 313/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0872 - accuracy: 0.9794 - val_loss: 0.3010 - val_accuracy: 0.9263\n",
      "Epoch 314/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0869 - accuracy: 0.9799 - val_loss: 0.2925 - val_accuracy: 0.9249\n",
      "Epoch 315/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0876 - accuracy: 0.9790 - val_loss: 0.2967 - val_accuracy: 0.9294\n",
      "Epoch 316/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0868 - accuracy: 0.9799 - val_loss: 0.2958 - val_accuracy: 0.9265\n",
      "Epoch 317/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0817 - accuracy: 0.9814 - val_loss: 0.2963 - val_accuracy: 0.9301\n",
      "Epoch 318/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0862 - accuracy: 0.9796 - val_loss: 0.2925 - val_accuracy: 0.9263\n",
      "Epoch 319/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0849 - accuracy: 0.9798 - val_loss: 0.2944 - val_accuracy: 0.9286\n",
      "Epoch 320/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0843 - accuracy: 0.9811 - val_loss: 0.2942 - val_accuracy: 0.9259\n",
      "Epoch 321/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0850 - accuracy: 0.9804 - val_loss: 0.2866 - val_accuracy: 0.9294\n",
      "Epoch 322/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0829 - accuracy: 0.9810 - val_loss: 0.2915 - val_accuracy: 0.9298\n",
      "Epoch 323/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0845 - accuracy: 0.9796 - val_loss: 0.2847 - val_accuracy: 0.9278\n",
      "Epoch 324/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0848 - accuracy: 0.9798 - val_loss: 0.2883 - val_accuracy: 0.9305\n",
      "Epoch 325/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0863 - accuracy: 0.9797 - val_loss: 0.2955 - val_accuracy: 0.9298\n",
      "Epoch 326/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0838 - accuracy: 0.9806 - val_loss: 0.2945 - val_accuracy: 0.9286\n",
      "Epoch 327/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0808 - accuracy: 0.9815 - val_loss: 0.2950 - val_accuracy: 0.9298\n",
      "Epoch 328/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0844 - accuracy: 0.9809 - val_loss: 0.2810 - val_accuracy: 0.9296\n",
      "Epoch 329/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0855 - accuracy: 0.9803 - val_loss: 0.2912 - val_accuracy: 0.9315\n",
      "Epoch 330/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0826 - accuracy: 0.9810 - val_loss: 0.2866 - val_accuracy: 0.9288\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0846 - accuracy: 0.9803 - val_loss: 0.2855 - val_accuracy: 0.9313\n",
      "Epoch 332/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0847 - accuracy: 0.9807 - val_loss: 0.2838 - val_accuracy: 0.9313\n",
      "Epoch 333/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0844 - accuracy: 0.9797 - val_loss: 0.2909 - val_accuracy: 0.9280\n",
      "Epoch 334/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0824 - accuracy: 0.9809 - val_loss: 0.2944 - val_accuracy: 0.9284\n",
      "Epoch 335/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0840 - accuracy: 0.9806 - val_loss: 0.2978 - val_accuracy: 0.9267\n",
      "Epoch 336/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0820 - accuracy: 0.9809 - val_loss: 0.2828 - val_accuracy: 0.9292\n",
      "Epoch 337/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0805 - accuracy: 0.9822 - val_loss: 0.2945 - val_accuracy: 0.9265\n",
      "Epoch 338/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0830 - accuracy: 0.9811 - val_loss: 0.2922 - val_accuracy: 0.9278\n",
      "Epoch 339/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0806 - accuracy: 0.9824 - val_loss: 0.2866 - val_accuracy: 0.9296\n",
      "Epoch 340/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0804 - accuracy: 0.9826 - val_loss: 0.2905 - val_accuracy: 0.9278\n",
      "Epoch 341/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0803 - accuracy: 0.9817 - val_loss: 0.2908 - val_accuracy: 0.9278\n",
      "Epoch 342/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0780 - accuracy: 0.9826 - val_loss: 0.2986 - val_accuracy: 0.9274\n",
      "Epoch 343/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0803 - accuracy: 0.9824 - val_loss: 0.2958 - val_accuracy: 0.9294\n",
      "Epoch 344/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0802 - accuracy: 0.9825 - val_loss: 0.2927 - val_accuracy: 0.9305\n",
      "Epoch 345/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0775 - accuracy: 0.9833 - val_loss: 0.2969 - val_accuracy: 0.9294\n",
      "Epoch 346/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0796 - accuracy: 0.9821 - val_loss: 0.2925 - val_accuracy: 0.9296\n",
      "Epoch 347/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0802 - accuracy: 0.9823 - val_loss: 0.2900 - val_accuracy: 0.9296\n",
      "Epoch 348/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0781 - accuracy: 0.9828 - val_loss: 0.2878 - val_accuracy: 0.9282\n",
      "Epoch 349/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0782 - accuracy: 0.9829 - val_loss: 0.2935 - val_accuracy: 0.9265\n",
      "Epoch 350/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0795 - accuracy: 0.9822 - val_loss: 0.2928 - val_accuracy: 0.9276\n",
      "Epoch 351/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0780 - accuracy: 0.9828 - val_loss: 0.2920 - val_accuracy: 0.9280\n",
      "Epoch 352/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0761 - accuracy: 0.9840 - val_loss: 0.2949 - val_accuracy: 0.9280\n",
      "Epoch 353/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0978 - accuracy: 0.9761 - val_loss: 0.2924 - val_accuracy: 0.9284\n",
      "Epoch 354/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0942 - accuracy: 0.9770 - val_loss: 0.2898 - val_accuracy: 0.9263\n",
      "Epoch 355/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0948 - accuracy: 0.9773 - val_loss: 0.2931 - val_accuracy: 0.9301\n",
      "Epoch 356/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0937 - accuracy: 0.9775 - val_loss: 0.2893 - val_accuracy: 0.9284\n",
      "Epoch 357/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0997 - accuracy: 0.9758 - val_loss: 0.2885 - val_accuracy: 0.9282\n",
      "Epoch 358/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0962 - accuracy: 0.9766 - val_loss: 0.2989 - val_accuracy: 0.9244\n",
      "Epoch 359/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0945 - accuracy: 0.9774 - val_loss: 0.2971 - val_accuracy: 0.9269\n",
      "Epoch 360/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0969 - accuracy: 0.9765 - val_loss: 0.2953 - val_accuracy: 0.9267\n",
      "Epoch 361/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0927 - accuracy: 0.9779 - val_loss: 0.2843 - val_accuracy: 0.9269\n",
      "Epoch 362/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0931 - accuracy: 0.9771 - val_loss: 0.2920 - val_accuracy: 0.9276\n",
      "Epoch 363/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0946 - accuracy: 0.9766 - val_loss: 0.2855 - val_accuracy: 0.9292\n",
      "Epoch 364/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0949 - accuracy: 0.9763 - val_loss: 0.2894 - val_accuracy: 0.9280\n",
      "Epoch 365/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0941 - accuracy: 0.9765 - val_loss: 0.2844 - val_accuracy: 0.9278\n",
      "Epoch 366/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0928 - accuracy: 0.9769 - val_loss: 0.2922 - val_accuracy: 0.9278\n",
      "Epoch 367/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0961 - accuracy: 0.9766 - val_loss: 0.2911 - val_accuracy: 0.9265\n",
      "Epoch 368/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0937 - accuracy: 0.9772 - val_loss: 0.2904 - val_accuracy: 0.9292\n",
      "Epoch 369/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0991 - accuracy: 0.9750 - val_loss: 0.2850 - val_accuracy: 0.9276\n",
      "Epoch 370/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0964 - accuracy: 0.9752 - val_loss: 0.2832 - val_accuracy: 0.9282\n",
      "Epoch 371/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0954 - accuracy: 0.9772 - val_loss: 0.2925 - val_accuracy: 0.9253\n",
      "Epoch 372/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0941 - accuracy: 0.9770 - val_loss: 0.2882 - val_accuracy: 0.9288\n",
      "Epoch 373/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0961 - accuracy: 0.9768 - val_loss: 0.2913 - val_accuracy: 0.9276\n",
      "Epoch 374/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0959 - accuracy: 0.9758 - val_loss: 0.2869 - val_accuracy: 0.9255\n",
      "Epoch 375/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0950 - accuracy: 0.9759 - val_loss: 0.2947 - val_accuracy: 0.9274\n",
      "Epoch 376/500\n",
      "1205/1205 [==============================] - 17s 14ms/step - loss: 0.0915 - accuracy: 0.9769 - val_loss: 0.2890 - val_accuracy: 0.9298\n",
      "Epoch 377/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0955 - accuracy: 0.9772 - val_loss: 0.2809 - val_accuracy: 0.9280\n",
      "Epoch 378/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0938 - accuracy: 0.9773 - val_loss: 0.2954 - val_accuracy: 0.9292\n",
      "Epoch 379/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0938 - accuracy: 0.9772 - val_loss: 0.2986 - val_accuracy: 0.9269\n",
      "Epoch 380/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0903 - accuracy: 0.9780 - val_loss: 0.3006 - val_accuracy: 0.9267\n",
      "Epoch 381/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0959 - accuracy: 0.9771 - val_loss: 0.2881 - val_accuracy: 0.9290\n",
      "Epoch 382/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0912 - accuracy: 0.9779 - val_loss: 0.2965 - val_accuracy: 0.9265\n",
      "Epoch 383/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0964 - accuracy: 0.9758 - val_loss: 0.3003 - val_accuracy: 0.9267\n",
      "Epoch 384/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0935 - accuracy: 0.9768 - val_loss: 0.2869 - val_accuracy: 0.9288\n",
      "Epoch 385/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0914 - accuracy: 0.9792 - val_loss: 0.2937 - val_accuracy: 0.9274\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0950 - accuracy: 0.9766 - val_loss: 0.2910 - val_accuracy: 0.9274\n",
      "Epoch 387/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0942 - accuracy: 0.9771 - val_loss: 0.3027 - val_accuracy: 0.9259\n",
      "Epoch 388/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0921 - accuracy: 0.9784 - val_loss: 0.2846 - val_accuracy: 0.9309\n",
      "Epoch 389/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0923 - accuracy: 0.9777 - val_loss: 0.2886 - val_accuracy: 0.9294\n",
      "Epoch 390/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0938 - accuracy: 0.9777 - val_loss: 0.2906 - val_accuracy: 0.9265\n",
      "Epoch 391/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0934 - accuracy: 0.9771 - val_loss: 0.2894 - val_accuracy: 0.9307\n",
      "Epoch 392/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0951 - accuracy: 0.9771 - val_loss: 0.2867 - val_accuracy: 0.9303\n",
      "Epoch 393/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0940 - accuracy: 0.9766 - val_loss: 0.2844 - val_accuracy: 0.9288\n",
      "Epoch 394/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0895 - accuracy: 0.9777 - val_loss: 0.2891 - val_accuracy: 0.9286\n",
      "Epoch 395/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0960 - accuracy: 0.9765 - val_loss: 0.3000 - val_accuracy: 0.9269\n",
      "Epoch 396/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0909 - accuracy: 0.9777 - val_loss: 0.2821 - val_accuracy: 0.9313\n",
      "Epoch 397/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0898 - accuracy: 0.9785 - val_loss: 0.2893 - val_accuracy: 0.9271\n",
      "Epoch 398/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0934 - accuracy: 0.9769 - val_loss: 0.2885 - val_accuracy: 0.9265\n",
      "Epoch 399/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0933 - accuracy: 0.9776 - val_loss: 0.2897 - val_accuracy: 0.9284\n",
      "Epoch 400/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0957 - accuracy: 0.9765 - val_loss: 0.2800 - val_accuracy: 0.9321\n",
      "Epoch 401/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0967 - accuracy: 0.9761 - val_loss: 0.2895 - val_accuracy: 0.9253\n",
      "Epoch 402/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0936 - accuracy: 0.9773 - val_loss: 0.2965 - val_accuracy: 0.9288\n",
      "Epoch 403/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0940 - accuracy: 0.9775 - val_loss: 0.2931 - val_accuracy: 0.9288\n",
      "Epoch 404/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0903 - accuracy: 0.9781 - val_loss: 0.2953 - val_accuracy: 0.9278\n",
      "Epoch 405/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0966 - accuracy: 0.9767 - val_loss: 0.2828 - val_accuracy: 0.9296\n",
      "Epoch 406/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0905 - accuracy: 0.9784 - val_loss: 0.2903 - val_accuracy: 0.9292\n",
      "Epoch 407/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0904 - accuracy: 0.9784 - val_loss: 0.2882 - val_accuracy: 0.9269\n",
      "Epoch 408/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0919 - accuracy: 0.9780 - val_loss: 0.2911 - val_accuracy: 0.9278\n",
      "Epoch 409/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0931 - accuracy: 0.9779 - val_loss: 0.2913 - val_accuracy: 0.9278\n",
      "Epoch 410/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0958 - accuracy: 0.9763 - val_loss: 0.2864 - val_accuracy: 0.9276\n",
      "Epoch 411/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0949 - accuracy: 0.9768 - val_loss: 0.2942 - val_accuracy: 0.9257\n",
      "Epoch 412/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0929 - accuracy: 0.9771 - val_loss: 0.2897 - val_accuracy: 0.9307\n",
      "Epoch 413/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0938 - accuracy: 0.9770 - val_loss: 0.2878 - val_accuracy: 0.9303\n",
      "Epoch 414/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0966 - accuracy: 0.9756 - val_loss: 0.2916 - val_accuracy: 0.9280\n",
      "Epoch 415/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0933 - accuracy: 0.9769 - val_loss: 0.2961 - val_accuracy: 0.9288\n",
      "Epoch 416/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0921 - accuracy: 0.9775 - val_loss: 0.2923 - val_accuracy: 0.9284\n",
      "Epoch 417/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0958 - accuracy: 0.9774 - val_loss: 0.2892 - val_accuracy: 0.9286\n",
      "Epoch 418/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0939 - accuracy: 0.9769 - val_loss: 0.2896 - val_accuracy: 0.9259\n",
      "Epoch 419/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0950 - accuracy: 0.9776 - val_loss: 0.2884 - val_accuracy: 0.9288\n",
      "Epoch 420/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0951 - accuracy: 0.9763 - val_loss: 0.2844 - val_accuracy: 0.9280\n",
      "Epoch 421/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0923 - accuracy: 0.9778 - val_loss: 0.2816 - val_accuracy: 0.9301\n",
      "Epoch 422/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0917 - accuracy: 0.9784 - val_loss: 0.2904 - val_accuracy: 0.9271\n",
      "Epoch 423/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0933 - accuracy: 0.9779 - val_loss: 0.2907 - val_accuracy: 0.9284\n",
      "Epoch 424/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0912 - accuracy: 0.9782 - val_loss: 0.2964 - val_accuracy: 0.9265\n",
      "Epoch 425/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0922 - accuracy: 0.9775 - val_loss: 0.2898 - val_accuracy: 0.9292\n",
      "Epoch 426/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0918 - accuracy: 0.9772 - val_loss: 0.2939 - val_accuracy: 0.9282\n",
      "Epoch 427/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0938 - accuracy: 0.9778 - val_loss: 0.2842 - val_accuracy: 0.9280\n",
      "Epoch 428/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0886 - accuracy: 0.9790 - val_loss: 0.2868 - val_accuracy: 0.9267\n",
      "Epoch 429/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0930 - accuracy: 0.9776 - val_loss: 0.2857 - val_accuracy: 0.9286\n",
      "Epoch 430/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0954 - accuracy: 0.9762 - val_loss: 0.2887 - val_accuracy: 0.9282\n",
      "Epoch 431/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0931 - accuracy: 0.9772 - val_loss: 0.2847 - val_accuracy: 0.9282\n",
      "Epoch 432/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0960 - accuracy: 0.9765 - val_loss: 0.2846 - val_accuracy: 0.9294\n",
      "Epoch 433/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0921 - accuracy: 0.9785 - val_loss: 0.2962 - val_accuracy: 0.9253\n",
      "Epoch 434/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0903 - accuracy: 0.9792 - val_loss: 0.2889 - val_accuracy: 0.9284\n",
      "Epoch 435/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0918 - accuracy: 0.9781 - val_loss: 0.2859 - val_accuracy: 0.9309\n",
      "Epoch 436/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0917 - accuracy: 0.9778 - val_loss: 0.2933 - val_accuracy: 0.9284\n",
      "Epoch 437/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0928 - accuracy: 0.9778 - val_loss: 0.2973 - val_accuracy: 0.9271\n",
      "Epoch 438/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0937 - accuracy: 0.9767 - val_loss: 0.2923 - val_accuracy: 0.9307\n",
      "Epoch 439/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0938 - accuracy: 0.9782 - val_loss: 0.2924 - val_accuracy: 0.9282\n",
      "Epoch 440/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0928 - accuracy: 0.9777 - val_loss: 0.2882 - val_accuracy: 0.9259\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0919 - accuracy: 0.9776 - val_loss: 0.2898 - val_accuracy: 0.9301\n",
      "Epoch 442/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0924 - accuracy: 0.9775 - val_loss: 0.2942 - val_accuracy: 0.9280\n",
      "Epoch 443/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0888 - accuracy: 0.9785 - val_loss: 0.2876 - val_accuracy: 0.9303\n",
      "Epoch 444/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0918 - accuracy: 0.9778 - val_loss: 0.3002 - val_accuracy: 0.9294\n",
      "Epoch 445/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0949 - accuracy: 0.9765 - val_loss: 0.2827 - val_accuracy: 0.9303\n",
      "Epoch 446/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0894 - accuracy: 0.9790 - val_loss: 0.2975 - val_accuracy: 0.9288\n",
      "Epoch 447/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0931 - accuracy: 0.9781 - val_loss: 0.2938 - val_accuracy: 0.9288\n",
      "Epoch 448/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0951 - accuracy: 0.9770 - val_loss: 0.2941 - val_accuracy: 0.9276\n",
      "Epoch 449/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0942 - accuracy: 0.9772 - val_loss: 0.2908 - val_accuracy: 0.9298\n",
      "Epoch 450/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0911 - accuracy: 0.9783 - val_loss: 0.2968 - val_accuracy: 0.9292\n",
      "Epoch 451/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0910 - accuracy: 0.9787 - val_loss: 0.2942 - val_accuracy: 0.9263\n",
      "Epoch 452/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0897 - accuracy: 0.9789 - val_loss: 0.2917 - val_accuracy: 0.9265\n",
      "Epoch 453/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0929 - accuracy: 0.9778 - val_loss: 0.2920 - val_accuracy: 0.9280\n",
      "Epoch 454/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0926 - accuracy: 0.9782 - val_loss: 0.2945 - val_accuracy: 0.9265\n",
      "Epoch 455/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0942 - accuracy: 0.9774 - val_loss: 0.2853 - val_accuracy: 0.9286\n",
      "Epoch 456/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0931 - accuracy: 0.9780 - val_loss: 0.2962 - val_accuracy: 0.9261\n",
      "Epoch 457/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0899 - accuracy: 0.9784 - val_loss: 0.2796 - val_accuracy: 0.9286\n",
      "Epoch 458/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0940 - accuracy: 0.9779 - val_loss: 0.2870 - val_accuracy: 0.9280\n",
      "Epoch 459/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0926 - accuracy: 0.9775 - val_loss: 0.2865 - val_accuracy: 0.9296\n",
      "Epoch 460/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0930 - accuracy: 0.9781 - val_loss: 0.2904 - val_accuracy: 0.9278\n",
      "Epoch 461/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0910 - accuracy: 0.9784 - val_loss: 0.2853 - val_accuracy: 0.9296\n",
      "Epoch 462/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0922 - accuracy: 0.9774 - val_loss: 0.2865 - val_accuracy: 0.9286\n",
      "Epoch 463/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0912 - accuracy: 0.9782 - val_loss: 0.2889 - val_accuracy: 0.9282\n",
      "Epoch 464/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0916 - accuracy: 0.9783 - val_loss: 0.2825 - val_accuracy: 0.9292\n",
      "Epoch 465/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0910 - accuracy: 0.9787 - val_loss: 0.2868 - val_accuracy: 0.9311\n",
      "Epoch 466/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0920 - accuracy: 0.9772 - val_loss: 0.2999 - val_accuracy: 0.9276\n",
      "Epoch 467/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0910 - accuracy: 0.9780 - val_loss: 0.2863 - val_accuracy: 0.9288\n",
      "Epoch 468/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0933 - accuracy: 0.9768 - val_loss: 0.2906 - val_accuracy: 0.9274\n",
      "Epoch 469/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0921 - accuracy: 0.9781 - val_loss: 0.2903 - val_accuracy: 0.9290\n",
      "Epoch 470/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0910 - accuracy: 0.9775 - val_loss: 0.2893 - val_accuracy: 0.9294\n",
      "Epoch 471/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0914 - accuracy: 0.9778 - val_loss: 0.2939 - val_accuracy: 0.9278\n",
      "Epoch 472/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0901 - accuracy: 0.9790 - val_loss: 0.2845 - val_accuracy: 0.9311\n",
      "Epoch 473/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0935 - accuracy: 0.9768 - val_loss: 0.2883 - val_accuracy: 0.9303\n",
      "Epoch 474/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0920 - accuracy: 0.9786 - val_loss: 0.2838 - val_accuracy: 0.9292\n",
      "Epoch 475/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0952 - accuracy: 0.9762 - val_loss: 0.2810 - val_accuracy: 0.9301\n",
      "Epoch 476/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0911 - accuracy: 0.9783 - val_loss: 0.2902 - val_accuracy: 0.9271\n",
      "Epoch 477/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0924 - accuracy: 0.9778 - val_loss: 0.2884 - val_accuracy: 0.9265\n",
      "Epoch 478/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0942 - accuracy: 0.9768 - val_loss: 0.2818 - val_accuracy: 0.9303\n",
      "Epoch 479/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0912 - accuracy: 0.9775 - val_loss: 0.2865 - val_accuracy: 0.9301\n",
      "Epoch 480/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0943 - accuracy: 0.9769 - val_loss: 0.2853 - val_accuracy: 0.9298\n",
      "Epoch 481/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0931 - accuracy: 0.9779 - val_loss: 0.2854 - val_accuracy: 0.9305\n",
      "Epoch 482/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0921 - accuracy: 0.9773 - val_loss: 0.2775 - val_accuracy: 0.9301\n",
      "Epoch 483/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0879 - accuracy: 0.9792 - val_loss: 0.2796 - val_accuracy: 0.9288\n",
      "Epoch 484/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0925 - accuracy: 0.9775 - val_loss: 0.2826 - val_accuracy: 0.9303\n",
      "Epoch 485/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0887 - accuracy: 0.9788 - val_loss: 0.2862 - val_accuracy: 0.9255\n",
      "Epoch 486/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0897 - accuracy: 0.9793 - val_loss: 0.2764 - val_accuracy: 0.9311\n",
      "Epoch 487/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0912 - accuracy: 0.9775 - val_loss: 0.2875 - val_accuracy: 0.9292\n",
      "Epoch 488/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0923 - accuracy: 0.9779 - val_loss: 0.2921 - val_accuracy: 0.9286\n",
      "Epoch 489/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0908 - accuracy: 0.9783 - val_loss: 0.2797 - val_accuracy: 0.9315\n",
      "Epoch 490/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0913 - accuracy: 0.9774 - val_loss: 0.2921 - val_accuracy: 0.9269\n",
      "Epoch 491/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0885 - accuracy: 0.9785 - val_loss: 0.2829 - val_accuracy: 0.9288\n",
      "Epoch 492/500\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.0900 - accuracy: 0.9786 - val_loss: 0.2873 - val_accuracy: 0.9276\n",
      "Epoch 493/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0921 - accuracy: 0.9777 - val_loss: 0.2952 - val_accuracy: 0.9244\n",
      "Epoch 494/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0897 - accuracy: 0.9790 - val_loss: 0.2826 - val_accuracy: 0.9290\n",
      "Epoch 495/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0893 - accuracy: 0.9781 - val_loss: 0.2823 - val_accuracy: 0.9294\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0899 - accuracy: 0.9782 - val_loss: 0.2883 - val_accuracy: 0.9290\n",
      "Epoch 497/500\n",
      "1205/1205 [==============================] - 19s 15ms/step - loss: 0.0931 - accuracy: 0.9769 - val_loss: 0.2905 - val_accuracy: 0.9292\n",
      "Epoch 498/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0920 - accuracy: 0.9774 - val_loss: 0.2915 - val_accuracy: 0.9305\n",
      "Epoch 499/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0898 - accuracy: 0.9780 - val_loss: 0.2888 - val_accuracy: 0.9278\n",
      "Epoch 500/500\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.0881 - accuracy: 0.9795 - val_loss: 0.2866 - val_accuracy: 0.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0d986d5520>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantization aware training, in which the best model is saved\n",
    "\n",
    "EPOCHS = 500\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "history = quantized_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),  \n",
    "    epochs=EPOCHS,\n",
    "    batch_size = 32,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "quantized_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38d549d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6418/897927363.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
      "/tmp/ipykernel_6418/897927363.py:11: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
      "/tmp/ipykernel_6418/897927363.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
      "/tmp/ipykernel_6418/897927363.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d116b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized CNN model\n",
    "\n",
    "models.save_model(quantized_model, Quantized_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4037feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Optional if pretrained ##########\n",
    "\n",
    "quantized_model.load_weights(Quantized_model_filename)\n",
    "quantized_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63d68f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of quantized CNN: 99.96886849403381 %\n",
      "Accuracy on validation set of quantized CNN: 93.31672787666321 %\n",
      "Accuracy on test set with SNR of 1 of quantized CNN: 76.87837481498718 %\n",
      "Accuracy on test set with SNR of 10 of quantized CNN: 89.82980251312256 %\n",
      "Accuracy on test set with SNR of 20 of quantized CNN: 93.0261492729187 %\n",
      "Accuracy on test set with SNR of 100 of quantized CNN: 94.12619471549988 %\n",
      "Accuracy on test set with SNR of 1000 of quantized CNN: 94.10544037818909 %\n"
     ]
    }
   ],
   "source": [
    "# Print peformance of the quantized CNN after quantization aware training\n",
    "\n",
    "score = quantized_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of quantized CNN:', score[1] * 100,'%')\n",
    "\n",
    "score = quantized_model.evaluate(x_test1, y_test1, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test10, y_test10, verbose=0)\n",
    "print('Accuracy on test set with SNR of 10 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test20, y_test20, verbose=0)\n",
    "print('Accuracy on test set with SNR of 20 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test100, y_test100, verbose=0)\n",
    "print('Accuracy on test set with SNR of 100 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test1000, y_test1000, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1000 of quantized CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1562af",
   "metadata": {},
   "source": [
    "<font size=\"5\">4. Akida Model Conversion</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4efc22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Summary                 \n",
      "_______________________________________________\n",
      "Input shape   Output shape  Sequences  Layers\n",
      "===============================================\n",
      "[40, 101, 1]  [1, 1, 12]    1          10    \n",
      "_______________________________________________\n",
      "\n",
      "                SW/conv_0-dense (Software)                 \n",
      "___________________________________________________________\n",
      "Layer (type)             Output shape   Kernel shape     \n",
      "===========================================================\n",
      "conv_0 (InputConv.)      [51, 20, 32]   (3, 3, 1, 32)    \n",
      "___________________________________________________________\n",
      "separable_1 (Sep.Conv.)  [51, 20, 32]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 32)   \n",
      "___________________________________________________________\n",
      "separable_2 (Sep.Conv.)  [26, 10, 64]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 64)   \n",
      "___________________________________________________________\n",
      "separable_3 (Sep.Conv.)  [26, 10, 128]  (3, 3, 64, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 64, 128)  \n",
      "___________________________________________________________\n",
      "separable_4 (Sep.Conv.)  [13, 5, 128]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 128) \n",
      "___________________________________________________________\n",
      "separable_5 (Sep.Conv.)  [13, 5, 256]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 256) \n",
      "___________________________________________________________\n",
      "separable_6 (Sep.Conv.)  [7, 3, 256]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 256) \n",
      "___________________________________________________________\n",
      "separable_7 (Sep.Conv.)  [4, 2, 512]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 512) \n",
      "___________________________________________________________\n",
      "separable_8 (Sep.Conv.)  [1, 1, 1024]   (3, 3, 512, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 512, 1024)\n",
      "___________________________________________________________\n",
      "dense (Fully.)           [1, 1, 12]     (1, 1, 1024, 12) \n",
      "___________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Convert to an Akida model\n",
    "\n",
    "akida_model = convert(quantized_model)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6c944ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN accuracy on training set after conversion: 99.97405697089192 %\n",
      "SNN accuracy on validation set after conversion: 93.08841843088418 %\n",
      "SNN accuracy on test set with SNR of 1 after conversion: 77.21046077210461 %\n",
      "SNN accuracy on test set with SNR of 10 after conversion: 89.89207139892072 %\n",
      "SNN accuracy on test set with SNR of 20 after conversion: 92.86010792860108 %\n",
      "SNN accuracy on test set with SNR of 100 after conversion: 93.93939393939394 %\n",
      "SNN accuracy on test set with SNR of 1000 after conversion: 94.06392694063926 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the final Akida model\n",
    "\n",
    "results = akida_model.predict(x_train)\n",
    "accuracy = (y_train == results).mean()\n",
    "\n",
    "print('SNN accuracy on training set after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_val)\n",
    "accuracy = (y_val == results).mean()\n",
    "\n",
    "print('SNN accuracy on validation set after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test1)\n",
    "accuracy = (y_test1 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 1 after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test10)\n",
    "accuracy = (y_test10 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 10 after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test20)\n",
    "accuracy = (y_test20 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 20 after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test100)\n",
    "accuracy = (y_test100 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 100 after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test1000)\n",
    "accuracy = (y_test1000 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 1000 after conversion:', accuracy * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb59492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
