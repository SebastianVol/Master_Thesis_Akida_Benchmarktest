{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2e232e",
   "metadata": {},
   "source": [
    "<font size=\"5\">On-Chip Edge Learning</font>\n",
    "\n",
    "This notebook was executed on the development kit from BrainChip. Furthermore, the on-chip edge learning was executed. The code was inspired by the official code from BrainChip (https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc01ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import pathlib\n",
    "\n",
    "import akida\n",
    "from akida import FullyConnected\n",
    "from akida import evaluate_sparsity\n",
    "import cnn2snn\n",
    "from cnn2snn import check_model_compatibility\n",
    "from cnn2snn import quantize\n",
    "from cnn2snn import quantize_layer\n",
    "from cnn2snn import convert\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053f066",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 1. Load the Data Set and Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d9c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous trained model. (Source Model: Final_Edge)\n",
    "\n",
    "quantized_model = cnn2snn.load_quantized_model('final_quantized_edge_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9845b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Sets:  ['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']\n",
      "Feature Sets for Edge:  ['x_train', 'y_train', 'x_val', 'y_val']\n"
     ]
    }
   ],
   "source": [
    "# Define directories of the data\n",
    "\n",
    "feature_sets_filename = 'final_stored_files_targets_int_normalized_wedge.npz'\n",
    "feature_sets_filename_edge = 'final_stored_files_targets_int_normalized_edge.npz'\n",
    "\n",
    "# Load feature sets\n",
    "\n",
    "feature_sets = np.load(feature_sets_filename)\n",
    "feature_sets_edge = np.load(feature_sets_filename_edge)\n",
    "print('Feature Sets: ', feature_sets.files)\n",
    "print('Feature Sets for Edge: ', feature_sets_edge.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9389bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets of inital data set\n",
    "\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']\n",
    "\n",
    "# Assign feature sets of edge data set\n",
    "\n",
    "x_train_edge = feature_sets_edge['x_train']\n",
    "y_train_edge = feature_sets_edge['y_train']\n",
    "x_val_edge = feature_sets_edge['x_val']\n",
    "y_val_edge = feature_sets_edge['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8caab792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add dimension to all data: Order Train, Val, Test, Train_edge, Val_edge: \n",
      "(34972, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(714, 40, 101, 1)\n",
      "(85, 40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN for conversion expects (batch, height, width, channels)\n",
    "# The channels can either be 1 for gray-scaled images or 3 for RGB-images\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "x_val = x_val.reshape(x_val.shape[0], \n",
    "                      x_val.shape[1], \n",
    "                      x_val.shape[2], \n",
    "                      1)\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_train_edge = x_train_edge.reshape(x_train_edge.shape[0], \n",
    "                          x_train_edge.shape[1], \n",
    "                          x_train_edge.shape[2], \n",
    "                          1)\n",
    "x_val_edge = x_val_edge.reshape(x_val_edge.shape[0], \n",
    "                      x_val_edge.shape[1], \n",
    "                      x_val_edge.shape[2], \n",
    "                      1)\n",
    "\n",
    "\n",
    "\n",
    "print('Add dimension to all data: Order Train, Val, Test, Train_edge, Val_edge: ')\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "print(x_train_edge.shape)\n",
    "print(x_val_edge.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3d4e84",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 2. Hyperparameter Search</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ee3d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida NP available : <akida.core.HardwareDevice object at 0xffff8807b970>\n"
     ]
    }
   ],
   "source": [
    "# Define the Akida device\n",
    "\n",
    "devices = akida.devices()\n",
    "print('Akida NP available :', devices[0])\n",
    "device = devices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ac6ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida inference 34972 MFCC took 380.86 with neurons per class: s.\n",
      " 2\n",
      "Akida validation set accuracy on initial data set: 93.23 % with neurons per class:  2\n",
      "The floor power with 2 neurons per class was:  917.8812866210938\n",
      "Statistics with 2 neurons were: 917.88 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Last inference power range (mW):  Avg 1046.12 / Min 1045.00 / Max 1047.00 / Std 1.01 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1108.27 fps\n",
      "Last inference power range (mW):  Avg 920.33 / Min 917.00 / Max 940.00 / Std 4.01 \n",
      "Last inference energy consumed (mJ/frame): 0.83\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 3527.85 fps\n",
      "Last inference power range (mW):  Avg 920.25 / Min 920.00 / Max 922.00 / Std 0.58 \n",
      "Last inference energy consumed (mJ/frame): 0.26\n",
      "Akida inference 34972 MFCC took 385.46 with neurons per class: s.\n",
      " 4\n",
      "Akida validation set accuracy on initial data set: 93.34 % with neurons per class:  4\n",
      "The floor power with 4 neurons per class was:  917.8812866210938\n",
      "Statistics with 4 neurons were: 917.88 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Last inference power range (mW):  Avg 1047.00 / Min 1047.00 / Max 1047.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1121.63 fps\n",
      "Last inference power range (mW):  Avg 922.46 / Min 920.00 / Max 1045.00 / Std 17.00 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 3223.45 fps\n",
      "Last inference power range (mW):  Avg 921.56 / Min 920.00 / Max 933.00 / Std 4.18 \n",
      "Last inference energy consumed (mJ/frame): 0.29\n",
      "Akida inference 34972 MFCC took 395.91 with neurons per class: s.\n",
      " 8\n",
      "Akida validation set accuracy on initial data set: 93.71 % with neurons per class:  8\n",
      "The floor power with 8 neurons per class was:  917.8812866210938\n",
      "Statistics with 8 neurons were: 917.88 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Last inference power range (mW):  Avg 1047.08 / Min 1045.00 / Max 1050.00 / Std 1.06 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1103.51 fps\n",
      "Last inference power range (mW):  Avg 922.89 / Min 920.00 / Max 1047.00 / Std 17.28 \n",
      "Last inference energy consumed (mJ/frame): 0.84\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 3409.52 fps\n",
      "Last inference power range (mW):  Avg 920.53 / Min 920.00 / Max 929.00 / Std 2.18 \n",
      "Last inference energy consumed (mJ/frame): 0.27\n",
      "Akida inference 34972 MFCC took 425.52 with neurons per class: s.\n",
      " 16\n",
      "Akida validation set accuracy on initial data set: 93.85 % with neurons per class:  16\n",
      "The floor power with 16 neurons per class was:  917.8812866210938\n",
      "Statistics with 16 neurons were: 917.88 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Last inference power range (mW):  Avg 1045.00 / Min 1045.00 / Max 1045.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1119.05 fps\n",
      "Last inference power range (mW):  Avg 919.15 / Min 917.00 / Max 971.00 / Std 10.28 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 2689.85 fps\n",
      "Last inference power range (mW):  Avg 917.68 / Min 917.00 / Max 920.00 / Std 1.29 \n",
      "Last inference energy consumed (mJ/frame): 0.34\n",
      "Akida inference 34972 MFCC took 446.83 with neurons per class: s.\n",
      " 32\n",
      "Akida validation set accuracy on initial data set: 93.82 % with neurons per class:  32\n",
      "The floor power with 32 neurons per class was:  916.09375\n",
      "Statistics with 32 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.70 fps\n",
      "Last inference power range (mW):  Avg 1044.78 / Min 1043.00 / Max 1045.00 / Std 0.65 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1122.50 fps\n",
      "Last inference power range (mW):  Avg 918.33 / Min 917.00 / Max 953.00 / Std 6.86 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 2389.83 fps\n",
      "Last inference power range (mW):  Avg 925.16 / Min 925.00 / Max 926.00 / Std 0.37 \n",
      "Last inference energy consumed (mJ/frame): 0.39\n",
      "Akida inference 34972 MFCC took 474.98 with neurons per class: s.\n",
      " 40\n",
      "Akida validation set accuracy on initial data set: 93.80 % with neurons per class:  40\n",
      "The floor power with 40 neurons per class was:  916.09375\n",
      "Statistics with 40 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.70 fps\n",
      "Last inference power range (mW):  Avg 1045.31 / Min 1045.00 / Max 1047.00 / Std 0.75 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1109.67 fps\n",
      "Last inference power range (mW):  Avg 919.40 / Min 917.00 / Max 1043.00 / Std 16.98 \n",
      "Last inference energy consumed (mJ/frame): 0.83\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 2103.46 fps\n",
      "Last inference power range (mW):  Avg 926.07 / Min 925.00 / Max 929.00 / Std 0.88 \n",
      "Last inference energy consumed (mJ/frame): 0.44\n",
      "Akida inference 34972 MFCC took 505.78 with neurons per class: s.\n",
      " 50\n",
      "Akida validation set accuracy on initial data set: 93.94 % with neurons per class:  50\n",
      "The floor power with 50 neurons per class was:  916.09375\n",
      "Statistics with 50 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.64 fps\n",
      "Last inference power range (mW):  Avg 1045.80 / Min 1045.00 / Max 1047.00 / Std 1.03 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1122.78 fps\n",
      "Last inference power range (mW):  Avg 918.59 / Min 917.00 / Max 960.00 / Std 8.20 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 1882.43 fps\n",
      "Last inference power range (mW):  Avg 926.62 / Min 926.00 / Max 931.00 / Std 1.43 \n",
      "Last inference energy consumed (mJ/frame): 0.49\n",
      "Akida inference 34972 MFCC took 540.39 with neurons per class: s.\n",
      " 60\n",
      "Akida validation set accuracy on initial data set: 93.82 % with neurons per class:  60\n",
      "The floor power with 60 neurons per class was:  916.09375\n",
      "Statistics with 60 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.64 fps\n",
      "Last inference power range (mW):  Avg 1047.00 / Min 1047.00 / Max 1047.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1108.27 fps\n",
      "Last inference power range (mW):  Avg 922.65 / Min 920.00 / Max 992.00 / Std 13.60 \n",
      "Last inference energy consumed (mJ/frame): 0.83\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 1699.46 fps\n",
      "Last inference power range (mW):  Avg 929.25 / Min 920.00 / Max 938.00 / Std 2.62 \n",
      "Last inference energy consumed (mJ/frame): 0.55\n",
      "Akida inference 34972 MFCC took 567.32 with neurons per class: s.\n",
      " 70\n",
      "Akida validation set accuracy on initial data set: 93.71 % with neurons per class:  70\n",
      "The floor power with 70 neurons per class was:  916.09375\n",
      "Statistics with 70 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Last inference power range (mW):  Avg 1047.00 / Min 1047.00 / Max 1047.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 2.83\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1117.33 fps\n",
      "Last inference power range (mW):  Avg 923.07 / Min 920.00 / Max 1047.00 / Std 17.43 \n",
      "Last inference energy consumed (mJ/frame): 0.83\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 1552.20 fps\n",
      "Last inference power range (mW):  Avg 929.62 / Min 929.00 / Max 935.00 / Std 1.46 \n",
      "Last inference energy consumed (mJ/frame): 0.60\n",
      "Akida inference 34972 MFCC took 580.60 with neurons per class: s.\n",
      " 80\n",
      "Akida validation set accuracy on initial data set: 93.80 % with neurons per class:  80\n",
      "The floor power with 80 neurons per class was:  916.09375\n",
      "Statistics with 80 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1123.07 fps\n",
      "Last inference power range (mW):  Avg 920.45 / Min 920.00 / Max 944.00 / Std 3.30 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 1395.15 fps\n",
      "Last inference power range (mW):  Avg 930.05 / Min 929.00 / Max 931.00 / Std 1.01 \n",
      "Last inference energy consumed (mJ/frame): 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida inference 34972 MFCC took 605.69 with neurons per class: s.\n",
      " 90\n",
      "Akida validation set accuracy on initial data set: 93.75 % with neurons per class:  90\n",
      "The floor power with 90 neurons per class was:  916.09375\n",
      "Statistics with 90 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1118.47 fps\n",
      "Last inference power range (mW):  Avg 920.00 / Min 920.00 / Max 920.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 1313.40 fps\n",
      "Last inference power range (mW):  Avg 930.83 / Min 929.00 / Max 931.00 / Std 0.56 \n",
      "Last inference energy consumed (mJ/frame): 0.71\n",
      "Akida inference 34972 MFCC took 632.48 with neurons per class: s.\n",
      " 100\n",
      "Akida validation set accuracy on initial data set: 93.82 % with neurons per class:  100\n",
      "The floor power with 100 neurons per class was:  916.09375\n",
      "Statistics with 100 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.64 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1119.91 fps\n",
      "Last inference power range (mW):  Avg 920.00 / Min 920.00 / Max 920.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 1216.87 fps\n",
      "Last inference power range (mW):  Avg 930.76 / Min 925.00 / Max 931.00 / Std 1.19 \n",
      "Last inference energy consumed (mJ/frame): 0.76\n",
      "Akida inference 34972 MFCC took 799.33 with neurons per class: s.\n",
      " 150\n",
      "Akida validation set accuracy on initial data set: 93.71 % with neurons per class:  150\n",
      "The floor power with 150 neurons per class was:  916.09375\n",
      "Statistics with 150 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1116.48 fps\n",
      "Last inference power range (mW):  Avg 920.00 / Min 920.00 / Max 920.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 903.47 fps\n",
      "Last inference power range (mW):  Avg 932.63 / Min 920.00 / Max 933.00 / Std 1.66 \n",
      "Last inference energy consumed (mJ/frame): 1.03\n",
      "Akida inference 34972 MFCC took 923.69 with neurons per class: s.\n",
      " 200\n",
      "Akida validation set accuracy on initial data set: 94.19 % with neurons per class:  200\n",
      "The floor power with 200 neurons per class was:  916.09375\n",
      "Statistics with 200 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1120.48 fps\n",
      "Last inference power range (mW):  Avg 920.25 / Min 920.00 / Max 921.00 / Std 0.45 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 738.10 fps\n",
      "Last inference power range (mW):  Avg 933.01 / Min 920.00 / Max 940.00 / Std 1.80 \n",
      "Last inference energy consumed (mJ/frame): 1.26\n",
      "Akida inference 34972 MFCC took 1263.14 with neurons per class: s.\n",
      " 300\n",
      "Akida validation set accuracy on initial data set: 94.01 % with neurons per class:  300\n",
      "The floor power with 300 neurons per class was:  916.09375\n",
      "Statistics with 300 neurons were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.70 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1119.91 fps\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 514.24 fps\n",
      "Last inference power range (mW):  Avg 934.54 / Min 933.00 / Max 935.00 / Std 0.85 \n",
      "Last inference energy consumed (mJ/frame): 1.82\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error when programming layer 'akida_edge_layer': 758424 cannot fit in a 20 bits signed integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4155/744511316.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0makida_model_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_akida/lib/python3.7/site-packages/akida/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, input_labels, batch_size)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit expects integer as labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         outputs = super().fit(inputs, input_labels,\n\u001b[0;32m--> 169\u001b[0;31m                               0 if batch_size is None else batch_size)\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error when programming layer 'akida_edge_layer': 758424 cannot fit in a 20 bits signed integer"
     ]
    }
   ],
   "source": [
    "# Hyperparameter search of \"neurons per class\"\n",
    "# In every iteration the summary and floor power of the power measurement is printed\n",
    "\n",
    "neurons_per_class = [2, 4, 8, 16, 32, 40, 50, 60, 70, 80, 90, 100, 150, 200, 300, 350, 400, 450, 500]\n",
    "num_labels = 12\n",
    "num_weights = 300\n",
    "device.soc.power_measurement_enabled = True\n",
    "\n",
    "for idx, n in enumerate(neurons_per_class):\n",
    "    \n",
    "    akida_model_test = convert(quantized_model)\n",
    "\n",
    "    akida_model_test.pop_layer()\n",
    "    layer_fc = FullyConnected(name='akida_edge_layer',\n",
    "                              units=num_labels * n,\n",
    "                              activation=False)\n",
    "    akida_model_test.add(layer_fc)\n",
    "    \n",
    "    akida_model_test.map(device)\n",
    "\n",
    "    #akida_model_test.summary()\n",
    "    \n",
    "    akida_model_test.compile(num_weights=num_weights,\n",
    "                     num_classes=num_labels,\n",
    "                     learning_competition=0.1)\n",
    "\n",
    "    batch_size = 8\n",
    "    preds_ak = np.zeros(y_val.shape[0])\n",
    "    num_batches_val = ceil(x_val.shape[0] / batch_size)\n",
    "    num_batches = ceil(x_train.shape[0] / batch_size)\n",
    "    \n",
    "    \n",
    "    start = timer()\n",
    "    for i in range(num_batches):\n",
    "        s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        akida_model_test.fit(x_train[s], y_train[s].astype(np.int32))\n",
    "    end = timer()\n",
    "    \n",
    "    \n",
    "    floor_power = device.soc.power_meter.floor\n",
    "    \n",
    "    preds_val_ak = akida_model_test.predict(x_val, num_classes=num_labels)\n",
    "    acc_val_ak = np.sum(preds_val_ak == y_val) / y_val.shape[0]\n",
    "    print(f'Akida inference {len(x_train)} MFCC took {end-start:.2f} with neurons per class: s.\\n', n)\n",
    "    print(f\"Akida validation set accuracy on initial data set: {100 * acc_val_ak:.2f} %\", 'with neurons per class: ',n)\n",
    "    print(f'The floor power with {n} neurons per class was: ', floor_power)\n",
    "    print(f'Statistics with {n} neurons were: {floor_power:.2f} mW')\n",
    "    print(akida_model_test.statistics)\n",
    "    del akida_model_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33246ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida inference 34972 MFCC took 922.22 with learning competition: s.\n",
      " 0.1\n",
      "Akida validation set accuracy on initial data set: 93.89 % with learning competition:  0.1\n",
      "The floor power with 0.1 learning competition was:  916.09375\n",
      "Statistics with 0.1 learning competition were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1119.91 fps\n",
      "Last inference power range (mW):  Avg 920.00 / Min 920.00 / Max 920.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 729.35 fps\n",
      "Last inference power range (mW):  Avg 933.31 / Min 933.00 / Max 938.00 / Std 0.94 \n",
      "Last inference energy consumed (mJ/frame): 1.28\n",
      "Akida inference 34972 MFCC took 922.45 with learning competition: s.\n",
      " 0.15\n",
      "Akida validation set accuracy on initial data set: 93.94 % with learning competition:  0.15\n",
      "The floor power with 0.15 learning competition was:  916.09375\n",
      "Statistics with 0.15 learning competition were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.70 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1124.23 fps\n",
      "Last inference power range (mW):  Avg 918.64 / Min 917.00 / Max 920.00 / Std 1.57 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 736.73 fps\n",
      "Last inference power range (mW):  Avg 932.81 / Min 925.00 / Max 933.00 / Std 0.97 \n",
      "Last inference energy consumed (mJ/frame): 1.27\n",
      "Akida inference 34972 MFCC took 923.12 with learning competition: s.\n",
      " 0.2\n",
      "Akida validation set accuracy on initial data set: 93.85 % with learning competition:  0.2\n",
      "The floor power with 0.2 learning competition was:  916.09375\n",
      "Statistics with 0.2 learning competition were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.64 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1122.50 fps\n",
      "Last inference power range (mW):  Avg 920.00 / Min 920.00 / Max 920.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 696.02 fps\n",
      "Last inference power range (mW):  Avg 932.90 / Min 920.00 / Max 935.00 / Std 1.42 \n",
      "Last inference energy consumed (mJ/frame): 1.34\n",
      "Akida inference 34972 MFCC took 923.67 with learning competition: s.\n",
      " 0.3\n",
      "Akida validation set accuracy on initial data set: 93.78 % with learning competition:  0.3\n",
      "The floor power with 0.3 learning competition was:  916.09375\n",
      "Statistics with 0.3 learning competition were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1113.06 fps\n",
      "Last inference power range (mW):  Avg 920.00 / Min 920.00 / Max 920.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 0.83\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 679.89 fps\n",
      "Last inference power range (mW):  Avg 931.96 / Min 920.00 / Max 933.00 / Std 1.61 \n",
      "Last inference energy consumed (mJ/frame): 1.37\n",
      "Akida inference 34972 MFCC took 923.23 with learning competition: s.\n",
      " 0.4\n",
      "Akida validation set accuracy on initial data set: 93.80 % with learning competition:  0.4\n",
      "The floor power with 0.4 learning competition was:  916.09375\n",
      "Statistics with 0.4 learning competition were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1119.62 fps\n",
      "Last inference power range (mW):  Avg 920.00 / Min 920.00 / Max 920.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 739.34 fps\n",
      "Last inference power range (mW):  Avg 933.19 / Min 931.00 / Max 935.00 / Std 0.74 \n",
      "Last inference energy consumed (mJ/frame): 1.26\n",
      "Akida inference 34972 MFCC took 923.40 with learning competition: s.\n",
      " 0.5\n",
      "Akida validation set accuracy on initial data set: 93.80 % with learning competition:  0.5\n",
      "The floor power with 0.5 learning competition was:  916.09375\n",
      "Statistics with 0.5 learning competition were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1104.35 fps\n",
      "Last inference power range (mW):  Avg 920.17 / Min 920.00 / Max 921.00 / Std 0.39 \n",
      "Last inference energy consumed (mJ/frame): 0.83\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 733.27 fps\n",
      "Last inference power range (mW):  Avg 932.62 / Min 929.00 / Max 933.00 / Std 0.85 \n",
      "Last inference energy consumed (mJ/frame): 1.27\n",
      "Akida inference 34972 MFCC took 923.71 with learning competition: s.\n",
      " 0.8\n",
      "Akida validation set accuracy on initial data set: 93.34 % with learning competition:  0.8\n",
      "The floor power with 0.8 learning competition was:  916.09375\n",
      "Statistics with 0.8 learning competition were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.70 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1121.06 fps\n",
      "Last inference power range (mW):  Avg 917.00 / Min 917.00 / Max 917.00 / Std 0.00 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 739.47 fps\n",
      "Last inference power range (mW):  Avg 931.33 / Min 926.00 / Max 933.00 / Std 0.99 \n",
      "Last inference energy consumed (mJ/frame): 1.26\n",
      "Akida inference 34972 MFCC took 924.32 with learning competition: s.\n",
      " 1\n",
      "Akida validation set accuracy on initial data set: 92.52 % with learning competition:  1\n",
      "The floor power with 1 learning competition was:  916.09375\n",
      "Statistics with 1 learning competition were: 916.09 mW\n",
      "\n",
      "Sequence HW/conv_0-separable_7\n",
      "Average framerate = 369.67 fps\n",
      "Sequence SW/separable_8\n",
      "Average framerate = 1122.21 fps\n",
      "Last inference power range (mW):  Avg 918.71 / Min 917.00 / Max 920.00 / Std 1.60 \n",
      "Last inference energy consumed (mJ/frame): 0.82\n",
      "Sequence HW/akida_edge_layer\n",
      "Average framerate = 694.47 fps\n",
      "Last inference power range (mW):  Avg 931.35 / Min 926.00 / Max 933.00 / Std 0.99 \n",
      "Last inference energy consumed (mJ/frame): 1.34\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter search of \"learning competition\"\n",
    "\n",
    "learning_comp = [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.8, 1]\n",
    "num_labels = 12\n",
    "num_weights = 300\n",
    "device.soc.power_measurement_enabled = True\n",
    "\n",
    "for idx, n in enumerate(learning_comp):\n",
    "    \n",
    "    akida_model_test = convert(quantized_model)\n",
    "\n",
    "    akida_model_test.pop_layer()\n",
    "    layer_fc = FullyConnected(name='akida_edge_layer',\n",
    "                              units=num_labels * 200,\n",
    "                              activation=False)\n",
    "    akida_model_test.add(layer_fc)\n",
    "    \n",
    "    akida_model_test.map(device)\n",
    "\n",
    "    #akida_model_test.summary()\n",
    "    \n",
    "    akida_model_test.compile(num_weights=num_weights,\n",
    "                     num_classes=num_labels,\n",
    "                     learning_competition=n)\n",
    "\n",
    "    batch_size = 8\n",
    "    preds_ak = np.zeros(y_val.shape[0])\n",
    "    num_batches_val = ceil(x_val.shape[0] / batch_size)\n",
    "    num_batches = ceil(x_train.shape[0] / batch_size)\n",
    "    \n",
    "    \n",
    "    start = timer()\n",
    "    for i in range(num_batches):\n",
    "        s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        akida_model_test.fit(x_train[s], y_train[s].astype(np.int32))\n",
    "    end = timer()\n",
    "    \n",
    "    \n",
    "    floor_power = device.soc.power_meter.floor\n",
    "    \n",
    "    preds_val_ak = akida_model_test.predict(x_val, num_classes=num_labels)\n",
    "    acc_val_ak = np.sum(preds_val_ak == y_val) / y_val.shape[0]\n",
    "    print(f'Akida inference {len(x_train)} MFCC took {end-start:.2f} with learning competition: s.\\n', n)\n",
    "    print(f\"Akida validation set accuracy on initial data set: {100 * acc_val_ak:.2f} %\", 'with learning competition: ',n)\n",
    "    print(f'The floor power with {n} learning competition was: ', floor_power)\n",
    "    print(f'Statistics with {n} learning competition were: {floor_power:.2f} mW')\n",
    "    print(akida_model_test.statistics)\n",
    "    del akida_model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1243380",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 3. Edge Learning with previously defined Hyperparameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22bb5dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Summary                 \n",
      "_______________________________________________\n",
      "Input shape   Output shape  Sequences  Layers\n",
      "===============================================\n",
      "[40, 101, 1]  [1, 1, 12]    1          10    \n",
      "_______________________________________________\n",
      "\n",
      "                SW/conv_0-dense (Software)                 \n",
      "___________________________________________________________\n",
      "Layer (type)             Output shape   Kernel shape     \n",
      "===========================================================\n",
      "conv_0 (InputConv.)      [51, 20, 32]   (3, 3, 1, 32)    \n",
      "___________________________________________________________\n",
      "separable_1 (Sep.Conv.)  [51, 20, 32]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 32)   \n",
      "___________________________________________________________\n",
      "separable_2 (Sep.Conv.)  [26, 10, 64]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 64)   \n",
      "___________________________________________________________\n",
      "separable_3 (Sep.Conv.)  [26, 10, 128]  (3, 3, 64, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 64, 128)  \n",
      "___________________________________________________________\n",
      "separable_4 (Sep.Conv.)  [13, 5, 128]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 128) \n",
      "___________________________________________________________\n",
      "separable_5 (Sep.Conv.)  [13, 5, 256]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 256) \n",
      "___________________________________________________________\n",
      "separable_6 (Sep.Conv.)  [7, 3, 256]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 256) \n",
      "___________________________________________________________\n",
      "separable_7 (Sep.Conv.)  [4, 2, 512]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 512) \n",
      "___________________________________________________________\n",
      "separable_8 (Sep.Conv.)  [1, 1, 1024]   (3, 3, 512, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 512, 1024)\n",
      "___________________________________________________________\n",
      "dense (Fully.)           [1, 1, 12]     (1, 1, 1024, 12) \n",
      "___________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to an Akida model\n",
    "\n",
    "akida_model = convert(quantized_model)\n",
    "akida_model.summary()\n",
    "\n",
    "# Replace the last layer by a classification layer with binary weights\n",
    "# Here, we choose to set 15 neurons per class.\n",
    "\n",
    "num_neurons_per_class = 200\n",
    "\n",
    "akida_model.pop_layer()\n",
    "layer_fc = FullyConnected(name='akida_edge_layer',\n",
    "                          units=num_labels * num_neurons_per_class,\n",
    "                          activation=False)\n",
    "akida_model.add(layer_fc)\n",
    "\n",
    "akida_model.map(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a297a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Summary                 \n",
      "_______________________________________________\n",
      "Input shape   Output shape  Sequences  Layers\n",
      "===============================================\n",
      "[40, 101, 1]  [1, 1, 2400]  3          10    \n",
      "_______________________________________________\n",
      "\n",
      "     HW/conv_0-separable_7 (Hardware) - size: 204356 bytes     \n",
      "_______________________________________________________________\n",
      "Layer (type)             Output shape   Kernel shape      NPs\n",
      "===============================================================\n",
      "conv_0 (InputConv.)      [51, 20, 32]   (3, 3, 1, 32)     N/A\n",
      "_______________________________________________________________\n",
      "separable_1 (Sep.Conv.)  [51, 20, 32]   (3, 3, 32, 1)     2  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 32, 32)       \n",
      "_______________________________________________________________\n",
      "separable_2 (Sep.Conv.)  [26, 10, 64]   (3, 3, 32, 1)     2  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 32, 64)       \n",
      "_______________________________________________________________\n",
      "separable_3 (Sep.Conv.)  [26, 10, 128]  (3, 3, 64, 1)     1  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 64, 128)      \n",
      "_______________________________________________________________\n",
      "separable_4 (Sep.Conv.)  [13, 5, 128]   (3, 3, 128, 1)    1  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 128, 128)     \n",
      "_______________________________________________________________\n",
      "separable_5 (Sep.Conv.)  [13, 5, 256]   (3, 3, 128, 1)    1  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 128, 256)     \n",
      "_______________________________________________________________\n",
      "separable_6 (Sep.Conv.)  [7, 3, 256]    (3, 3, 256, 1)    1  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 256, 256)     \n",
      "_______________________________________________________________\n",
      "separable_7 (Sep.Conv.)  [4, 2, 512]    (3, 3, 256, 1)    2  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 256, 512)     \n",
      "_______________________________________________________________\n",
      "\n",
      "                SW/separable_8 (Software)                 \n",
      "__________________________________________________________\n",
      "Layer (type)             Output shape  Kernel shape     \n",
      "==========================================================\n",
      "separable_8 (Sep.Conv.)  [1, 1, 1024]  (3, 3, 512, 1)   \n",
      "__________________________________________________________\n",
      "                                       (1, 1, 512, 1024)\n",
      "__________________________________________________________\n",
      "\n",
      "       HW/akida_edge_layer (Hardware) - size: 365420 bytes        \n",
      "__________________________________________________________________\n",
      "Layer (type)               Output shape  Kernel shape        NPs\n",
      "==================================================================\n",
      "akida_edge_layer (Fully.)  [1, 1, 2400]  (1, 1, 1024, 2400)  1  \n",
      "__________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed274000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN accuracy on training set after edge layer replacement: 7.820542148004117 %\n",
      "SNN accuracy on validation set after edge layer replacement: 7.778540379775794 %\n",
      "SNN accuracy on test set after edge layer replacement: 8.053077099062 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance of the Akida model\n",
    "\n",
    "results = akida_model.predict(x_train)\n",
    "accuracy = (y_train == results).mean()\n",
    "\n",
    "print('SNN accuracy on training set after edge layer replacement:', accuracy * 100,'%')\n",
    "\n",
    "\n",
    "results = akida_model.predict(x_val)\n",
    "accuracy = (y_val == results).mean()\n",
    "\n",
    "print('SNN accuracy on validation set after edge layer replacement:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test)\n",
    "accuracy = (y_test == results).mean()\n",
    "\n",
    "\n",
    "print('SNN accuracy on test set after edge layer replacement:', accuracy * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7342d8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of spikes: 250.38078902229847\n",
      "The number of weights is then set to: 300\n"
     ]
    }
   ],
   "source": [
    "# Estimate the hyperparameter \"number of weights\".\n",
    "# This hyperparameter describes the number of weights assigned for each neuron in the edge layer. \n",
    "# As described in the MetaTF documentation 10% of the training set is used to evaluate the sparsity. \n",
    "# Code Source: https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html\n",
    "\n",
    "num_samples = ceil(0.1 * x_train.shape[0])\n",
    "sparsities = evaluate_sparsity(akida_model, x_train[:num_samples])\n",
    "\n",
    "# Retrieve the number of output spikes from the feature extractor output\n",
    "output_density = 1 - sparsities[akida_model.get_layer('separable_8')]\n",
    "avg_spikes = quantized_model.get_layer('separable_8').output_shape[-1] * output_density\n",
    "print(f\"Average number of spikes: {avg_spikes}\")\n",
    "\n",
    "# Fix the number of weights to 1.2 times the average number of output spikes\n",
    "num_weights = int(1.2 * avg_spikes)\n",
    "print(\"The number of weights is then set to:\", num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4964539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Summary                 \n",
      "_______________________________________________\n",
      "Input shape   Output shape  Sequences  Layers\n",
      "===============================================\n",
      "[40, 101, 1]  [1, 1, 2400]  3          10    \n",
      "_______________________________________________\n",
      "\n",
      "     HW/conv_0-separable_7 (Hardware) - size: 204356 bytes     \n",
      "_______________________________________________________________\n",
      "Layer (type)             Output shape   Kernel shape      NPs\n",
      "===============================================================\n",
      "conv_0 (InputConv.)      [51, 20, 32]   (3, 3, 1, 32)     N/A\n",
      "_______________________________________________________________\n",
      "separable_1 (Sep.Conv.)  [51, 20, 32]   (3, 3, 32, 1)     2  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 32, 32)       \n",
      "_______________________________________________________________\n",
      "separable_2 (Sep.Conv.)  [26, 10, 64]   (3, 3, 32, 1)     2  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 32, 64)       \n",
      "_______________________________________________________________\n",
      "separable_3 (Sep.Conv.)  [26, 10, 128]  (3, 3, 64, 1)     1  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 64, 128)      \n",
      "_______________________________________________________________\n",
      "separable_4 (Sep.Conv.)  [13, 5, 128]   (3, 3, 128, 1)    1  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 128, 128)     \n",
      "_______________________________________________________________\n",
      "separable_5 (Sep.Conv.)  [13, 5, 256]   (3, 3, 128, 1)    1  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 128, 256)     \n",
      "_______________________________________________________________\n",
      "separable_6 (Sep.Conv.)  [7, 3, 256]    (3, 3, 256, 1)    1  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 256, 256)     \n",
      "_______________________________________________________________\n",
      "separable_7 (Sep.Conv.)  [4, 2, 512]    (3, 3, 256, 1)    2  \n",
      "_______________________________________________________________\n",
      "                                        (1, 1, 256, 512)     \n",
      "_______________________________________________________________\n",
      "\n",
      "                SW/separable_8 (Software)                 \n",
      "__________________________________________________________\n",
      "Layer (type)             Output shape  Kernel shape     \n",
      "==========================================================\n",
      "separable_8 (Sep.Conv.)  [1, 1, 1024]  (3, 3, 512, 1)   \n",
      "__________________________________________________________\n",
      "                                       (1, 1, 512, 1024)\n",
      "__________________________________________________________\n",
      "\n",
      "       HW/akida_edge_layer (Hardware) - size: 711332 bytes        \n",
      "__________________________________________________________________\n",
      "Layer (type)               Output shape  Kernel shape        NPs\n",
      "==================================================================\n",
      "akida_edge_layer (Fully.)  [1, 1, 2400]  (1, 1, 1024, 2400)  1  \n",
      "__________________________________________________________________\n",
      "\n",
      "              Learning Summary              \n",
      "____________________________________________\n",
      "Learning Layer    # Input Conn.  # Weights\n",
      "============================================\n",
      "akida_edge_layer  1024           300      \n",
      "____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile Akida model with learning parameters\n",
    "\n",
    "akida_model.compile(num_weights=num_weights,\n",
    "                 num_classes=num_labels,\n",
    "                 learning_competition=0.15)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "010236f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida learning with 12 classes...         (this step can take a few minutes)\n",
      "Elapsed time for Akida training: 365.64 s\n"
     ]
    }
   ],
   "source": [
    "# Train the Akida model\n",
    "# Code Source: https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html\n",
    "\n",
    "batch_size = 32\n",
    "preds_ak = np.zeros(y_val.shape[0])\n",
    "num_batches_val = ceil(x_val.shape[0] / batch_size)\n",
    "\n",
    "# Train the last layer using Akida `fit` method\n",
    "print(f\"Akida learning with {num_labels} classes... \\\n",
    "        (this step can take a few minutes)\")\n",
    "num_batches = ceil(x_train.shape[0] / batch_size)\n",
    "start = timer()\n",
    "for i in range(num_batches):\n",
    "    s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "    akida_model.fit(x_train[s], y_train[s].astype(np.int32))\n",
    "end = timer()\n",
    "\n",
    "print(f\"Elapsed time for Akida training: {end-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d25009da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida train set accuracy: 99.02 %\n",
      "Akida validation set accuracy: 94.07 %\n",
      "Akida test set accuracy: 93.46 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performanc of the Akida model\n",
    "# Code Source: https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html\n",
    "\n",
    "preds_val_ak = akida_model.predict(x_train, num_classes=num_labels)\n",
    "acc_val_ak = np.sum(preds_val_ak == y_train) / y_train.shape[0]\n",
    "print(f\"Akida train set accuracy: {100 * acc_val_ak:.2f} %\")\n",
    "\n",
    "# Measure Akida accuracy on validation set\n",
    "preds_val_ak = np.zeros(y_val.shape[0])\n",
    "for i in range(num_batches_val):\n",
    "    s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "    preds_val_ak[s] = akida_model.predict(x_val[s], num_classes=num_labels)\n",
    "\n",
    "acc_val_ak = np.sum(preds_val_ak == y_val) / y_val.shape[0]\n",
    "print(f\"Akida validation set accuracy: {100 * acc_val_ak:.2f} %\")\n",
    "\n",
    "# Measure Akida accuracy on validation set\n",
    "preds_val_ak = np.zeros(y_test.shape[0])\n",
    "for i in range(num_batches_val):\n",
    "    s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "    preds_val_ak[s] = akida_model.predict(x_test[s], num_classes=num_labels)\n",
    "\n",
    "acc_val_ak = np.sum(preds_val_ak == y_test) / y_test.shape[0]\n",
    "print(f\"Akida test set accuracy: {100 * acc_val_ak:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44061cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Akida model\n",
    "\n",
    "akida_model.save('akida_model_edge.fbz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b271b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 3 classes\n",
    "\n",
    "akida_model.add_classes(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f32584fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Edge learning with 3 new classes ...\n",
      "Elapsed time for Akida edge learning: 3.96 s\n"
     ]
    }
   ],
   "source": [
    "# Train the Akida on the new keywords\n",
    "# Code Source: https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html\n",
    "\n",
    "print(\"\\nEdge learning with 3 new classes ...\")\n",
    "start = timer()\n",
    "akida_model.fit(x_train_edge, y_train_edge.astype(np.int32))\n",
    "end = timer()\n",
    "print(f\"Elapsed time for Akida edge learning: {end-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec7f0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of keywords used in the edge data set\n",
    "\n",
    "num_labels_edge = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c0c76f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida train set accuracy on old data set: 98.97 %\n",
      "Akida validation set accuracy on old data set: 94.01 %\n",
      "Akida test set accuracy on old data set: 93.27 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance on the different data sets\n",
    "\n",
    "preds_val_ak_old_train = akida_model.predict(x_train, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak_old_train == y_train) / y_train.shape[0]\n",
    "print(f\"Akida train set accuracy on old data set: {100 * acc_val_ak:.2f} %\")\n",
    "preds_val_ak_old_val = akida_model.predict(x_val, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak_old_val == y_val) / y_val.shape[0]\n",
    "print(f\"Akida validation set accuracy on old data set: {100 * acc_val_ak:.2f} %\")\n",
    "preds_val_ak_old_test = akida_model.predict(x_test, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak_old_test == y_test) / y_test.shape[0]\n",
    "print(f\"Akida test set accuracy on old data set: {100 * acc_val_ak:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e035815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida training set accuracy on new data set: 96.22 %\n",
      "Akida validation set accuracy on new data set: 92.94 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance on the edge data set. \n",
    "\n",
    "preds_val_ak_new_train = akida_model.predict(x_train_edge, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak_new_train == y_train_edge) / y_train_edge.shape[0]\n",
    "print(f\"Akida training set accuracy on new data set: {100 * acc_val_ak:.2f} %\")\n",
    "preds_val_ak_new_val = akida_model.predict(x_val_edge, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak_new_val == y_val_edge) / y_val_edge.shape[0]\n",
    "print(f\"Akida validation set accuracy on new data set: {100 * acc_val_ak:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a528c5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
