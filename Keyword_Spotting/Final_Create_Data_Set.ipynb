{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d240aca",
   "metadata": {},
   "source": [
    "<font size=\"5\">Create data set</font>\n",
    "\n",
    "Create a data set from the \"Google Speech Command Data Set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e44ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and dependencies\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "from tensorflow.python.ops import gen_audio_ops as audio_ops\n",
    "\n",
    "\n",
    "import akida\n",
    "import akida_models\n",
    "from akida_models import kws\n",
    "from akida_models.kws import preprocessing\n",
    "import cnn2snn\n",
    "from cnn2snn import check_model_compatibility\n",
    "from cnn2snn import quantize\n",
    "from cnn2snn import quantize_layer\n",
    "from cnn2snn import convert\n",
    "\n",
    "import librosa\n",
    "import scipy\n",
    "from scipy import io\n",
    "from scipy.io import wavfile\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1ac87",
   "metadata": {},
   "source": [
    "<font size=\"5\">1. Load the data set</font>\n",
    "\n",
    "The Google Speech Command data set is loaded in this section of the code as a randomly ordered list of directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16e53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, set seed for experiment reproducibility\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e46cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories of the data\n",
    "# Folder Silence only includes the silence category\n",
    "\n",
    "data_dir = pathlib.Path('data/Modded_Google')\n",
    "silence_dir = pathlib.Path('data/Modded_Google/silence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c21492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known and unknown commands: ['off' 'up' 'down' 'on' 'stop' 'yes' 'right' 'unknown' 'left' 'go' 'no'\n",
      " 'silence']\n"
     ]
    }
   ],
   "source": [
    "# Check if the keywords are the desired ones\n",
    "\n",
    "targets = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "\n",
    "targets = targets[targets != 'README.md']\n",
    "\n",
    "print('Known and unknown commands:', targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda59aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Modded_Google/off\n",
      "data/Modded_Google/up\n",
      "data/Modded_Google/down\n",
      "data/Modded_Google/on\n",
      "data/Modded_Google/stop\n",
      "data/Modded_Google/yes\n",
      "data/Modded_Google/right\n",
      "data/Modded_Google/unknown\n",
      "data/Modded_Google/left\n",
      "data/Modded_Google/go\n",
      "data/Modded_Google/no\n",
      "data/Modded_Google/silence\n"
     ]
    }
   ],
   "source": [
    "# Create list of file names, along with its target \n",
    "\n",
    "filenames = []\n",
    "y = []\n",
    "for i, target in enumerate(targets):\n",
    "    print(join(data_dir, target))\n",
    "    filenames.append(listdir(join(data_dir, target)))\n",
    "    y.append(np.ones(len(filenames[i])) * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "291c86fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 402)\n"
     ]
    }
   ],
   "source": [
    "# Create list with all the silence file names\n",
    "# The targets in this case are note neccessary because these files are used later as added noise\n",
    "\n",
    "silence_filenames = []\n",
    "silence_filenames.append(listdir(silence_dir))\n",
    "print(np.shape(silence_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97e0216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filenames:  106231\n",
      "y:  106231\n"
     ]
    }
   ],
   "source": [
    "# Flatten the array to make it a list instead of a list of arrays\n",
    "\n",
    "filenames = [item for sublist in filenames for item in sublist]\n",
    "y = [item for sublist in y for item in sublist]\n",
    "print('Filenames: ', len(filenames))\n",
    "print('y: ', len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8c498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 14:24:20.406635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.467036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.467217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.468119: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-21 14:24:20.468526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.468664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.468781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.803998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.804174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.804294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 14:24:20.804392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9349 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filenames:  95792\n",
      "y:  95792\n"
     ]
    }
   ],
   "source": [
    "# Exclude files that are not one second in length\n",
    "\n",
    "filenames_temp = []\n",
    "y_temp=[]\n",
    "\n",
    "\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "\n",
    "    path = join(data_dir, targets[int(y[index])], filename)\n",
    "    wav_loader = tf.io.read_file(path)\n",
    "    wav_decoder = tf.audio.decode_wav(wav_loader,desired_channels=1, desired_samples=-1)\n",
    "    \n",
    "    if wav_decoder[0].shape == (16000,1):\n",
    "        filenames_temp.append(filename)\n",
    "        y_temp.append(y[index])\n",
    "\n",
    "filenames = filenames_temp\n",
    "y = y_temp\n",
    "\n",
    "print('Filenames: ', len(filenames))\n",
    "print('y: ', len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa820f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 3427,\n",
       " 1.0: 3269,\n",
       " 2.0: 3580,\n",
       " 3.0: 3471,\n",
       " 4.0: 3563,\n",
       " 5.0: 3692,\n",
       " 6.0: 3448,\n",
       " 7.0: 60419,\n",
       " 8.0: 3502,\n",
       " 9.0: 3478,\n",
       " 10.0: 3545,\n",
       " 11.0: 398}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of all labels after the conversion\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674434d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4371\n"
     ]
    }
   ],
   "source": [
    "# There are 34975 files that are not unkown or silence \n",
    "# Create number that should be equal to 10 % of the final data set\n",
    "# This number is later used, such that the category \"silence\" and \"unkown\" make up 10% of the data.\n",
    "\n",
    "amount_sil_un = 34975 / 0.8\n",
    "amount_sil_un = amount_sil_un * 0.1\n",
    "print(int(amount_sil_un))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ef5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    }
   ],
   "source": [
    "# Make file names of silence to one long list \n",
    "\n",
    "silence_filenames = np.squeeze(silence_filenames)\n",
    "\n",
    "# Print the length in order to check if something has changed\n",
    "\n",
    "print(len(silence_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c34bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silence Filenames:  398\n"
     ]
    }
   ],
   "source": [
    "# Include only the silence files which have a total of one second in length\n",
    "\n",
    "silence_temp = []\n",
    "\n",
    "\n",
    "for index, filename in enumerate(silence_filenames):\n",
    "\n",
    "    path = join(silence_dir, filename)\n",
    "    wav_loader = tf.io.read_file(path)\n",
    "    wav_decoder = tf.audio.decode_wav(wav_loader,desired_channels=1, desired_samples=-1)\n",
    "    \n",
    "    if wav_decoder[0].shape == (16000,1):\n",
    "        silence_temp.append(filename)\n",
    "\n",
    "silence_filenames = silence_temp\n",
    "\n",
    "print('Silence Filenames: ', len(silence_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6152636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31dude_miaowing.wav\n",
      "19exercise_bike.wav\n"
     ]
    }
   ],
   "source": [
    "# Shuffle file names of the silence category\n",
    "# Print the first position of the list to check if it worked\n",
    "\n",
    "print(silence_filenames[0])\n",
    "random.shuffle(silence_filenames)\n",
    "print(silence_filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af181116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39744\n"
     ]
    }
   ],
   "source": [
    "# Randomly select files of the \"unknown\" category in order to match the 10% constraint\n",
    "\n",
    "filenames_target = list(zip(filenames, y))\n",
    "random.shuffle(filenames_target)\n",
    "#print(filenames_target)\n",
    "counter = 0\n",
    "index = 0\n",
    "unknown_id = 7\n",
    "result = []\n",
    "for i in filenames_target:\n",
    "    if filenames_target[index][1] != unknown_id:\n",
    "        result.append(i)\n",
    "    if filenames_target[index][1] == unknown_id:\n",
    "        counter += 1\n",
    "        if counter <= amount_sil_un:\n",
    "            result.append(i)\n",
    "    index += 1\n",
    "filenames_target = result\n",
    "    \n",
    "print(len(filenames_target))\n",
    "#print(filenames_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3cfb8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 3427,\n",
       " 1.0: 3269,\n",
       " 2.0: 3580,\n",
       " 3.0: 3471,\n",
       " 4.0: 3563,\n",
       " 5.0: 3692,\n",
       " 6.0: 3448,\n",
       " 7.0: 4371,\n",
       " 8.0: 3502,\n",
       " 9.0: 3478,\n",
       " 10.0: 3545,\n",
       " 11.0: 398}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the distribution still matches the one from the beginning. \n",
    "\n",
    "filenames, y = zip(*filenames_target)\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a76db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate silence files in random order till it is 10% of the data\n",
    "# The randomness was introduced by previously shuffling the set\n",
    "\n",
    "\n",
    "counter = 398\n",
    "silence_id = 11\n",
    "result = filenames_target\n",
    "index = 0\n",
    "\n",
    "while counter <= amount_sil_un:\n",
    "    for i in filenames_target:\n",
    "        if filenames_target[index][1] == silence_id:\n",
    "            if counter <= amount_sil_un:\n",
    "                result.append(i)\n",
    "                counter +=1\n",
    "        index += 1\n",
    "    \n",
    "    \n",
    "\n",
    "filenames_target = result\n",
    "#print(counter)\n",
    "#print(len(filenames_target))\n",
    "#print(filenames_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab642a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43718\n"
     ]
    }
   ],
   "source": [
    "# Shuffle filenames again and unzip\n",
    "\n",
    "#filenames_target = list(zip(filenames, y))\n",
    "random.shuffle(filenames_target)\n",
    "filenames, y = zip(*filenames_target)\n",
    "\n",
    "# Check if data has the right length\n",
    "\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8dee0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 3427,\n",
       " 1.0: 3269,\n",
       " 2.0: 3580,\n",
       " 3.0: 3471,\n",
       " 4.0: 3563,\n",
       " 5.0: 3692,\n",
       " 6.0: 3448,\n",
       " 7.0: 4371,\n",
       " 8.0: 3502,\n",
       " 9.0: 3478,\n",
       " 10.0: 3545,\n",
       " 11.0: 4372}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if nothing changed besideds \"unknown\" and \"silence\"\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5088aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% :  34974\n",
      "10% :  4371\n",
      "Number of total samples:  43718\n",
      "80% + 10% + 10% :  43716\n",
      "Number of samples that would be left out :  2\n"
     ]
    }
   ],
   "source": [
    "# Indexing such that no file gets left out due to the integer precision\n",
    "\n",
    "num_samples = (len(filenames_target))\n",
    "\n",
    "a = num_samples * 0.8\n",
    "b = num_samples * 0.1\n",
    "c = num_samples - int(a) - int(b) - int(b)\n",
    "int(a)\n",
    "int(b)\n",
    "print('80% : ', int(a))\n",
    "print('10% : ', int(b))\n",
    "print('Number of total samples: ', num_samples)\n",
    "print('80% + 10% + 10% : ', int(a) + int(b) + int(b))\n",
    "print('Number of samples that would be left out : ', int(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ba10dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 34976\n",
      "Validation set size 4371\n",
      "Test set size 4371\n"
     ]
    }
   ],
   "source": [
    "# Split and print all sets\n",
    "\n",
    "train_files = filenames[:int(a)+int(c)]\n",
    "val_files = filenames[int(a)+int(c): int(a)+int(c) + int(b)]\n",
    "test_files = filenames[-int(b):]\n",
    "\n",
    "print('Training set size', len(train_files))\n",
    "print('Validation set size', len(val_files))\n",
    "print('Test set size', len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f85d5474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 34976\n",
      "Validation set size 4371\n",
      "Test set size 4371\n"
     ]
    }
   ],
   "source": [
    "# Same splitting procedure for target labels \n",
    "\n",
    "y_train = y[:int(a)+int(c)]\n",
    "y_val = y[int(a)+int(c): int(a)+int(c) + int(b)]\n",
    "y_test = y[-int(b):]\n",
    "\n",
    "print('Training set size', len(y_train))\n",
    "print('Validation set size', len(y_val))\n",
    "print('Test set size', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a6d3c",
   "metadata": {},
   "source": [
    "<font size=\"5\">2. Define MFCC functions </font>\n",
    "\n",
    "In this chapter the functions for calculating the MFCCs are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a44ff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'desired_samples': 16000, 'window_size_samples': 480, 'window_stride_samples': 160, 'spectrogram_length': 98, 'fingerprint_width': 40, 'fingerprint_size': 3920}\n"
     ]
    }
   ],
   "source": [
    " model_settings = akida_models.kws.preprocessing.prepare_model_settings(sample_rate = 16000, clip_duration_ms = 1000, window_size_ms = 30, window_stride_ms = 10, feature_bin_count = 40)\n",
    "print(model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6f6ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Create MFCC from given path\n",
    "\n",
    "def calc_mfcc(path,num_ceps):\n",
    "    \n",
    "    # Load wave file\n",
    "    \n",
    "    wav_loader = tf.io.read_file(path)\n",
    "    #wav_decoder = tf.audio.decode_wav(wav_loader,desired_channels=1, desired_samples=model_settings['desired_samples'])\n",
    "    wav_decoder = tf.audio.decode_wav(wav_loader,desired_channels=1, desired_samples=-1)\n",
    "    if wav_decoder[0].shape != (16000,1):\n",
    "        return wav_decoder.audio\n",
    "        \n",
    "    \n",
    "    # Randomly shift position to either 100ms forward or backward \n",
    "\n",
    "        \n",
    "    position = random.randint(0,1)\n",
    "    if position == 0:\n",
    "        paddings = [[0, int(model_settings['desired_samples']*0.1)], [0, 0]]\n",
    "        begin = [int(model_settings['desired_samples']*0.1),0]\n",
    "    if position == 1:\n",
    "        paddings = [[int(model_settings['desired_samples']*0.1), 0], [0, 0]]\n",
    "        begin = [0,0]\n",
    "    scaled_wav_decoder = tf.multiply(wav_decoder.audio, 1)\n",
    "    padded_wav_decoder = tf.pad(scaled_wav_decoder, paddings)\n",
    "    sliced_wav_decoder = tf.slice(padded_wav_decoder, begin = begin, size = [model_settings['desired_samples'], -1])\n",
    "\n",
    "    # Take random silence file and add it to the signal in range between 0 and 0.1\n",
    "\n",
    "    rand_silence = random.randint(0,len(silence_filenames) - 1)\n",
    "    rand_amount = random.uniform(0, 0.1)\n",
    "    silence_loader = tf.io.read_file(join(silence_dir,silence_filenames[rand_silence]))\n",
    "    silence_decoder = tf.audio.decode_wav(silence_loader,desired_channels=1, desired_samples=model_settings['desired_samples'])\n",
    "    silence_padded_wav = tf.add(sliced_wav_decoder, tf.multiply(silence_decoder.audio, rand_amount))\n",
    "    silence_padded_wav = tf.squeeze(silence_padded_wav)\n",
    "    silence_padded_wav = silence_padded_wav.numpy()\n",
    "\n",
    "    # Create MFCC of the augmented signal\n",
    "\n",
    "    output = librosa.feature.mfcc(y=silence_padded_wav,sr=model_settings['desired_samples'],n_mfcc=model_settings['fingerprint_width'],n_fft=512,win_length=model_settings['window_size_samples'],hop_length=model_settings['window_stride_samples'])\n",
    "\n",
    "\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44d032b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of problematic samples: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Test if the function works properly and outputs the desired dimension of the UltraTrail setup\n",
    "\n",
    "prob_cnt = 0\n",
    "x_test_s = []\n",
    "y_test_s = []\n",
    "num_ceps = 101\n",
    "\n",
    "for index, filename in enumerate(train_files):\n",
    "    \n",
    "    # Stop after 500\n",
    "    if index >= 100:\n",
    "        break\n",
    "    \n",
    "    # Create path from given filename and target item\n",
    "    path = join(data_dir, targets[int(y_train[index])], \n",
    "                filename)\n",
    "    \n",
    "    # Create MFCCs\n",
    "    mfccs = calc_mfcc(path,num_ceps)\n",
    "    \n",
    "    if mfccs.shape[1] == num_ceps:\n",
    "        x_test_s.append(mfccs)\n",
    "        y_test_s.append(y_train[index])\n",
    "    else:\n",
    "        print('Dropped:', index, mfccs.shape)\n",
    "        prob_cnt += 1\n",
    "        \n",
    "print('% of problematic samples:', prob_cnt / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac81fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 101)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_s[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08d3e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates the MFCC and check if they have the desired length \n",
    "\n",
    "def extract_features(samples, labels, num_ceps):\n",
    "    prob_cnt = 0\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "        \n",
    "    for index, filename in enumerate(samples):\n",
    "\n",
    "        # Create path from given filename and target item\n",
    "        path = join(data_dir, targets[int(labels[index])], \n",
    "                    filename)\n",
    "\n",
    "        # Create MFCCs\n",
    "        mfccs = calc_mfcc(path,num_ceps)\n",
    "\n",
    "        if mfccs.shape[1] == num_ceps:\n",
    "            out_x.append(mfccs)\n",
    "            out_y.append(labels[index])\n",
    "        else:\n",
    "            print('Dropped:', index, mfccs.shape)\n",
    "            prob_cnt += 1\n",
    "\n",
    "    return out_x, out_y, prob_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ba61e",
   "metadata": {},
   "source": [
    "<font size=\"5\">3. Save the MFCCs </font>\n",
    "\n",
    "Save the MFCCs including their targets seperated into training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d88e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed percentage: 0.0\n",
      "Removed percentage: 0.0\n",
      "Removed percentage: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Create train, validation, and test sets\n",
    "\n",
    "x_train, y_train, prob = extract_features(train_files, y_train, num_ceps)\n",
    "print('Removed percentage:', prob / len(y_train))\n",
    "x_val, y_val, prob = extract_features(val_files, y_val, num_ceps)\n",
    "print('Removed percentage:', prob / len(y_val))\n",
    "x_test, y_test, prob = extract_features(test_files, y_test, num_ceps)\n",
    "print('Removed percentage:', prob / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05f6519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MFCCs and their target\n",
    "\n",
    "feature_sets_file = 'stored_files_targets.npz'\n",
    "np.savez(feature_sets_file, \n",
    "         x_train=x_train, \n",
    "         y_train=y_train, \n",
    "         x_val=x_val, \n",
    "         y_val= y_val, \n",
    "         x_test=x_test, \n",
    "         y_test=y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f399f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if everything worked correctly \n",
    "\n",
    "feature_sets = np.load(feature_sets_file)\n",
    "feature_sets.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9119e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
