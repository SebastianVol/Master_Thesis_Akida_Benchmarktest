{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bece0ff0",
   "metadata": {},
   "source": [
    "<font size=\"5\">Second UltraTrail Run</font>\n",
    "\n",
    "In this notebook the performance of an Akida model is evaluated on a data set according to the UltraTrail\n",
    "experimental setup. The noise in the test set is fixed to a certain SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d98b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and dependencies\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "import akida\n",
    "from akida import FullyConnected\n",
    "from akida import evaluate_sparsity\n",
    "import cnn2snn\n",
    "from cnn2snn import check_model_compatibility\n",
    "from cnn2snn import quantize\n",
    "from cnn2snn import quantize_layer\n",
    "from cnn2snn import convert\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import (Input, Reshape, Activation, Flatten, Rescaling, Add, Dropout)\n",
    "\n",
    "import akida_models\n",
    "from akida_models import layer_blocks\n",
    "from akida_models.layer_blocks import conv_block, separable_conv_block, dense_block\n",
    "\n",
    "\n",
    "from math import ceil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004de406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, set seed for experiment reproducibility\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c1c1c5",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 1. Load the Data Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7801fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory\n",
    "\n",
    "data_dir = pathlib.Path('data/Modded_Google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c09dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known and unknown commands: ['off' 'up' 'down' 'on' 'stop' 'yes' 'right' 'unknown' 'left' 'go' 'no'\n",
      " 'silence']\n"
     ]
    }
   ],
   "source": [
    "# Check commands\n",
    "\n",
    "targets = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "targets = targets[targets != 'README.md']\n",
    "\n",
    "print('Known and unknown commands:', targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf58b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading preprocessed Data\n",
    "\n",
    "feature_sets_path = '/home/sebastian/Schreibtisch/Masterarbeit/Audio/'\n",
    "feature_sets_filename = 'final_SNR_audio.npz'\n",
    "\n",
    "CNN_model_filename = 'final_CNN_ultratrail_SNR_model.h5'\n",
    "Quantized_model_filename = 'final_quantized_ultratrail_SNR_model.h5'\n",
    "Akida_model_filename = 'final_akida_ultratrail_SNR_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7da8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Sets:  ['x_train', 'y_train', 'x_val', 'y_val', 'x_test1', 'y_test1', 'x_test10', 'y_test10', 'x_test20', 'y_test20', 'x_test100', 'y_test100', 'x_test1000', 'y_test1000']\n"
     ]
    }
   ],
   "source": [
    "# Load feature sets\n",
    "\n",
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "\n",
    "print('Feature Sets: ', feature_sets.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d22817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets\n",
    "\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "\n",
    "x_test1 = feature_sets['x_test1']\n",
    "y_test1 = feature_sets['y_test1']\n",
    "x_test10 = feature_sets['x_test10']\n",
    "y_test10 = feature_sets['y_test10']\n",
    "x_test20 = feature_sets['x_test20']\n",
    "y_test20 = feature_sets['y_test20']\n",
    "x_test100 = feature_sets['x_test100']\n",
    "y_test100 = feature_sets['y_test100']\n",
    "x_test1000 = feature_sets['x_test1000']\n",
    "y_test1000 = feature_sets['y_test1000']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3614c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (34976, 40, 101)\n",
      "x_val shape:  (4371, 40, 101)\n",
      "x_test shape:  (4371, 40, 101)\n"
     ]
    }
   ],
   "source": [
    "# Look at tensor dimensions\n",
    "\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('x_val shape: ', x_val.shape)\n",
    "print('x_test shape: ', x_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834f237",
   "metadata": {},
   "source": [
    "Check the dimensions of the data set. \n",
    "Is the unknown and silence category roughly 10% (Category 7 and 11)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7391d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 2697,\n",
       " 1.0: 2606,\n",
       " 2.0: 2889,\n",
       " 3.0: 2747,\n",
       " 4.0: 2874,\n",
       " 5.0: 2966,\n",
       " 6.0: 2747,\n",
       " 7.0: 3513,\n",
       " 8.0: 2770,\n",
       " 9.0: 2786,\n",
       " 10.0: 2849,\n",
       " 11.0: 3532}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e59bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 358,\n",
       " 1.0: 340,\n",
       " 2.0: 343,\n",
       " 3.0: 373,\n",
       " 4.0: 335,\n",
       " 5.0: 358,\n",
       " 6.0: 363,\n",
       " 7.0: 439,\n",
       " 8.0: 381,\n",
       " 9.0: 335,\n",
       " 10.0: 333,\n",
       " 11.0: 413}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4a5de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 372,\n",
       " 1.0: 323,\n",
       " 2.0: 348,\n",
       " 3.0: 351,\n",
       " 4.0: 354,\n",
       " 5.0: 368,\n",
       " 6.0: 338,\n",
       " 7.0: 419,\n",
       " 8.0: 351,\n",
       " 9.0: 357,\n",
       " 10.0: 363,\n",
       " 11.0: 427}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test1, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe971e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels:  12\n"
     ]
    }
   ],
   "source": [
    "# Define the number of labels\n",
    "\n",
    "num_labels = len(unique)\n",
    "print('number of labels: ', num_labels)\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc71662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add dimension to all data: Order Train, Val, Test\n",
      "(34976, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN for conversion expects (batch, height, width, channels)\n",
    "# The channels can either be 1 for gray-scaled images or 3 for RGB-images\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "x_val = x_val.reshape(x_val.shape[0], \n",
    "                      x_val.shape[1], \n",
    "                      x_val.shape[2], \n",
    "                      1)\n",
    "\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0], \n",
    "                        x_test1.shape[1], \n",
    "                        x_test1.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_test10 = x_test10.reshape(x_test10.shape[0], \n",
    "                        x_test10.shape[1], \n",
    "                        x_test10.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_test20 = x_test20.reshape(x_test20.shape[0], \n",
    "                        x_test20.shape[1], \n",
    "                        x_test20.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_test100 = x_test100.reshape(x_test100.shape[0], \n",
    "                        x_test100.shape[1], \n",
    "                        x_test100.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_test1000 = x_test1000.reshape(x_test1000.shape[0], \n",
    "                        x_test1000.shape[1], \n",
    "                        x_test1000.shape[2], \n",
    "                        1)\n",
    "\n",
    "\n",
    "print('Add dimension to all data: Order Train, Val, Test')\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test1.shape)\n",
    "print(x_test10.shape)\n",
    "print(x_test20.shape)\n",
    "print(x_test100.shape)\n",
    "print(x_test1000.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e50af6",
   "metadata": {},
   "source": [
    "<font size=\"5\">2. Train and Save the CNN-Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0476781a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of 1 Tensor/MFCC:  (40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape for the CNN, namely the dimension of 1 MFCC\n",
    "\n",
    "input_shape = x_test1.shape[1:]\n",
    "print('Input shape of 1 Tensor/MFCC: ', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e285a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 21:34:30.803581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:30.837321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:30.837489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:30.838049: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-17 21:34:30.838734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:30.838869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:30.838982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:31.178162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:31.178314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:31.178425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 21:34:31.178522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9495 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 20, 51, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_0_BN (BatchNormalizatio (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ReLU)           (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (SeparableConv2D (None, 20, 51, 32)        1312      \n",
      "_________________________________________________________________\n",
      "separable_1_BN (BatchNormali (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "separable_1_relu (ReLU)      (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (SeparableConv2D (None, 10, 26, 64)        2336      \n",
      "_________________________________________________________________\n",
      "separable_2_BN (BatchNormali (None, 10, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_2_relu (ReLU)      (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (SeparableConv2D (None, 10, 26, 128)       8768      \n",
      "_________________________________________________________________\n",
      "separable_3_BN (BatchNormali (None, 10, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_3_relu (ReLU)      (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (SeparableConv2D (None, 5, 13, 128)        17536     \n",
      "_________________________________________________________________\n",
      "separable_4_BN (BatchNormali (None, 5, 13, 128)        512       \n",
      "_________________________________________________________________\n",
      "separable_4_relu (ReLU)      (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (SeparableConv2D (None, 5, 13, 256)        33920     \n",
      "_________________________________________________________________\n",
      "separable_5_BN (BatchNormali (None, 5, 13, 256)        1024      \n",
      "_________________________________________________________________\n",
      "separable_5_relu (ReLU)      (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (SeparableConv2D (None, 3, 7, 256)         67840     \n",
      "_________________________________________________________________\n",
      "separable_6_BN (BatchNormali (None, 3, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "separable_6_relu (ReLU)      (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (SeparableConv2D (None, 2, 4, 512)         133376    \n",
      "_________________________________________________________________\n",
      "separable_7_BN (BatchNormali (None, 2, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "separable_7_relu (ReLU)      (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (SeparableConv2D (None, 2, 4, 1024)        528896    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_BN (BatchNormali (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "separable_8_relu (ReLU)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 816,348\n",
      "Trainable params: 811,460\n",
      "Non-trainable params: 4,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN created with the functional API and from akida_models layer_blocks\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Rescaling(1. / 255)(inputs)\n",
    "x = conv_block(x,\n",
    "               filters=32,\n",
    "               kernel_size=(3, 3),\n",
    "               padding='same',\n",
    "               strides=(2, 2),\n",
    "               use_bias=False,\n",
    "               name='conv_0',\n",
    "               add_batchnorm=True)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=32,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_1',\n",
    "                         add_batchnorm=True)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=64,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_2',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=128,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_3',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=128,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_4',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=256,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_5',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=256,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_6',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=512,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_7',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=1024,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_8',\n",
    "                         pooling='global_avg',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "shape = (1, 1, int(1024))\n",
    "x = Reshape(shape, name='reshape_1')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = layers.Dense(units = 12, activation='linear', use_bias = True)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "outputs = layers.Activation('softmax')(x)\n",
    "\n",
    "CNN_model = keras.Model(inputs=inputs, outputs=outputs, name='CNN_model')\n",
    "\n",
    "CNN_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a1e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compatible for Akida conversion: True\n"
     ]
    }
   ],
   "source": [
    "# Check if model is compatible\n",
    "\n",
    "print(\"Model compatible for Akida conversion:\", check_model_compatibility(CNN_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208c5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN model\n",
    "\n",
    "CNN_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25eb38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 21:34:38.648478: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 21:34:41.261574: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8301\n",
      "2022-04-17 21:34:43.858974: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-17 21:34:44.400677: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 17s 10ms/step - loss: 2.2575 - accuracy: 0.2091 - val_loss: 2.1397 - val_accuracy: 0.3175\n",
      "Epoch 2/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 1.4000 - accuracy: 0.5518 - val_loss: 0.8911 - val_accuracy: 0.7138\n",
      "Epoch 3/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.9847 - accuracy: 0.6896 - val_loss: 0.7276 - val_accuracy: 0.7728\n",
      "Epoch 4/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.8087 - accuracy: 0.7471 - val_loss: 0.5561 - val_accuracy: 0.8250\n",
      "Epoch 5/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.7142 - accuracy: 0.7762 - val_loss: 0.5430 - val_accuracy: 0.8254\n",
      "Epoch 6/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.6523 - accuracy: 0.7981 - val_loss: 0.7136 - val_accuracy: 0.7881\n",
      "Epoch 7/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.6029 - accuracy: 0.8139 - val_loss: 0.4527 - val_accuracy: 0.8545\n",
      "Epoch 8/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.5579 - accuracy: 0.8275 - val_loss: 0.4033 - val_accuracy: 0.8742\n",
      "Epoch 9/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.5272 - accuracy: 0.8378 - val_loss: 0.4637 - val_accuracy: 0.8636\n",
      "Epoch 10/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.5046 - accuracy: 0.8427 - val_loss: 0.4331 - val_accuracy: 0.8749\n",
      "Epoch 11/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.4729 - accuracy: 0.8540 - val_loss: 0.3222 - val_accuracy: 0.8936\n",
      "Epoch 12/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.4574 - accuracy: 0.8580 - val_loss: 0.3685 - val_accuracy: 0.8890\n",
      "Epoch 13/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.4420 - accuracy: 0.8640 - val_loss: 0.3258 - val_accuracy: 0.8991\n",
      "Epoch 14/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.4169 - accuracy: 0.8720 - val_loss: 0.3315 - val_accuracy: 0.8959\n",
      "Epoch 15/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.4059 - accuracy: 0.8737 - val_loss: 0.2992 - val_accuracy: 0.9039\n",
      "Epoch 16/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3918 - accuracy: 0.8793 - val_loss: 0.2845 - val_accuracy: 0.9080\n",
      "Epoch 17/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3841 - accuracy: 0.8801 - val_loss: 0.3028 - val_accuracy: 0.9044\n",
      "Epoch 18/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.3681 - accuracy: 0.8843 - val_loss: 0.2898 - val_accuracy: 0.9124\n",
      "Epoch 19/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3584 - accuracy: 0.8875 - val_loss: 0.2949 - val_accuracy: 0.9101\n",
      "Epoch 20/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3586 - accuracy: 0.8891 - val_loss: 0.2858 - val_accuracy: 0.9117\n",
      "Epoch 21/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3389 - accuracy: 0.8951 - val_loss: 0.2452 - val_accuracy: 0.9256\n",
      "Epoch 22/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3354 - accuracy: 0.8955 - val_loss: 0.2623 - val_accuracy: 0.9188\n",
      "Epoch 23/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3285 - accuracy: 0.8966 - val_loss: 0.2595 - val_accuracy: 0.9204\n",
      "Epoch 24/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3249 - accuracy: 0.8972 - val_loss: 0.2912 - val_accuracy: 0.9089\n",
      "Epoch 25/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3162 - accuracy: 0.9008 - val_loss: 0.2917 - val_accuracy: 0.9064\n",
      "Epoch 26/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3118 - accuracy: 0.9023 - val_loss: 0.2674 - val_accuracy: 0.9176\n",
      "Epoch 27/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3022 - accuracy: 0.9031 - val_loss: 0.2398 - val_accuracy: 0.9243\n",
      "Epoch 28/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2979 - accuracy: 0.9043 - val_loss: 0.2463 - val_accuracy: 0.9270\n",
      "Epoch 29/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2935 - accuracy: 0.9065 - val_loss: 0.2599 - val_accuracy: 0.9170\n",
      "Epoch 30/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2882 - accuracy: 0.9088 - val_loss: 0.2319 - val_accuracy: 0.9318\n",
      "Epoch 31/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2840 - accuracy: 0.9100 - val_loss: 0.2234 - val_accuracy: 0.9277\n",
      "Epoch 32/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2876 - accuracy: 0.9083 - val_loss: 0.2328 - val_accuracy: 0.9250\n",
      "Epoch 33/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2729 - accuracy: 0.9125 - val_loss: 0.2209 - val_accuracy: 0.9295\n",
      "Epoch 34/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2722 - accuracy: 0.9127 - val_loss: 0.2120 - val_accuracy: 0.9332\n",
      "Epoch 35/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2716 - accuracy: 0.9137 - val_loss: 0.2139 - val_accuracy: 0.9314\n",
      "Epoch 36/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2663 - accuracy: 0.9168 - val_loss: 0.2317 - val_accuracy: 0.9220\n",
      "Epoch 37/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2634 - accuracy: 0.9171 - val_loss: 0.2274 - val_accuracy: 0.9311\n",
      "Epoch 38/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2596 - accuracy: 0.9164 - val_loss: 0.2211 - val_accuracy: 0.9288\n",
      "Epoch 39/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2540 - accuracy: 0.9177 - val_loss: 0.2123 - val_accuracy: 0.9316\n",
      "Epoch 40/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2538 - accuracy: 0.9186 - val_loss: 0.2219 - val_accuracy: 0.9305\n",
      "Epoch 41/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2514 - accuracy: 0.9188 - val_loss: 0.2130 - val_accuracy: 0.9318\n",
      "Epoch 42/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2452 - accuracy: 0.9207 - val_loss: 0.2220 - val_accuracy: 0.9300\n",
      "Epoch 43/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2411 - accuracy: 0.9223 - val_loss: 0.2145 - val_accuracy: 0.9327\n",
      "Epoch 44/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2394 - accuracy: 0.9229 - val_loss: 0.2135 - val_accuracy: 0.9332\n",
      "Epoch 45/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2351 - accuracy: 0.9246 - val_loss: 0.2210 - val_accuracy: 0.9339\n",
      "Epoch 46/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2357 - accuracy: 0.9238 - val_loss: 0.2257 - val_accuracy: 0.9327\n",
      "Epoch 47/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2288 - accuracy: 0.9258 - val_loss: 0.2100 - val_accuracy: 0.9346\n",
      "Epoch 48/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2294 - accuracy: 0.9258 - val_loss: 0.2146 - val_accuracy: 0.9341\n",
      "Epoch 49/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2228 - accuracy: 0.9281 - val_loss: 0.2124 - val_accuracy: 0.9334\n",
      "Epoch 50/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2238 - accuracy: 0.9263 - val_loss: 0.2091 - val_accuracy: 0.9348\n",
      "Epoch 51/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2258 - accuracy: 0.9269 - val_loss: 0.2076 - val_accuracy: 0.9373\n",
      "Epoch 52/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2230 - accuracy: 0.9271 - val_loss: 0.2025 - val_accuracy: 0.9378\n",
      "Epoch 53/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2168 - accuracy: 0.9276 - val_loss: 0.2004 - val_accuracy: 0.9417\n",
      "Epoch 54/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2194 - accuracy: 0.9275 - val_loss: 0.2143 - val_accuracy: 0.9341\n",
      "Epoch 55/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2158 - accuracy: 0.9286 - val_loss: 0.2173 - val_accuracy: 0.9373\n",
      "Epoch 56/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2096 - accuracy: 0.9312 - val_loss: 0.2068 - val_accuracy: 0.9378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2138 - accuracy: 0.9296 - val_loss: 0.2077 - val_accuracy: 0.9366\n",
      "Epoch 58/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2079 - accuracy: 0.9326 - val_loss: 0.2151 - val_accuracy: 0.9325\n",
      "Epoch 59/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2114 - accuracy: 0.9298 - val_loss: 0.2330 - val_accuracy: 0.9314\n",
      "Epoch 60/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2022 - accuracy: 0.9328 - val_loss: 0.2059 - val_accuracy: 0.9380\n",
      "Epoch 61/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2000 - accuracy: 0.9352 - val_loss: 0.2021 - val_accuracy: 0.9398\n",
      "Epoch 62/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2025 - accuracy: 0.9327 - val_loss: 0.1952 - val_accuracy: 0.9401\n",
      "Epoch 63/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2001 - accuracy: 0.9339 - val_loss: 0.2107 - val_accuracy: 0.9403\n",
      "Epoch 64/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1963 - accuracy: 0.9360 - val_loss: 0.2123 - val_accuracy: 0.9373\n",
      "Epoch 65/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1979 - accuracy: 0.9360 - val_loss: 0.2194 - val_accuracy: 0.9325\n",
      "Epoch 66/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1911 - accuracy: 0.9371 - val_loss: 0.2136 - val_accuracy: 0.9348\n",
      "Epoch 67/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1934 - accuracy: 0.9354 - val_loss: 0.2184 - val_accuracy: 0.9353\n",
      "Epoch 68/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1945 - accuracy: 0.9359 - val_loss: 0.1927 - val_accuracy: 0.9403\n",
      "Epoch 69/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1910 - accuracy: 0.9375 - val_loss: 0.2061 - val_accuracy: 0.9387\n",
      "Epoch 70/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1848 - accuracy: 0.9391 - val_loss: 0.2016 - val_accuracy: 0.9410\n",
      "Epoch 71/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1882 - accuracy: 0.9383 - val_loss: 0.2106 - val_accuracy: 0.9355\n",
      "Epoch 72/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1863 - accuracy: 0.9381 - val_loss: 0.2090 - val_accuracy: 0.9323\n",
      "Epoch 73/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1829 - accuracy: 0.9396 - val_loss: 0.2093 - val_accuracy: 0.9380\n",
      "Epoch 74/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1823 - accuracy: 0.9395 - val_loss: 0.2113 - val_accuracy: 0.9348\n",
      "Epoch 75/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1831 - accuracy: 0.9394 - val_loss: 0.2035 - val_accuracy: 0.9398\n",
      "Epoch 76/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1843 - accuracy: 0.9411 - val_loss: 0.2142 - val_accuracy: 0.9378\n",
      "Epoch 77/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1757 - accuracy: 0.9423 - val_loss: 0.2077 - val_accuracy: 0.9389\n",
      "Epoch 78/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1751 - accuracy: 0.9418 - val_loss: 0.2034 - val_accuracy: 0.9382\n",
      "Epoch 79/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1750 - accuracy: 0.9422 - val_loss: 0.2069 - val_accuracy: 0.9366\n",
      "Epoch 80/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1769 - accuracy: 0.9418 - val_loss: 0.2059 - val_accuracy: 0.9382\n",
      "Epoch 81/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1744 - accuracy: 0.9432 - val_loss: 0.2182 - val_accuracy: 0.9288\n",
      "Epoch 82/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1706 - accuracy: 0.9428 - val_loss: 0.1896 - val_accuracy: 0.9423\n",
      "Epoch 83/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1707 - accuracy: 0.9426 - val_loss: 0.2045 - val_accuracy: 0.9410\n",
      "Epoch 84/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1678 - accuracy: 0.9441 - val_loss: 0.2014 - val_accuracy: 0.9421\n",
      "Epoch 85/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1719 - accuracy: 0.9428 - val_loss: 0.1979 - val_accuracy: 0.9382\n",
      "Epoch 86/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1638 - accuracy: 0.9461 - val_loss: 0.2003 - val_accuracy: 0.9407\n",
      "Epoch 87/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1643 - accuracy: 0.9444 - val_loss: 0.2093 - val_accuracy: 0.9389\n",
      "Epoch 88/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1671 - accuracy: 0.9443 - val_loss: 0.2136 - val_accuracy: 0.9364\n",
      "Epoch 89/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1655 - accuracy: 0.9450 - val_loss: 0.2161 - val_accuracy: 0.9357\n",
      "Epoch 90/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1660 - accuracy: 0.9448 - val_loss: 0.2189 - val_accuracy: 0.9382\n",
      "Epoch 91/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1641 - accuracy: 0.9448 - val_loss: 0.2036 - val_accuracy: 0.9401\n",
      "Epoch 92/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1609 - accuracy: 0.9480 - val_loss: 0.1956 - val_accuracy: 0.9430\n",
      "Epoch 93/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1623 - accuracy: 0.9464 - val_loss: 0.2158 - val_accuracy: 0.9387\n",
      "Epoch 94/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1597 - accuracy: 0.9474 - val_loss: 0.2307 - val_accuracy: 0.9369\n",
      "Epoch 95/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1580 - accuracy: 0.9468 - val_loss: 0.1988 - val_accuracy: 0.9396\n",
      "Epoch 96/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1607 - accuracy: 0.9465 - val_loss: 0.2101 - val_accuracy: 0.9353\n",
      "Epoch 97/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1570 - accuracy: 0.9470 - val_loss: 0.2222 - val_accuracy: 0.9334\n",
      "Epoch 98/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1565 - accuracy: 0.9468 - val_loss: 0.2061 - val_accuracy: 0.9398\n",
      "Epoch 99/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1511 - accuracy: 0.9497 - val_loss: 0.2010 - val_accuracy: 0.9407\n",
      "Epoch 100/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1588 - accuracy: 0.9481 - val_loss: 0.1972 - val_accuracy: 0.9426\n",
      "Epoch 101/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1533 - accuracy: 0.9477 - val_loss: 0.2286 - val_accuracy: 0.9375\n",
      "Epoch 102/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1523 - accuracy: 0.9483 - val_loss: 0.2055 - val_accuracy: 0.9401\n",
      "Epoch 103/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1535 - accuracy: 0.9490 - val_loss: 0.1933 - val_accuracy: 0.9421\n",
      "Epoch 104/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1533 - accuracy: 0.9486 - val_loss: 0.2036 - val_accuracy: 0.9405\n",
      "Epoch 105/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1498 - accuracy: 0.9493 - val_loss: 0.2212 - val_accuracy: 0.9366\n",
      "Epoch 106/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1517 - accuracy: 0.9489 - val_loss: 0.2221 - val_accuracy: 0.9366\n",
      "Epoch 107/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1495 - accuracy: 0.9503 - val_loss: 0.2115 - val_accuracy: 0.9385\n",
      "Epoch 108/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1518 - accuracy: 0.9493 - val_loss: 0.2083 - val_accuracy: 0.9364\n",
      "Epoch 109/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1483 - accuracy: 0.9503 - val_loss: 0.2143 - val_accuracy: 0.9407\n",
      "Epoch 110/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1450 - accuracy: 0.9512 - val_loss: 0.2229 - val_accuracy: 0.9311\n",
      "Epoch 111/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1481 - accuracy: 0.9506 - val_loss: 0.2016 - val_accuracy: 0.9414\n",
      "Epoch 112/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1446 - accuracy: 0.9509 - val_loss: 0.2143 - val_accuracy: 0.9398\n",
      "Epoch 113/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1424 - accuracy: 0.9497 - val_loss: 0.2198 - val_accuracy: 0.9391\n",
      "Epoch 114/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1435 - accuracy: 0.9517 - val_loss: 0.2082 - val_accuracy: 0.9396\n",
      "Epoch 115/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1443 - accuracy: 0.9511 - val_loss: 0.2033 - val_accuracy: 0.9419\n",
      "Epoch 116/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1399 - accuracy: 0.9530 - val_loss: 0.1924 - val_accuracy: 0.9419\n",
      "Epoch 117/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1398 - accuracy: 0.9522 - val_loss: 0.1971 - val_accuracy: 0.9442\n",
      "Epoch 118/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1462 - accuracy: 0.9515 - val_loss: 0.1918 - val_accuracy: 0.9423\n",
      "Epoch 119/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1390 - accuracy: 0.9543 - val_loss: 0.2029 - val_accuracy: 0.9403\n",
      "Epoch 120/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1383 - accuracy: 0.9534 - val_loss: 0.2108 - val_accuracy: 0.9412\n",
      "Epoch 121/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1387 - accuracy: 0.9533 - val_loss: 0.2050 - val_accuracy: 0.9421\n",
      "Epoch 122/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1416 - accuracy: 0.9519 - val_loss: 0.2033 - val_accuracy: 0.9423\n",
      "Epoch 123/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1363 - accuracy: 0.9539 - val_loss: 0.2005 - val_accuracy: 0.9396\n",
      "Epoch 124/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1381 - accuracy: 0.9547 - val_loss: 0.2011 - val_accuracy: 0.9394\n",
      "Epoch 125/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1368 - accuracy: 0.9534 - val_loss: 0.2283 - val_accuracy: 0.9366\n",
      "Epoch 126/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1352 - accuracy: 0.9539 - val_loss: 0.2261 - val_accuracy: 0.9371\n",
      "Epoch 127/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1336 - accuracy: 0.9551 - val_loss: 0.2049 - val_accuracy: 0.9389\n",
      "Epoch 128/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1327 - accuracy: 0.9550 - val_loss: 0.2065 - val_accuracy: 0.9417\n",
      "Epoch 129/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1321 - accuracy: 0.9557 - val_loss: 0.2095 - val_accuracy: 0.9401\n",
      "Epoch 130/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1322 - accuracy: 0.9550 - val_loss: 0.1987 - val_accuracy: 0.9419\n",
      "Epoch 131/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1326 - accuracy: 0.9556 - val_loss: 0.2156 - val_accuracy: 0.9350\n",
      "Epoch 132/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1339 - accuracy: 0.9555 - val_loss: 0.2121 - val_accuracy: 0.9412\n",
      "Epoch 133/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1295 - accuracy: 0.9561 - val_loss: 0.2210 - val_accuracy: 0.9380\n",
      "Epoch 134/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1310 - accuracy: 0.9565 - val_loss: 0.1980 - val_accuracy: 0.9433\n",
      "Epoch 135/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1335 - accuracy: 0.9561 - val_loss: 0.2068 - val_accuracy: 0.9446\n",
      "Epoch 136/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1305 - accuracy: 0.9563 - val_loss: 0.2056 - val_accuracy: 0.9412\n",
      "Epoch 137/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1318 - accuracy: 0.9553 - val_loss: 0.2066 - val_accuracy: 0.9396\n",
      "Epoch 138/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1266 - accuracy: 0.9571 - val_loss: 0.2132 - val_accuracy: 0.9412\n",
      "Epoch 139/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1302 - accuracy: 0.9558 - val_loss: 0.2090 - val_accuracy: 0.9407\n",
      "Epoch 140/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1263 - accuracy: 0.9571 - val_loss: 0.2171 - val_accuracy: 0.9378\n",
      "Epoch 141/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1332 - accuracy: 0.9549 - val_loss: 0.2002 - val_accuracy: 0.9437\n",
      "Epoch 142/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1234 - accuracy: 0.9588 - val_loss: 0.2111 - val_accuracy: 0.9417\n",
      "Epoch 143/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1269 - accuracy: 0.9569 - val_loss: 0.2023 - val_accuracy: 0.9414\n",
      "Epoch 144/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1217 - accuracy: 0.9596 - val_loss: 0.2025 - val_accuracy: 0.9435\n",
      "Epoch 145/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1251 - accuracy: 0.9582 - val_loss: 0.2131 - val_accuracy: 0.9369\n",
      "Epoch 146/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1277 - accuracy: 0.9568 - val_loss: 0.2096 - val_accuracy: 0.9375\n",
      "Epoch 147/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1238 - accuracy: 0.9575 - val_loss: 0.2225 - val_accuracy: 0.9371\n",
      "Epoch 148/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1260 - accuracy: 0.9561 - val_loss: 0.2069 - val_accuracy: 0.9382\n",
      "Epoch 149/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1199 - accuracy: 0.9590 - val_loss: 0.2048 - val_accuracy: 0.9421\n",
      "Epoch 150/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1259 - accuracy: 0.9567 - val_loss: 0.2191 - val_accuracy: 0.9382\n",
      "Epoch 151/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1262 - accuracy: 0.9573 - val_loss: 0.2314 - val_accuracy: 0.9359\n",
      "Epoch 152/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1251 - accuracy: 0.9581 - val_loss: 0.2060 - val_accuracy: 0.9405\n",
      "Epoch 153/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1190 - accuracy: 0.9595 - val_loss: 0.2187 - val_accuracy: 0.9401\n",
      "Epoch 154/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1174 - accuracy: 0.9600 - val_loss: 0.2261 - val_accuracy: 0.9369\n",
      "Epoch 155/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1169 - accuracy: 0.9618 - val_loss: 0.2184 - val_accuracy: 0.9391\n",
      "Epoch 156/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1191 - accuracy: 0.9597 - val_loss: 0.2217 - val_accuracy: 0.9387\n",
      "Epoch 157/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1205 - accuracy: 0.9583 - val_loss: 0.2179 - val_accuracy: 0.9398\n",
      "Epoch 158/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1186 - accuracy: 0.9597 - val_loss: 0.2044 - val_accuracy: 0.9419\n",
      "Epoch 159/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1211 - accuracy: 0.9595 - val_loss: 0.2034 - val_accuracy: 0.9398\n",
      "Epoch 160/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1198 - accuracy: 0.9592 - val_loss: 0.2097 - val_accuracy: 0.9405\n",
      "Epoch 161/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1196 - accuracy: 0.9607 - val_loss: 0.2209 - val_accuracy: 0.9371\n",
      "Epoch 162/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1204 - accuracy: 0.9598 - val_loss: 0.2026 - val_accuracy: 0.9430\n",
      "Epoch 163/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1206 - accuracy: 0.9591 - val_loss: 0.2232 - val_accuracy: 0.9378\n",
      "Epoch 164/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1173 - accuracy: 0.9591 - val_loss: 0.2107 - val_accuracy: 0.9458\n",
      "Epoch 165/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1106 - accuracy: 0.9611 - val_loss: 0.2594 - val_accuracy: 0.9364\n",
      "Epoch 166/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1173 - accuracy: 0.9604 - val_loss: 0.2219 - val_accuracy: 0.9366\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1134 - accuracy: 0.9610 - val_loss: 0.2177 - val_accuracy: 0.9414\n",
      "Epoch 168/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1171 - accuracy: 0.9603 - val_loss: 0.2097 - val_accuracy: 0.9417\n",
      "Epoch 169/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1114 - accuracy: 0.9621 - val_loss: 0.2189 - val_accuracy: 0.9385\n",
      "Epoch 170/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1127 - accuracy: 0.9617 - val_loss: 0.2179 - val_accuracy: 0.9419\n",
      "Epoch 171/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1133 - accuracy: 0.9622 - val_loss: 0.2212 - val_accuracy: 0.9389\n",
      "Epoch 172/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1129 - accuracy: 0.9625 - val_loss: 0.2302 - val_accuracy: 0.9357\n",
      "Epoch 173/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1137 - accuracy: 0.9610 - val_loss: 0.2256 - val_accuracy: 0.9373\n",
      "Epoch 174/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1145 - accuracy: 0.9615 - val_loss: 0.2138 - val_accuracy: 0.9439\n",
      "Epoch 175/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1100 - accuracy: 0.9617 - val_loss: 0.2102 - val_accuracy: 0.9405\n",
      "Epoch 176/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1097 - accuracy: 0.9624 - val_loss: 0.2156 - val_accuracy: 0.9405\n",
      "Epoch 177/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1134 - accuracy: 0.9630 - val_loss: 0.2112 - val_accuracy: 0.9449\n",
      "Epoch 178/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1121 - accuracy: 0.9620 - val_loss: 0.2170 - val_accuracy: 0.9414\n",
      "Epoch 179/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1097 - accuracy: 0.9619 - val_loss: 0.2542 - val_accuracy: 0.9369\n",
      "Epoch 180/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1082 - accuracy: 0.9644 - val_loss: 0.2306 - val_accuracy: 0.9396\n",
      "Epoch 181/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1110 - accuracy: 0.9629 - val_loss: 0.2114 - val_accuracy: 0.9407\n",
      "Epoch 182/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1105 - accuracy: 0.9621 - val_loss: 0.2311 - val_accuracy: 0.9353\n",
      "Epoch 183/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1073 - accuracy: 0.9649 - val_loss: 0.2338 - val_accuracy: 0.9412\n",
      "Epoch 184/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1089 - accuracy: 0.9634 - val_loss: 0.2153 - val_accuracy: 0.9430\n",
      "Epoch 185/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1046 - accuracy: 0.9643 - val_loss: 0.2181 - val_accuracy: 0.9403\n",
      "Epoch 186/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1024 - accuracy: 0.9644 - val_loss: 0.2087 - val_accuracy: 0.9458\n",
      "Epoch 187/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1107 - accuracy: 0.9624 - val_loss: 0.2162 - val_accuracy: 0.9456\n",
      "Epoch 188/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1081 - accuracy: 0.9639 - val_loss: 0.2211 - val_accuracy: 0.9442\n",
      "Epoch 189/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1046 - accuracy: 0.9651 - val_loss: 0.2222 - val_accuracy: 0.9405\n",
      "Epoch 190/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1108 - accuracy: 0.9621 - val_loss: 0.2249 - val_accuracy: 0.9419\n",
      "Epoch 191/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1091 - accuracy: 0.9623 - val_loss: 0.2154 - val_accuracy: 0.9394\n",
      "Epoch 192/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1057 - accuracy: 0.9646 - val_loss: 0.2265 - val_accuracy: 0.9437\n",
      "Epoch 193/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1084 - accuracy: 0.9634 - val_loss: 0.2196 - val_accuracy: 0.9401\n",
      "Epoch 194/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1054 - accuracy: 0.9651 - val_loss: 0.2214 - val_accuracy: 0.9405\n",
      "Epoch 195/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1039 - accuracy: 0.9639 - val_loss: 0.2183 - val_accuracy: 0.9430\n",
      "Epoch 196/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1039 - accuracy: 0.9646 - val_loss: 0.2385 - val_accuracy: 0.9339\n",
      "Epoch 197/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1037 - accuracy: 0.9637 - val_loss: 0.2162 - val_accuracy: 0.9435\n",
      "Epoch 198/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1051 - accuracy: 0.9641 - val_loss: 0.2100 - val_accuracy: 0.9453\n",
      "Epoch 199/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1033 - accuracy: 0.9647 - val_loss: 0.2086 - val_accuracy: 0.9444\n",
      "Epoch 200/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1022 - accuracy: 0.9646 - val_loss: 0.2258 - val_accuracy: 0.9412\n",
      "Epoch 201/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1032 - accuracy: 0.9650 - val_loss: 0.2113 - val_accuracy: 0.9428\n",
      "Epoch 202/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1052 - accuracy: 0.9640 - val_loss: 0.2078 - val_accuracy: 0.9426\n",
      "Epoch 203/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1018 - accuracy: 0.9655 - val_loss: 0.2256 - val_accuracy: 0.9373\n",
      "Epoch 204/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1024 - accuracy: 0.9652 - val_loss: 0.2101 - val_accuracy: 0.9433\n",
      "Epoch 205/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0978 - accuracy: 0.9660 - val_loss: 0.2181 - val_accuracy: 0.9423\n",
      "Epoch 206/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0996 - accuracy: 0.9663 - val_loss: 0.2226 - val_accuracy: 0.9417\n",
      "Epoch 207/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1042 - accuracy: 0.9648 - val_loss: 0.2177 - val_accuracy: 0.9401\n",
      "Epoch 208/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0982 - accuracy: 0.9679 - val_loss: 0.2182 - val_accuracy: 0.9398\n",
      "Epoch 209/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1004 - accuracy: 0.9653 - val_loss: 0.2134 - val_accuracy: 0.9412\n",
      "Epoch 210/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1005 - accuracy: 0.9660 - val_loss: 0.2372 - val_accuracy: 0.9373\n",
      "Epoch 211/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0981 - accuracy: 0.9666 - val_loss: 0.2356 - val_accuracy: 0.9401\n",
      "Epoch 212/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0992 - accuracy: 0.9665 - val_loss: 0.2094 - val_accuracy: 0.9410\n",
      "Epoch 213/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0956 - accuracy: 0.9679 - val_loss: 0.2247 - val_accuracy: 0.9419\n",
      "Epoch 214/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1014 - accuracy: 0.9659 - val_loss: 0.2147 - val_accuracy: 0.9412\n",
      "Epoch 215/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0984 - accuracy: 0.9666 - val_loss: 0.2122 - val_accuracy: 0.9421\n",
      "Epoch 216/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1000 - accuracy: 0.9664 - val_loss: 0.2147 - val_accuracy: 0.9423\n",
      "Epoch 217/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0995 - accuracy: 0.9658 - val_loss: 0.2293 - val_accuracy: 0.9449\n",
      "Epoch 218/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0951 - accuracy: 0.9668 - val_loss: 0.2311 - val_accuracy: 0.9385\n",
      "Epoch 219/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0959 - accuracy: 0.9683 - val_loss: 0.2181 - val_accuracy: 0.9417\n",
      "Epoch 220/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0947 - accuracy: 0.9671 - val_loss: 0.2233 - val_accuracy: 0.9391\n",
      "Epoch 221/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0968 - accuracy: 0.9667 - val_loss: 0.2236 - val_accuracy: 0.9417\n",
      "Epoch 222/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0964 - accuracy: 0.9674 - val_loss: 0.2318 - val_accuracy: 0.9410\n",
      "Epoch 223/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0973 - accuracy: 0.9685 - val_loss: 0.2288 - val_accuracy: 0.9382\n",
      "Epoch 224/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0925 - accuracy: 0.9681 - val_loss: 0.2261 - val_accuracy: 0.9401\n",
      "Epoch 225/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0961 - accuracy: 0.9677 - val_loss: 0.2328 - val_accuracy: 0.9394\n",
      "Epoch 226/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0959 - accuracy: 0.9665 - val_loss: 0.2281 - val_accuracy: 0.9405\n",
      "Epoch 227/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0948 - accuracy: 0.9680 - val_loss: 0.2212 - val_accuracy: 0.9414\n",
      "Epoch 228/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0975 - accuracy: 0.9674 - val_loss: 0.2379 - val_accuracy: 0.9378\n",
      "Epoch 229/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0948 - accuracy: 0.9675 - val_loss: 0.2105 - val_accuracy: 0.9437\n",
      "Epoch 230/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0966 - accuracy: 0.9674 - val_loss: 0.2197 - val_accuracy: 0.9433\n",
      "Epoch 231/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0954 - accuracy: 0.9683 - val_loss: 0.2191 - val_accuracy: 0.9398\n",
      "Epoch 232/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0950 - accuracy: 0.9677 - val_loss: 0.2210 - val_accuracy: 0.9419\n",
      "Epoch 233/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0910 - accuracy: 0.9692 - val_loss: 0.2330 - val_accuracy: 0.9334\n",
      "Epoch 234/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0964 - accuracy: 0.9673 - val_loss: 0.2171 - val_accuracy: 0.9423\n",
      "Epoch 235/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0963 - accuracy: 0.9675 - val_loss: 0.2118 - val_accuracy: 0.9407\n",
      "Epoch 236/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0988 - accuracy: 0.9654 - val_loss: 0.2292 - val_accuracy: 0.9417\n",
      "Epoch 237/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0909 - accuracy: 0.9700 - val_loss: 0.2182 - val_accuracy: 0.9444\n",
      "Epoch 238/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0948 - accuracy: 0.9675 - val_loss: 0.2224 - val_accuracy: 0.9433\n",
      "Epoch 239/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0923 - accuracy: 0.9674 - val_loss: 0.2283 - val_accuracy: 0.9394\n",
      "Epoch 240/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.2094 - val_accuracy: 0.9412\n",
      "Epoch 241/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0881 - accuracy: 0.9685 - val_loss: 0.2218 - val_accuracy: 0.9442\n",
      "Epoch 242/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0917 - accuracy: 0.9682 - val_loss: 0.2188 - val_accuracy: 0.9430\n",
      "Epoch 243/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0952 - accuracy: 0.9683 - val_loss: 0.2168 - val_accuracy: 0.9419\n",
      "Epoch 244/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0907 - accuracy: 0.9688 - val_loss: 0.2283 - val_accuracy: 0.9435\n",
      "Epoch 245/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0931 - accuracy: 0.9685 - val_loss: 0.2217 - val_accuracy: 0.9405\n",
      "Epoch 246/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.2230 - val_accuracy: 0.9426\n",
      "Epoch 247/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0890 - accuracy: 0.9691 - val_loss: 0.2303 - val_accuracy: 0.9433\n",
      "Epoch 248/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0902 - accuracy: 0.9695 - val_loss: 0.2235 - val_accuracy: 0.9428\n",
      "Epoch 249/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0852 - accuracy: 0.9707 - val_loss: 0.2204 - val_accuracy: 0.9426\n",
      "Epoch 250/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0895 - accuracy: 0.9691 - val_loss: 0.2376 - val_accuracy: 0.9389\n",
      "Epoch 251/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0885 - accuracy: 0.9699 - val_loss: 0.2231 - val_accuracy: 0.9412\n",
      "Epoch 252/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0884 - accuracy: 0.9703 - val_loss: 0.2271 - val_accuracy: 0.9433\n",
      "Epoch 253/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0899 - accuracy: 0.9699 - val_loss: 0.2438 - val_accuracy: 0.9385\n",
      "Epoch 254/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0886 - accuracy: 0.9702 - val_loss: 0.2345 - val_accuracy: 0.9396\n",
      "Epoch 255/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0912 - accuracy: 0.9688 - val_loss: 0.2302 - val_accuracy: 0.9412\n",
      "Epoch 256/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0878 - accuracy: 0.9701 - val_loss: 0.2204 - val_accuracy: 0.9437\n",
      "Epoch 257/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0883 - accuracy: 0.9704 - val_loss: 0.2336 - val_accuracy: 0.9373\n",
      "Epoch 258/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0907 - accuracy: 0.9693 - val_loss: 0.2310 - val_accuracy: 0.9396\n",
      "Epoch 259/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0876 - accuracy: 0.9710 - val_loss: 0.2299 - val_accuracy: 0.9385\n",
      "Epoch 260/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0895 - accuracy: 0.9698 - val_loss: 0.2275 - val_accuracy: 0.9419\n",
      "Epoch 261/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0884 - accuracy: 0.9695 - val_loss: 0.2238 - val_accuracy: 0.9433\n",
      "Epoch 262/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0901 - accuracy: 0.9699 - val_loss: 0.2474 - val_accuracy: 0.9389\n",
      "Epoch 263/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0885 - accuracy: 0.9702 - val_loss: 0.2248 - val_accuracy: 0.9428\n",
      "Epoch 264/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0892 - accuracy: 0.9702 - val_loss: 0.2261 - val_accuracy: 0.9414\n",
      "Epoch 265/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0842 - accuracy: 0.9706 - val_loss: 0.2397 - val_accuracy: 0.9410\n",
      "Epoch 266/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0843 - accuracy: 0.9702 - val_loss: 0.2267 - val_accuracy: 0.9430\n",
      "Epoch 267/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0837 - accuracy: 0.9719 - val_loss: 0.2283 - val_accuracy: 0.9401\n",
      "Epoch 268/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 0.2161 - val_accuracy: 0.9414\n",
      "Epoch 269/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0867 - accuracy: 0.9700 - val_loss: 0.2451 - val_accuracy: 0.9423\n",
      "Epoch 270/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0851 - accuracy: 0.9712 - val_loss: 0.2403 - val_accuracy: 0.9419\n",
      "Epoch 271/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0849 - accuracy: 0.9716 - val_loss: 0.2226 - val_accuracy: 0.9439\n",
      "Epoch 272/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0892 - accuracy: 0.9694 - val_loss: 0.2211 - val_accuracy: 0.9442\n",
      "Epoch 273/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0826 - accuracy: 0.9719 - val_loss: 0.2299 - val_accuracy: 0.9428\n",
      "Epoch 274/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0849 - accuracy: 0.9714 - val_loss: 0.2255 - val_accuracy: 0.9396\n",
      "Epoch 275/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0857 - accuracy: 0.9715 - val_loss: 0.2348 - val_accuracy: 0.9419\n",
      "Epoch 276/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0824 - accuracy: 0.9726 - val_loss: 0.2217 - val_accuracy: 0.9426\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0853 - accuracy: 0.9712 - val_loss: 0.2179 - val_accuracy: 0.9410\n",
      "Epoch 278/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0877 - accuracy: 0.9704 - val_loss: 0.2190 - val_accuracy: 0.9426\n",
      "Epoch 279/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0875 - accuracy: 0.9691 - val_loss: 0.2277 - val_accuracy: 0.9428\n",
      "Epoch 280/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0820 - accuracy: 0.9716 - val_loss: 0.2169 - val_accuracy: 0.9421\n",
      "Epoch 281/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0858 - accuracy: 0.9691 - val_loss: 0.2231 - val_accuracy: 0.9435\n",
      "Epoch 282/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0843 - accuracy: 0.9710 - val_loss: 0.2265 - val_accuracy: 0.9410\n",
      "Epoch 283/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0828 - accuracy: 0.9724 - val_loss: 0.2296 - val_accuracy: 0.9403\n",
      "Epoch 284/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0846 - accuracy: 0.9717 - val_loss: 0.2166 - val_accuracy: 0.9423\n",
      "Epoch 285/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0862 - accuracy: 0.9708 - val_loss: 0.2093 - val_accuracy: 0.9453\n",
      "Epoch 286/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0851 - accuracy: 0.9716 - val_loss: 0.2179 - val_accuracy: 0.9462\n",
      "Epoch 287/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0793 - accuracy: 0.9722 - val_loss: 0.2340 - val_accuracy: 0.9414\n",
      "Epoch 288/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0857 - accuracy: 0.9703 - val_loss: 0.2241 - val_accuracy: 0.9451\n",
      "Epoch 289/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0824 - accuracy: 0.9712 - val_loss: 0.2238 - val_accuracy: 0.9430\n",
      "Epoch 290/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0813 - accuracy: 0.9724 - val_loss: 0.2373 - val_accuracy: 0.9401\n",
      "Epoch 291/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0822 - accuracy: 0.9720 - val_loss: 0.2339 - val_accuracy: 0.9435\n",
      "Epoch 292/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0817 - accuracy: 0.9724 - val_loss: 0.2346 - val_accuracy: 0.9401\n",
      "Epoch 293/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0836 - accuracy: 0.9716 - val_loss: 0.2324 - val_accuracy: 0.9414\n",
      "Epoch 294/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0772 - accuracy: 0.9738 - val_loss: 0.2365 - val_accuracy: 0.9437\n",
      "Epoch 295/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0845 - accuracy: 0.9712 - val_loss: 0.2280 - val_accuracy: 0.9435\n",
      "Epoch 296/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0819 - accuracy: 0.9721 - val_loss: 0.2331 - val_accuracy: 0.9430\n",
      "Epoch 297/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0806 - accuracy: 0.9735 - val_loss: 0.2346 - val_accuracy: 0.9414\n",
      "Epoch 298/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0805 - accuracy: 0.9729 - val_loss: 0.2294 - val_accuracy: 0.9435\n",
      "Epoch 299/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0823 - accuracy: 0.9724 - val_loss: 0.2240 - val_accuracy: 0.9437\n",
      "Epoch 300/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0810 - accuracy: 0.9725 - val_loss: 0.2244 - val_accuracy: 0.9442\n",
      "Epoch 301/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0777 - accuracy: 0.9740 - val_loss: 0.2356 - val_accuracy: 0.9419\n",
      "Epoch 302/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0802 - accuracy: 0.9738 - val_loss: 0.2251 - val_accuracy: 0.9410\n",
      "Epoch 303/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0766 - accuracy: 0.9736 - val_loss: 0.2226 - val_accuracy: 0.9442\n",
      "Epoch 304/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0796 - accuracy: 0.9733 - val_loss: 0.2277 - val_accuracy: 0.9442\n",
      "Epoch 305/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0803 - accuracy: 0.9734 - val_loss: 0.2207 - val_accuracy: 0.9453\n",
      "Epoch 306/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0798 - accuracy: 0.9737 - val_loss: 0.2297 - val_accuracy: 0.9456\n",
      "Epoch 307/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0846 - accuracy: 0.9718 - val_loss: 0.2275 - val_accuracy: 0.9419\n",
      "Epoch 308/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0799 - accuracy: 0.9732 - val_loss: 0.2265 - val_accuracy: 0.9453\n",
      "Epoch 309/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0784 - accuracy: 0.9731 - val_loss: 0.2334 - val_accuracy: 0.9421\n",
      "Epoch 310/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0792 - accuracy: 0.9732 - val_loss: 0.2352 - val_accuracy: 0.9426\n",
      "Epoch 311/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0774 - accuracy: 0.9735 - val_loss: 0.2255 - val_accuracy: 0.9472\n",
      "Epoch 312/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0775 - accuracy: 0.9730 - val_loss: 0.2404 - val_accuracy: 0.9403\n",
      "Epoch 313/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0802 - accuracy: 0.9730 - val_loss: 0.2503 - val_accuracy: 0.9435\n",
      "Epoch 314/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0795 - accuracy: 0.9730 - val_loss: 0.2398 - val_accuracy: 0.9387\n",
      "Epoch 315/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0739 - accuracy: 0.9743 - val_loss: 0.2368 - val_accuracy: 0.9419\n",
      "Epoch 316/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0778 - accuracy: 0.9723 - val_loss: 0.2385 - val_accuracy: 0.9449\n",
      "Epoch 317/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0774 - accuracy: 0.9736 - val_loss: 0.2358 - val_accuracy: 0.9405\n",
      "Epoch 318/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0757 - accuracy: 0.9740 - val_loss: 0.2309 - val_accuracy: 0.9426\n",
      "Epoch 319/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0756 - accuracy: 0.9742 - val_loss: 0.2418 - val_accuracy: 0.9433\n",
      "Epoch 320/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0771 - accuracy: 0.9733 - val_loss: 0.2333 - val_accuracy: 0.9428\n",
      "Epoch 321/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0757 - accuracy: 0.9749 - val_loss: 0.2375 - val_accuracy: 0.9421\n",
      "Epoch 322/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0789 - accuracy: 0.9738 - val_loss: 0.2353 - val_accuracy: 0.9423\n",
      "Epoch 323/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0794 - accuracy: 0.9742 - val_loss: 0.2394 - val_accuracy: 0.9414\n",
      "Epoch 324/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0775 - accuracy: 0.9738 - val_loss: 0.2536 - val_accuracy: 0.9394\n",
      "Epoch 325/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0765 - accuracy: 0.9732 - val_loss: 0.2408 - val_accuracy: 0.9433\n",
      "Epoch 326/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0770 - accuracy: 0.9740 - val_loss: 0.2335 - val_accuracy: 0.9430\n",
      "Epoch 327/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0769 - accuracy: 0.9733 - val_loss: 0.2378 - val_accuracy: 0.9428\n",
      "Epoch 328/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0762 - accuracy: 0.9737 - val_loss: 0.2378 - val_accuracy: 0.9426\n",
      "Epoch 329/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0737 - accuracy: 0.9739 - val_loss: 0.2389 - val_accuracy: 0.9417\n",
      "Epoch 330/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0746 - accuracy: 0.9740 - val_loss: 0.2385 - val_accuracy: 0.9423\n",
      "Epoch 331/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0773 - accuracy: 0.9737 - val_loss: 0.2345 - val_accuracy: 0.9407\n",
      "Epoch 332/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0761 - accuracy: 0.9745 - val_loss: 0.2230 - val_accuracy: 0.9401\n",
      "Epoch 333/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0741 - accuracy: 0.9752 - val_loss: 0.2346 - val_accuracy: 0.9449\n",
      "Epoch 334/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0767 - accuracy: 0.9730 - val_loss: 0.2463 - val_accuracy: 0.9389\n",
      "Epoch 335/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0754 - accuracy: 0.9740 - val_loss: 0.2481 - val_accuracy: 0.9410\n",
      "Epoch 336/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0705 - accuracy: 0.9763 - val_loss: 0.2485 - val_accuracy: 0.9428\n",
      "Epoch 337/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0771 - accuracy: 0.9739 - val_loss: 0.2441 - val_accuracy: 0.9380\n",
      "Epoch 338/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.2431 - val_accuracy: 0.9410\n",
      "Epoch 339/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0735 - accuracy: 0.9753 - val_loss: 0.2414 - val_accuracy: 0.9423\n",
      "Epoch 340/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0755 - accuracy: 0.9743 - val_loss: 0.2546 - val_accuracy: 0.9405\n",
      "Epoch 341/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0710 - accuracy: 0.9760 - val_loss: 0.2250 - val_accuracy: 0.9462\n",
      "Epoch 342/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0738 - accuracy: 0.9744 - val_loss: 0.2631 - val_accuracy: 0.9373\n",
      "Epoch 343/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0755 - accuracy: 0.9748 - val_loss: 0.2306 - val_accuracy: 0.9430\n",
      "Epoch 344/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0711 - accuracy: 0.9755 - val_loss: 0.2463 - val_accuracy: 0.9394\n",
      "Epoch 345/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0776 - accuracy: 0.9731 - val_loss: 0.2487 - val_accuracy: 0.9375\n",
      "Epoch 346/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0714 - accuracy: 0.9754 - val_loss: 0.2370 - val_accuracy: 0.9410\n",
      "Epoch 347/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0766 - accuracy: 0.9744 - val_loss: 0.2312 - val_accuracy: 0.9433\n",
      "Epoch 348/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0719 - accuracy: 0.9743 - val_loss: 0.2382 - val_accuracy: 0.9417\n",
      "Epoch 349/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0731 - accuracy: 0.9754 - val_loss: 0.2391 - val_accuracy: 0.9410\n",
      "Epoch 350/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0729 - accuracy: 0.9766 - val_loss: 0.2480 - val_accuracy: 0.9410\n",
      "Epoch 351/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0752 - accuracy: 0.9751 - val_loss: 0.2310 - val_accuracy: 0.9435\n",
      "Epoch 352/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0756 - accuracy: 0.9746 - val_loss: 0.2380 - val_accuracy: 0.9433\n",
      "Epoch 353/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0734 - accuracy: 0.9751 - val_loss: 0.2363 - val_accuracy: 0.9453\n",
      "Epoch 354/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0698 - accuracy: 0.9766 - val_loss: 0.2354 - val_accuracy: 0.9423\n",
      "Epoch 355/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0747 - accuracy: 0.9744 - val_loss: 0.2345 - val_accuracy: 0.9403\n",
      "Epoch 356/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 0.2439 - val_accuracy: 0.9419\n",
      "Epoch 357/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0714 - accuracy: 0.9763 - val_loss: 0.2666 - val_accuracy: 0.9391\n",
      "Epoch 358/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0743 - accuracy: 0.9747 - val_loss: 0.2414 - val_accuracy: 0.9430\n",
      "Epoch 359/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0727 - accuracy: 0.9752 - val_loss: 0.2533 - val_accuracy: 0.9403\n",
      "Epoch 360/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0688 - accuracy: 0.9767 - val_loss: 0.2431 - val_accuracy: 0.9421\n",
      "Epoch 361/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0723 - accuracy: 0.9755 - val_loss: 0.2463 - val_accuracy: 0.9419\n",
      "Epoch 362/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0715 - accuracy: 0.9757 - val_loss: 0.2354 - val_accuracy: 0.9412\n",
      "Epoch 363/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0698 - accuracy: 0.9761 - val_loss: 0.2460 - val_accuracy: 0.9444\n",
      "Epoch 364/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0701 - accuracy: 0.9763 - val_loss: 0.2424 - val_accuracy: 0.9423\n",
      "Epoch 365/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0710 - accuracy: 0.9760 - val_loss: 0.2416 - val_accuracy: 0.9405\n",
      "Epoch 366/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0762 - accuracy: 0.9736 - val_loss: 0.2298 - val_accuracy: 0.9442\n",
      "Epoch 367/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0742 - accuracy: 0.9752 - val_loss: 0.2298 - val_accuracy: 0.9437\n",
      "Epoch 368/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.2403 - val_accuracy: 0.9419\n",
      "Epoch 369/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 0.2273 - val_accuracy: 0.9449\n",
      "Epoch 370/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0714 - accuracy: 0.9760 - val_loss: 0.2314 - val_accuracy: 0.9449\n",
      "Epoch 371/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0696 - accuracy: 0.9759 - val_loss: 0.2420 - val_accuracy: 0.9407\n",
      "Epoch 372/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0712 - accuracy: 0.9756 - val_loss: 0.2501 - val_accuracy: 0.9410\n",
      "Epoch 373/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0722 - accuracy: 0.9752 - val_loss: 0.2234 - val_accuracy: 0.9419\n",
      "Epoch 374/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0707 - accuracy: 0.9757 - val_loss: 0.2408 - val_accuracy: 0.9442\n",
      "Epoch 375/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0676 - accuracy: 0.9768 - val_loss: 0.2376 - val_accuracy: 0.9469\n",
      "Epoch 376/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0712 - accuracy: 0.9762 - val_loss: 0.2465 - val_accuracy: 0.9412\n",
      "Epoch 377/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0682 - accuracy: 0.9758 - val_loss: 0.2438 - val_accuracy: 0.9435\n",
      "Epoch 378/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0672 - accuracy: 0.9765 - val_loss: 0.2447 - val_accuracy: 0.9435\n",
      "Epoch 379/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0704 - accuracy: 0.9761 - val_loss: 0.2517 - val_accuracy: 0.9401\n",
      "Epoch 380/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.2300 - val_accuracy: 0.9451\n",
      "Epoch 381/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0672 - accuracy: 0.9770 - val_loss: 0.2372 - val_accuracy: 0.9407\n",
      "Epoch 382/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0688 - accuracy: 0.9773 - val_loss: 0.2426 - val_accuracy: 0.9419\n",
      "Epoch 383/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0683 - accuracy: 0.9764 - val_loss: 0.2352 - val_accuracy: 0.9435\n",
      "Epoch 384/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0663 - accuracy: 0.9770 - val_loss: 0.2470 - val_accuracy: 0.9442\n",
      "Epoch 385/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0658 - accuracy: 0.9775 - val_loss: 0.2609 - val_accuracy: 0.9423\n",
      "Epoch 386/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0723 - accuracy: 0.9754 - val_loss: 0.2304 - val_accuracy: 0.9430\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0686 - accuracy: 0.9767 - val_loss: 0.2341 - val_accuracy: 0.9428\n",
      "Epoch 388/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0705 - accuracy: 0.9761 - val_loss: 0.2306 - val_accuracy: 0.9437\n",
      "Epoch 389/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0679 - accuracy: 0.9769 - val_loss: 0.2384 - val_accuracy: 0.9444\n",
      "Epoch 390/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0721 - accuracy: 0.9769 - val_loss: 0.2388 - val_accuracy: 0.9414\n",
      "Epoch 391/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0667 - accuracy: 0.9772 - val_loss: 0.2390 - val_accuracy: 0.9423\n",
      "Epoch 392/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0682 - accuracy: 0.9768 - val_loss: 0.2503 - val_accuracy: 0.9410\n",
      "Epoch 393/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0661 - accuracy: 0.9773 - val_loss: 0.2348 - val_accuracy: 0.9405\n",
      "Epoch 394/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0683 - accuracy: 0.9770 - val_loss: 0.2274 - val_accuracy: 0.9428\n",
      "Epoch 395/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.2461 - val_accuracy: 0.9435\n",
      "Epoch 396/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0682 - accuracy: 0.9775 - val_loss: 0.2414 - val_accuracy: 0.9421\n",
      "Epoch 397/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0667 - accuracy: 0.9774 - val_loss: 0.2567 - val_accuracy: 0.9407\n",
      "Epoch 398/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0700 - accuracy: 0.9761 - val_loss: 0.2535 - val_accuracy: 0.9428\n",
      "Epoch 399/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0702 - accuracy: 0.9766 - val_loss: 0.2441 - val_accuracy: 0.9419\n",
      "Epoch 400/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0697 - accuracy: 0.9754 - val_loss: 0.2430 - val_accuracy: 0.9423\n",
      "Epoch 401/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0664 - accuracy: 0.9773 - val_loss: 0.2642 - val_accuracy: 0.9378\n",
      "Epoch 402/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.2694 - val_accuracy: 0.9373\n",
      "Epoch 403/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0677 - accuracy: 0.9778 - val_loss: 0.2788 - val_accuracy: 0.9357\n",
      "Epoch 404/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0682 - accuracy: 0.9766 - val_loss: 0.2647 - val_accuracy: 0.9391\n",
      "Epoch 405/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0685 - accuracy: 0.9768 - val_loss: 0.2441 - val_accuracy: 0.9412\n",
      "Epoch 406/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0656 - accuracy: 0.9779 - val_loss: 0.2391 - val_accuracy: 0.9428\n",
      "Epoch 407/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0657 - accuracy: 0.9773 - val_loss: 0.2392 - val_accuracy: 0.9439\n",
      "Epoch 408/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0677 - accuracy: 0.9762 - val_loss: 0.2456 - val_accuracy: 0.9426\n",
      "Epoch 409/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0684 - accuracy: 0.9764 - val_loss: 0.2482 - val_accuracy: 0.9387\n",
      "Epoch 410/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0648 - accuracy: 0.9778 - val_loss: 0.2397 - val_accuracy: 0.9444\n",
      "Epoch 411/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0705 - accuracy: 0.9766 - val_loss: 0.2457 - val_accuracy: 0.9394\n",
      "Epoch 412/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0670 - accuracy: 0.9776 - val_loss: 0.2453 - val_accuracy: 0.9412\n",
      "Epoch 413/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 0.2490 - val_accuracy: 0.9387\n",
      "Epoch 414/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0668 - accuracy: 0.9784 - val_loss: 0.2399 - val_accuracy: 0.9437\n",
      "Epoch 415/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0655 - accuracy: 0.9780 - val_loss: 0.2450 - val_accuracy: 0.9405\n",
      "Epoch 416/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0659 - accuracy: 0.9773 - val_loss: 0.2523 - val_accuracy: 0.9398\n",
      "Epoch 417/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0638 - accuracy: 0.9780 - val_loss: 0.2341 - val_accuracy: 0.9458\n",
      "Epoch 418/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 0.2509 - val_accuracy: 0.9421\n",
      "Epoch 419/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0670 - accuracy: 0.9778 - val_loss: 0.2456 - val_accuracy: 0.9407\n",
      "Epoch 420/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0679 - accuracy: 0.9768 - val_loss: 0.2430 - val_accuracy: 0.9410\n",
      "Epoch 421/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0646 - accuracy: 0.9785 - val_loss: 0.2435 - val_accuracy: 0.9435\n",
      "Epoch 422/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0671 - accuracy: 0.9772 - val_loss: 0.2382 - val_accuracy: 0.9460\n",
      "Epoch 423/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0651 - accuracy: 0.9783 - val_loss: 0.2432 - val_accuracy: 0.9403\n",
      "Epoch 424/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0675 - accuracy: 0.9777 - val_loss: 0.2363 - val_accuracy: 0.9433\n",
      "Epoch 425/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0630 - accuracy: 0.9777 - val_loss: 0.2456 - val_accuracy: 0.9435\n",
      "Epoch 426/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0607 - accuracy: 0.9790 - val_loss: 0.2562 - val_accuracy: 0.9407\n",
      "Epoch 427/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0678 - accuracy: 0.9767 - val_loss: 0.2454 - val_accuracy: 0.9423\n",
      "Epoch 428/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0639 - accuracy: 0.9781 - val_loss: 0.2381 - val_accuracy: 0.9442\n",
      "Epoch 429/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0647 - accuracy: 0.9786 - val_loss: 0.2393 - val_accuracy: 0.9430\n",
      "Epoch 430/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0646 - accuracy: 0.9776 - val_loss: 0.2698 - val_accuracy: 0.9405\n",
      "Epoch 431/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0633 - accuracy: 0.9782 - val_loss: 0.2444 - val_accuracy: 0.9419\n",
      "Epoch 432/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0653 - accuracy: 0.9770 - val_loss: 0.2511 - val_accuracy: 0.9419\n",
      "Epoch 433/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0641 - accuracy: 0.9792 - val_loss: 0.2468 - val_accuracy: 0.9426\n",
      "Epoch 434/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0654 - accuracy: 0.9776 - val_loss: 0.2450 - val_accuracy: 0.9435\n",
      "Epoch 435/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0648 - accuracy: 0.9780 - val_loss: 0.2408 - val_accuracy: 0.9439\n",
      "Epoch 436/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 0.2527 - val_accuracy: 0.9421\n",
      "Epoch 437/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0646 - accuracy: 0.9788 - val_loss: 0.2358 - val_accuracy: 0.9439\n",
      "Epoch 438/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0662 - accuracy: 0.9773 - val_loss: 0.2419 - val_accuracy: 0.9423\n",
      "Epoch 439/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0634 - accuracy: 0.9792 - val_loss: 0.2653 - val_accuracy: 0.9371\n",
      "Epoch 440/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0685 - accuracy: 0.9777 - val_loss: 0.2520 - val_accuracy: 0.9394\n",
      "Epoch 441/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0635 - accuracy: 0.9788 - val_loss: 0.2546 - val_accuracy: 0.9410\n",
      "Epoch 442/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0642 - accuracy: 0.9786 - val_loss: 0.2491 - val_accuracy: 0.9398\n",
      "Epoch 443/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0634 - accuracy: 0.9789 - val_loss: 0.2519 - val_accuracy: 0.9410\n",
      "Epoch 444/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0602 - accuracy: 0.9801 - val_loss: 0.2471 - val_accuracy: 0.9435\n",
      "Epoch 445/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0611 - accuracy: 0.9800 - val_loss: 0.2525 - val_accuracy: 0.9421\n",
      "Epoch 446/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0672 - accuracy: 0.9777 - val_loss: 0.2468 - val_accuracy: 0.9414\n",
      "Epoch 447/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0627 - accuracy: 0.9786 - val_loss: 0.2412 - val_accuracy: 0.9423\n",
      "Epoch 448/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0651 - accuracy: 0.9778 - val_loss: 0.2404 - val_accuracy: 0.9439\n",
      "Epoch 449/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0664 - accuracy: 0.9776 - val_loss: 0.2350 - val_accuracy: 0.9433\n",
      "Epoch 450/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0645 - accuracy: 0.9781 - val_loss: 0.2474 - val_accuracy: 0.9423\n",
      "Epoch 451/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.2386 - val_accuracy: 0.9437\n",
      "Epoch 452/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0640 - accuracy: 0.9784 - val_loss: 0.2483 - val_accuracy: 0.9439\n",
      "Epoch 453/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0629 - accuracy: 0.9778 - val_loss: 0.2437 - val_accuracy: 0.9453\n",
      "Epoch 454/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0645 - accuracy: 0.9784 - val_loss: 0.2400 - val_accuracy: 0.9407\n",
      "Epoch 455/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0613 - accuracy: 0.9791 - val_loss: 0.2325 - val_accuracy: 0.9446\n",
      "Epoch 456/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0643 - accuracy: 0.9786 - val_loss: 0.2404 - val_accuracy: 0.9437\n",
      "Epoch 457/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0614 - accuracy: 0.9791 - val_loss: 0.2608 - val_accuracy: 0.9423\n",
      "Epoch 458/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0651 - accuracy: 0.9774 - val_loss: 0.2468 - val_accuracy: 0.9430\n",
      "Epoch 459/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0595 - accuracy: 0.9798 - val_loss: 0.2452 - val_accuracy: 0.9465\n",
      "Epoch 460/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0617 - accuracy: 0.9795 - val_loss: 0.2525 - val_accuracy: 0.9430\n",
      "Epoch 461/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 0.2426 - val_accuracy: 0.9414\n",
      "Epoch 462/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0611 - accuracy: 0.9789 - val_loss: 0.2389 - val_accuracy: 0.9451\n",
      "Epoch 463/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0599 - accuracy: 0.9801 - val_loss: 0.2490 - val_accuracy: 0.9444\n",
      "Epoch 464/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0600 - accuracy: 0.9790 - val_loss: 0.2427 - val_accuracy: 0.9435\n",
      "Epoch 465/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0613 - accuracy: 0.9791 - val_loss: 0.2396 - val_accuracy: 0.9467\n",
      "Epoch 466/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0611 - accuracy: 0.9796 - val_loss: 0.2464 - val_accuracy: 0.9435\n",
      "Epoch 467/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0599 - accuracy: 0.9795 - val_loss: 0.2576 - val_accuracy: 0.9439\n",
      "Epoch 468/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0646 - accuracy: 0.9783 - val_loss: 0.2387 - val_accuracy: 0.9460\n",
      "Epoch 469/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.2472 - val_accuracy: 0.9426\n",
      "Epoch 470/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0574 - accuracy: 0.9801 - val_loss: 0.2618 - val_accuracy: 0.9398\n",
      "Epoch 471/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0632 - accuracy: 0.9793 - val_loss: 0.2399 - val_accuracy: 0.9439\n",
      "Epoch 472/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0607 - accuracy: 0.9792 - val_loss: 0.2395 - val_accuracy: 0.9426\n",
      "Epoch 473/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0650 - accuracy: 0.9776 - val_loss: 0.2548 - val_accuracy: 0.9419\n",
      "Epoch 474/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0641 - accuracy: 0.9783 - val_loss: 0.2400 - val_accuracy: 0.9414\n",
      "Epoch 475/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0594 - accuracy: 0.9796 - val_loss: 0.2327 - val_accuracy: 0.9462\n",
      "Epoch 476/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0594 - accuracy: 0.9807 - val_loss: 0.2484 - val_accuracy: 0.9456\n",
      "Epoch 477/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0585 - accuracy: 0.9802 - val_loss: 0.2531 - val_accuracy: 0.9407\n",
      "Epoch 478/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0597 - accuracy: 0.9797 - val_loss: 0.2522 - val_accuracy: 0.9446\n",
      "Epoch 479/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0615 - accuracy: 0.9798 - val_loss: 0.2488 - val_accuracy: 0.9462\n",
      "Epoch 480/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0617 - accuracy: 0.9797 - val_loss: 0.2397 - val_accuracy: 0.9442\n",
      "Epoch 481/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.2530 - val_accuracy: 0.9430\n",
      "Epoch 482/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0619 - accuracy: 0.9786 - val_loss: 0.2556 - val_accuracy: 0.9387\n",
      "Epoch 483/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0594 - accuracy: 0.9800 - val_loss: 0.2364 - val_accuracy: 0.9453\n",
      "Epoch 484/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0651 - accuracy: 0.9780 - val_loss: 0.2416 - val_accuracy: 0.9428\n",
      "Epoch 485/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0611 - accuracy: 0.9789 - val_loss: 0.2338 - val_accuracy: 0.9469\n",
      "Epoch 486/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 0.2459 - val_accuracy: 0.9423\n",
      "Epoch 487/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0582 - accuracy: 0.9803 - val_loss: 0.2534 - val_accuracy: 0.9435\n",
      "Epoch 488/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0624 - accuracy: 0.9790 - val_loss: 0.2447 - val_accuracy: 0.9428\n",
      "Epoch 489/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0606 - accuracy: 0.9799 - val_loss: 0.2481 - val_accuracy: 0.9426\n",
      "Epoch 490/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0603 - accuracy: 0.9796 - val_loss: 0.2349 - val_accuracy: 0.9444\n",
      "Epoch 491/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0570 - accuracy: 0.9806 - val_loss: 0.2548 - val_accuracy: 0.9407\n",
      "Epoch 492/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0604 - accuracy: 0.9798 - val_loss: 0.2366 - val_accuracy: 0.9442\n",
      "Epoch 493/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0599 - accuracy: 0.9798 - val_loss: 0.2322 - val_accuracy: 0.9451\n",
      "Epoch 494/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0590 - accuracy: 0.9796 - val_loss: 0.2392 - val_accuracy: 0.9417\n",
      "Epoch 495/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0576 - accuracy: 0.9809 - val_loss: 0.2446 - val_accuracy: 0.9446\n",
      "Epoch 496/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 0.2531 - val_accuracy: 0.9426\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0593 - accuracy: 0.9798 - val_loss: 0.2586 - val_accuracy: 0.9396\n",
      "Epoch 498/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0596 - accuracy: 0.9798 - val_loss: 0.2512 - val_accuracy: 0.9412\n",
      "Epoch 499/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0558 - accuracy: 0.9801 - val_loss: 0.2714 - val_accuracy: 0.9433\n",
      "Epoch 500/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0591 - accuracy: 0.9801 - val_loss: 0.2563 - val_accuracy: 0.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8f940467c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model for 500 epochs and keep the best model measured on the validation accuracy. \n",
    "\n",
    "EPOCHS = 500\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = CNN_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),  \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "CNN_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5747703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106266/897927363.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
      "/tmp/ipykernel_106266/897927363.py:11: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
      "/tmp/ipykernel_106266/897927363.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
      "/tmp/ipykernel_106266/897927363.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "172d89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNN-Model\n",
    "\n",
    "models.save_model(CNN_model, CNN_model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8dd616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of CNN: 99.9685525894165 %\n",
      "Accuracy on validation set of CNN: 94.71516609191895 %\n",
      "Accuracy on test set with SNR of 1 of CNN: 79.56989407539368 %\n",
      "Accuracy on test set with SNR of 10 of CNN: 91.16907119750977 %\n",
      "Accuracy on test set with SNR of 20 of CNN: 94.23472881317139 %\n",
      "Accuracy on test set with SNR of 100 of CNN: 94.53214406967163 %\n",
      "Accuracy on test set with SNR of 1000 of CNN: 94.66941356658936 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the CNN model \n",
    "\n",
    "score = CNN_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of CNN:', score[1] * 100,'%')\n",
    "\n",
    "score = CNN_model.evaluate(x_test1, y_test1, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1 of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test10, y_test10, verbose=0)\n",
    "print('Accuracy on test set with SNR of 10 of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test20, y_test20, verbose=0)\n",
    "print('Accuracy on test set with SNR of 20 of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test100, y_test100, verbose=0)\n",
    "print('Accuracy on test set with SNR of 100 of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test1000, y_test1000, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1000 of CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1a9d3",
   "metadata": {},
   "source": [
    "<font size=\"5\">3. Quantize the CNN-Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf0883cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (QuantizedConv2D)     (None, 20, 51, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ActivationDiscr (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (QuantizedSepara (None, 20, 51, 32)        1344      \n",
      "_________________________________________________________________\n",
      "separable_1_relu (Activation (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (QuantizedSepara (None, 10, 26, 64)        2400      \n",
      "_________________________________________________________________\n",
      "separable_2_relu (Activation (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (QuantizedSepara (None, 10, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "separable_3_relu (Activation (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (QuantizedSepara (None, 5, 13, 128)        17664     \n",
      "_________________________________________________________________\n",
      "separable_4_relu (Activation (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (QuantizedSepara (None, 5, 13, 256)        34176     \n",
      "_________________________________________________________________\n",
      "separable_5_relu (Activation (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (QuantizedSepara (None, 3, 7, 256)         68096     \n",
      "_________________________________________________________________\n",
      "separable_6_relu (Activation (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (QuantizedSepara (None, 2, 4, 512)         133888    \n",
      "_________________________________________________________________\n",
      "separable_7_relu (Activation (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (QuantizedSepara (None, 2, 4, 1024)        529920    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_relu (Activation (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (QuantizedDense)       (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "re_lu (ActivationDiscreteRel (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 809,004\n",
      "Trainable params: 809,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Quantize the CNN-model\n",
    "\n",
    "quantized_model = quantize(CNN_model,\n",
    "                           input_weight_quantization=8,\n",
    "                           weight_quantization=4,\n",
    "                           activ_quantization=4)\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0300370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy after quantization\n",
    "\n",
    "quantized_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab6dfa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of quantized CNN: 64.2068862915039 %\n",
      "Accuracy on validation set of quantized CNN: 59.43719744682312 %\n",
      "Accuracy on test set with SNR of 1 of quantized CNN: 51.15534067153931 %\n",
      "Accuracy on test set with SNR of 10 of quantized CNN: 57.97300338745117 %\n",
      "Accuracy on test set with SNR of 20 of quantized CNN: 58.430564403533936 %\n",
      "Accuracy on test set with SNR of 100 of quantized CNN: 58.1102728843689 %\n",
      "Accuracy on test set with SNR of 1000 of quantized CNN: 57.5383186340332 %\n"
     ]
    }
   ],
   "source": [
    "score = quantized_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of quantized CNN:', score[1] * 100,'%')\n",
    "\n",
    "score = quantized_model.evaluate(x_test1, y_test1, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test10, y_test10, verbose=0)\n",
    "print('Accuracy on test set with SNR of 10 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test20, y_test20, verbose=0)\n",
    "print('Accuracy on test set with SNR of 20 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test100, y_test100, verbose=0)\n",
    "print('Accuracy on test set with SNR of 100 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test1000, y_test1000, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1000 of quantized CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "043b41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1093/1093 [==============================] - 17s 13ms/step - loss: 0.3752 - accuracy: 0.8769 - val_loss: 0.2514 - val_accuracy: 0.9369\n",
      "Epoch 2/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1712 - accuracy: 0.9545 - val_loss: 0.2341 - val_accuracy: 0.9419\n",
      "Epoch 3/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1466 - accuracy: 0.9623 - val_loss: 0.2301 - val_accuracy: 0.9426\n",
      "Epoch 4/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1349 - accuracy: 0.9656 - val_loss: 0.2264 - val_accuracy: 0.9426\n",
      "Epoch 5/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1295 - accuracy: 0.9667 - val_loss: 0.2273 - val_accuracy: 0.9433\n",
      "Epoch 6/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1225 - accuracy: 0.9688 - val_loss: 0.2302 - val_accuracy: 0.9421\n",
      "Epoch 7/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1222 - accuracy: 0.9687 - val_loss: 0.2270 - val_accuracy: 0.9433\n",
      "Epoch 8/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1192 - accuracy: 0.9692 - val_loss: 0.2243 - val_accuracy: 0.9428\n",
      "Epoch 9/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1148 - accuracy: 0.9712 - val_loss: 0.2290 - val_accuracy: 0.9430\n",
      "Epoch 10/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1144 - accuracy: 0.9712 - val_loss: 0.2224 - val_accuracy: 0.9456\n",
      "Epoch 11/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1129 - accuracy: 0.9715 - val_loss: 0.2277 - val_accuracy: 0.9435\n",
      "Epoch 12/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1135 - accuracy: 0.9721 - val_loss: 0.2266 - val_accuracy: 0.9430\n",
      "Epoch 13/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1138 - accuracy: 0.9710 - val_loss: 0.2291 - val_accuracy: 0.9403\n",
      "Epoch 14/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1078 - accuracy: 0.9736 - val_loss: 0.2283 - val_accuracy: 0.9412\n",
      "Epoch 15/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1080 - accuracy: 0.9737 - val_loss: 0.2293 - val_accuracy: 0.9423\n",
      "Epoch 16/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1066 - accuracy: 0.9733 - val_loss: 0.2247 - val_accuracy: 0.9435\n",
      "Epoch 17/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1110 - accuracy: 0.9728 - val_loss: 0.2259 - val_accuracy: 0.9421\n",
      "Epoch 18/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1091 - accuracy: 0.9731 - val_loss: 0.2320 - val_accuracy: 0.9401\n",
      "Epoch 19/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1066 - accuracy: 0.9739 - val_loss: 0.2243 - val_accuracy: 0.9437\n",
      "Epoch 20/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1049 - accuracy: 0.9729 - val_loss: 0.2265 - val_accuracy: 0.9426\n",
      "Epoch 21/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1046 - accuracy: 0.9742 - val_loss: 0.2227 - val_accuracy: 0.9439\n",
      "Epoch 22/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1015 - accuracy: 0.9747 - val_loss: 0.2201 - val_accuracy: 0.9423\n",
      "Epoch 23/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1044 - accuracy: 0.9730 - val_loss: 0.2163 - val_accuracy: 0.9456\n",
      "Epoch 24/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1013 - accuracy: 0.9754 - val_loss: 0.2217 - val_accuracy: 0.9417\n",
      "Epoch 25/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1002 - accuracy: 0.9762 - val_loss: 0.2256 - val_accuracy: 0.9426\n",
      "Epoch 26/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1011 - accuracy: 0.9748 - val_loss: 0.2196 - val_accuracy: 0.9458\n",
      "Epoch 27/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1006 - accuracy: 0.9752 - val_loss: 0.2190 - val_accuracy: 0.9462\n",
      "Epoch 28/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1012 - accuracy: 0.9756 - val_loss: 0.2194 - val_accuracy: 0.9458\n",
      "Epoch 29/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0970 - accuracy: 0.9763 - val_loss: 0.2214 - val_accuracy: 0.9458\n",
      "Epoch 30/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1026 - accuracy: 0.9746 - val_loss: 0.2193 - val_accuracy: 0.9453\n",
      "Epoch 31/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0977 - accuracy: 0.9773 - val_loss: 0.2257 - val_accuracy: 0.9426\n",
      "Epoch 32/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1028 - accuracy: 0.9746 - val_loss: 0.2258 - val_accuracy: 0.9419\n",
      "Epoch 33/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1002 - accuracy: 0.9760 - val_loss: 0.2250 - val_accuracy: 0.9430\n",
      "Epoch 34/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1004 - accuracy: 0.9752 - val_loss: 0.2298 - val_accuracy: 0.9426\n",
      "Epoch 35/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0981 - accuracy: 0.9766 - val_loss: 0.2246 - val_accuracy: 0.9451\n",
      "Epoch 36/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0976 - accuracy: 0.9765 - val_loss: 0.2320 - val_accuracy: 0.9423\n",
      "Epoch 37/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0992 - accuracy: 0.9756 - val_loss: 0.2350 - val_accuracy: 0.9412\n",
      "Epoch 38/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0961 - accuracy: 0.9768 - val_loss: 0.2308 - val_accuracy: 0.9410\n",
      "Epoch 39/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0966 - accuracy: 0.9766 - val_loss: 0.2295 - val_accuracy: 0.9412\n",
      "Epoch 40/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0962 - accuracy: 0.9764 - val_loss: 0.2227 - val_accuracy: 0.9428\n",
      "Epoch 41/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0958 - accuracy: 0.9778 - val_loss: 0.2228 - val_accuracy: 0.9444\n",
      "Epoch 42/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0960 - accuracy: 0.9764 - val_loss: 0.2302 - val_accuracy: 0.9405\n",
      "Epoch 43/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0949 - accuracy: 0.9769 - val_loss: 0.2260 - val_accuracy: 0.9428\n",
      "Epoch 44/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0946 - accuracy: 0.9775 - val_loss: 0.2248 - val_accuracy: 0.9458\n",
      "Epoch 45/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0939 - accuracy: 0.9780 - val_loss: 0.2328 - val_accuracy: 0.9433\n",
      "Epoch 46/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0964 - accuracy: 0.9767 - val_loss: 0.2265 - val_accuracy: 0.9437\n",
      "Epoch 47/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0935 - accuracy: 0.9780 - val_loss: 0.2208 - val_accuracy: 0.9446\n",
      "Epoch 48/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0947 - accuracy: 0.9774 - val_loss: 0.2241 - val_accuracy: 0.9444\n",
      "Epoch 49/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0941 - accuracy: 0.9766 - val_loss: 0.2281 - val_accuracy: 0.9446\n",
      "Epoch 50/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0945 - accuracy: 0.9776 - val_loss: 0.2233 - val_accuracy: 0.9442\n",
      "Epoch 51/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0925 - accuracy: 0.9781 - val_loss: 0.2266 - val_accuracy: 0.9421\n",
      "Epoch 52/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0933 - accuracy: 0.9775 - val_loss: 0.2281 - val_accuracy: 0.9446\n",
      "Epoch 53/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0926 - accuracy: 0.9777 - val_loss: 0.2272 - val_accuracy: 0.9433\n",
      "Epoch 54/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0971 - accuracy: 0.9764 - val_loss: 0.2261 - val_accuracy: 0.9419\n",
      "Epoch 55/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0942 - accuracy: 0.9774 - val_loss: 0.2242 - val_accuracy: 0.9449\n",
      "Epoch 56/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0932 - accuracy: 0.9773 - val_loss: 0.2246 - val_accuracy: 0.9449\n",
      "Epoch 57/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0913 - accuracy: 0.9787 - val_loss: 0.2251 - val_accuracy: 0.9453\n",
      "Epoch 58/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0925 - accuracy: 0.9780 - val_loss: 0.2258 - val_accuracy: 0.9456\n",
      "Epoch 59/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0940 - accuracy: 0.9783 - val_loss: 0.2275 - val_accuracy: 0.9442\n",
      "Epoch 60/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0913 - accuracy: 0.9789 - val_loss: 0.2249 - val_accuracy: 0.9421\n",
      "Epoch 61/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0899 - accuracy: 0.9788 - val_loss: 0.2291 - val_accuracy: 0.9426\n",
      "Epoch 62/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0922 - accuracy: 0.9787 - val_loss: 0.2263 - val_accuracy: 0.9439\n",
      "Epoch 63/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0882 - accuracy: 0.9794 - val_loss: 0.2344 - val_accuracy: 0.9426\n",
      "Epoch 64/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0871 - accuracy: 0.9800 - val_loss: 0.2251 - val_accuracy: 0.9426\n",
      "Epoch 65/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0924 - accuracy: 0.9778 - val_loss: 0.2275 - val_accuracy: 0.9456\n",
      "Epoch 66/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0902 - accuracy: 0.9789 - val_loss: 0.2217 - val_accuracy: 0.9462\n",
      "Epoch 67/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0894 - accuracy: 0.9786 - val_loss: 0.2240 - val_accuracy: 0.9446\n",
      "Epoch 68/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0930 - accuracy: 0.9775 - val_loss: 0.2272 - val_accuracy: 0.9405\n",
      "Epoch 69/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0915 - accuracy: 0.9782 - val_loss: 0.2302 - val_accuracy: 0.9428\n",
      "Epoch 70/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0883 - accuracy: 0.9803 - val_loss: 0.2248 - val_accuracy: 0.9435\n",
      "Epoch 71/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0912 - accuracy: 0.9788 - val_loss: 0.2304 - val_accuracy: 0.9419\n",
      "Epoch 72/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0904 - accuracy: 0.9780 - val_loss: 0.2381 - val_accuracy: 0.9412\n",
      "Epoch 73/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0928 - accuracy: 0.9779 - val_loss: 0.2278 - val_accuracy: 0.9437\n",
      "Epoch 74/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0910 - accuracy: 0.9789 - val_loss: 0.2267 - val_accuracy: 0.9426\n",
      "Epoch 75/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0918 - accuracy: 0.9778 - val_loss: 0.2330 - val_accuracy: 0.9407\n",
      "Epoch 76/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0914 - accuracy: 0.9780 - val_loss: 0.2351 - val_accuracy: 0.9389\n",
      "Epoch 77/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0919 - accuracy: 0.9784 - val_loss: 0.2309 - val_accuracy: 0.9423\n",
      "Epoch 78/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0857 - accuracy: 0.9802 - val_loss: 0.2347 - val_accuracy: 0.9407\n",
      "Epoch 79/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0855 - accuracy: 0.9803 - val_loss: 0.2382 - val_accuracy: 0.9417\n",
      "Epoch 80/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0905 - accuracy: 0.9788 - val_loss: 0.2282 - val_accuracy: 0.9407\n",
      "Epoch 81/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0886 - accuracy: 0.9788 - val_loss: 0.2350 - val_accuracy: 0.9412\n",
      "Epoch 82/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0896 - accuracy: 0.9789 - val_loss: 0.2278 - val_accuracy: 0.9421\n",
      "Epoch 83/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0879 - accuracy: 0.9796 - val_loss: 0.2294 - val_accuracy: 0.9407\n",
      "Epoch 84/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0882 - accuracy: 0.9793 - val_loss: 0.2309 - val_accuracy: 0.9405\n",
      "Epoch 85/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0893 - accuracy: 0.9796 - val_loss: 0.2303 - val_accuracy: 0.9417\n",
      "Epoch 86/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0844 - accuracy: 0.9806 - val_loss: 0.2263 - val_accuracy: 0.9426\n",
      "Epoch 87/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0881 - accuracy: 0.9799 - val_loss: 0.2358 - val_accuracy: 0.9414\n",
      "Epoch 88/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0846 - accuracy: 0.9811 - val_loss: 0.2279 - val_accuracy: 0.9419\n",
      "Epoch 89/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0863 - accuracy: 0.9798 - val_loss: 0.2277 - val_accuracy: 0.9403\n",
      "Epoch 90/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0896 - accuracy: 0.9780 - val_loss: 0.2311 - val_accuracy: 0.9378\n",
      "Epoch 91/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0885 - accuracy: 0.9802 - val_loss: 0.2287 - val_accuracy: 0.9426\n",
      "Epoch 92/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0863 - accuracy: 0.9801 - val_loss: 0.2317 - val_accuracy: 0.9419\n",
      "Epoch 93/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0878 - accuracy: 0.9802 - val_loss: 0.2326 - val_accuracy: 0.9394\n",
      "Epoch 94/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0859 - accuracy: 0.9803 - val_loss: 0.2272 - val_accuracy: 0.9421\n",
      "Epoch 95/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0861 - accuracy: 0.9796 - val_loss: 0.2277 - val_accuracy: 0.9437\n",
      "Epoch 96/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0863 - accuracy: 0.9802 - val_loss: 0.2261 - val_accuracy: 0.9430\n",
      "Epoch 97/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0856 - accuracy: 0.9806 - val_loss: 0.2235 - val_accuracy: 0.9469\n",
      "Epoch 98/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0892 - accuracy: 0.9792 - val_loss: 0.2234 - val_accuracy: 0.9423\n",
      "Epoch 99/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0842 - accuracy: 0.9803 - val_loss: 0.2208 - val_accuracy: 0.9430\n",
      "Epoch 100/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0901 - accuracy: 0.9790 - val_loss: 0.2268 - val_accuracy: 0.9419\n",
      "Epoch 101/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0875 - accuracy: 0.9797 - val_loss: 0.2270 - val_accuracy: 0.9423\n",
      "Epoch 102/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0867 - accuracy: 0.9793 - val_loss: 0.2306 - val_accuracy: 0.9437\n",
      "Epoch 103/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0868 - accuracy: 0.9796 - val_loss: 0.2310 - val_accuracy: 0.9410\n",
      "Epoch 104/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0865 - accuracy: 0.9796 - val_loss: 0.2357 - val_accuracy: 0.9410\n",
      "Epoch 105/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0869 - accuracy: 0.9798 - val_loss: 0.2321 - val_accuracy: 0.9405\n",
      "Epoch 106/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0842 - accuracy: 0.9810 - val_loss: 0.2267 - val_accuracy: 0.9442\n",
      "Epoch 107/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0863 - accuracy: 0.9806 - val_loss: 0.2344 - val_accuracy: 0.9423\n",
      "Epoch 108/500\n",
      "1093/1093 [==============================] - 13s 12ms/step - loss: 0.0863 - accuracy: 0.9807 - val_loss: 0.2336 - val_accuracy: 0.9423\n",
      "Epoch 109/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0845 - accuracy: 0.9802 - val_loss: 0.2296 - val_accuracy: 0.9428\n",
      "Epoch 110/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0869 - accuracy: 0.9791 - val_loss: 0.2304 - val_accuracy: 0.9435\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0847 - accuracy: 0.9808 - val_loss: 0.2308 - val_accuracy: 0.9439\n",
      "Epoch 112/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0863 - accuracy: 0.9802 - val_loss: 0.2293 - val_accuracy: 0.9433\n",
      "Epoch 113/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0837 - accuracy: 0.9809 - val_loss: 0.2308 - val_accuracy: 0.9421\n",
      "Epoch 114/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0870 - accuracy: 0.9796 - val_loss: 0.2287 - val_accuracy: 0.9437\n",
      "Epoch 115/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0848 - accuracy: 0.9809 - val_loss: 0.2320 - val_accuracy: 0.9449\n",
      "Epoch 116/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0835 - accuracy: 0.9810 - val_loss: 0.2322 - val_accuracy: 0.9428\n",
      "Epoch 117/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0843 - accuracy: 0.9807 - val_loss: 0.2281 - val_accuracy: 0.9456\n",
      "Epoch 118/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0896 - accuracy: 0.9796 - val_loss: 0.2276 - val_accuracy: 0.9428\n",
      "Epoch 119/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0849 - accuracy: 0.9806 - val_loss: 0.2280 - val_accuracy: 0.9430\n",
      "Epoch 120/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0808 - accuracy: 0.9822 - val_loss: 0.2294 - val_accuracy: 0.9433\n",
      "Epoch 121/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0835 - accuracy: 0.9802 - val_loss: 0.2372 - val_accuracy: 0.9405\n",
      "Epoch 122/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0842 - accuracy: 0.9805 - val_loss: 0.2273 - val_accuracy: 0.9430\n",
      "Epoch 123/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0860 - accuracy: 0.9798 - val_loss: 0.2287 - val_accuracy: 0.9405\n",
      "Epoch 124/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0839 - accuracy: 0.9816 - val_loss: 0.2360 - val_accuracy: 0.9396\n",
      "Epoch 125/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0827 - accuracy: 0.9810 - val_loss: 0.2274 - val_accuracy: 0.9446\n",
      "Epoch 126/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0816 - accuracy: 0.9808 - val_loss: 0.2271 - val_accuracy: 0.9426\n",
      "Epoch 127/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0843 - accuracy: 0.9803 - val_loss: 0.2339 - val_accuracy: 0.9433\n",
      "Epoch 128/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0809 - accuracy: 0.9817 - val_loss: 0.2308 - val_accuracy: 0.9407\n",
      "Epoch 129/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0829 - accuracy: 0.9806 - val_loss: 0.2294 - val_accuracy: 0.9423\n",
      "Epoch 130/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0846 - accuracy: 0.9801 - val_loss: 0.2261 - val_accuracy: 0.9426\n",
      "Epoch 131/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0828 - accuracy: 0.9814 - val_loss: 0.2298 - val_accuracy: 0.9433\n",
      "Epoch 132/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0850 - accuracy: 0.9808 - val_loss: 0.2278 - val_accuracy: 0.9426\n",
      "Epoch 133/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0825 - accuracy: 0.9809 - val_loss: 0.2267 - val_accuracy: 0.9433\n",
      "Epoch 134/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.0869 - accuracy: 0.9803 - val_loss: 0.2228 - val_accuracy: 0.9444\n",
      "Epoch 135/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0813 - accuracy: 0.9817 - val_loss: 0.2333 - val_accuracy: 0.9433\n",
      "Epoch 136/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0812 - accuracy: 0.9816 - val_loss: 0.2277 - val_accuracy: 0.9423\n",
      "Epoch 137/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0821 - accuracy: 0.9807 - val_loss: 0.2279 - val_accuracy: 0.9444\n",
      "Epoch 138/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0808 - accuracy: 0.9821 - val_loss: 0.2355 - val_accuracy: 0.9401\n",
      "Epoch 139/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0841 - accuracy: 0.9810 - val_loss: 0.2304 - val_accuracy: 0.9391\n",
      "Epoch 140/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0849 - accuracy: 0.9804 - val_loss: 0.2262 - val_accuracy: 0.9421\n",
      "Epoch 141/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0842 - accuracy: 0.9810 - val_loss: 0.2295 - val_accuracy: 0.9428\n",
      "Epoch 142/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0811 - accuracy: 0.9813 - val_loss: 0.2332 - val_accuracy: 0.9426\n",
      "Epoch 143/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.0821 - accuracy: 0.9816 - val_loss: 0.2260 - val_accuracy: 0.9437\n",
      "Epoch 144/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.0832 - accuracy: 0.9814 - val_loss: 0.2283 - val_accuracy: 0.9435\n",
      "Epoch 145/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0868 - accuracy: 0.9808 - val_loss: 0.2303 - val_accuracy: 0.9428\n",
      "Epoch 146/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0857 - accuracy: 0.9793 - val_loss: 0.2336 - val_accuracy: 0.9405\n",
      "Epoch 147/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0829 - accuracy: 0.9810 - val_loss: 0.2354 - val_accuracy: 0.9394\n",
      "Epoch 148/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0823 - accuracy: 0.9808 - val_loss: 0.2315 - val_accuracy: 0.9419\n",
      "Epoch 149/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0828 - accuracy: 0.9809 - val_loss: 0.2351 - val_accuracy: 0.9414\n",
      "Epoch 150/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0826 - accuracy: 0.9809 - val_loss: 0.2240 - val_accuracy: 0.9435\n",
      "Epoch 151/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0833 - accuracy: 0.9811 - val_loss: 0.2312 - val_accuracy: 0.9426\n",
      "Epoch 152/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.0822 - accuracy: 0.9818 - val_loss: 0.2352 - val_accuracy: 0.9430\n",
      "Epoch 153/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0793 - accuracy: 0.9826 - val_loss: 0.2241 - val_accuracy: 0.9442\n",
      "Epoch 154/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0813 - accuracy: 0.9819 - val_loss: 0.2359 - val_accuracy: 0.9391\n",
      "Epoch 155/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0823 - accuracy: 0.9815 - val_loss: 0.2281 - val_accuracy: 0.9423\n",
      "Epoch 156/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.0804 - accuracy: 0.9821 - val_loss: 0.2251 - val_accuracy: 0.9439\n",
      "Epoch 157/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0816 - accuracy: 0.9814 - val_loss: 0.2287 - val_accuracy: 0.9419\n",
      "Epoch 158/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0822 - accuracy: 0.9816 - val_loss: 0.2349 - val_accuracy: 0.9403\n",
      "Epoch 159/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0856 - accuracy: 0.9797 - val_loss: 0.2306 - val_accuracy: 0.9407\n",
      "Epoch 160/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0780 - accuracy: 0.9822 - val_loss: 0.2348 - val_accuracy: 0.9412\n",
      "Epoch 161/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0824 - accuracy: 0.9814 - val_loss: 0.2257 - val_accuracy: 0.9435\n",
      "Epoch 162/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0810 - accuracy: 0.9815 - val_loss: 0.2305 - val_accuracy: 0.9412\n",
      "Epoch 163/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0844 - accuracy: 0.9813 - val_loss: 0.2337 - val_accuracy: 0.9428\n",
      "Epoch 164/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0797 - accuracy: 0.9820 - val_loss: 0.2313 - val_accuracy: 0.9414\n",
      "Epoch 165/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.0815 - accuracy: 0.9813 - val_loss: 0.2319 - val_accuracy: 0.9389\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0809 - accuracy: 0.9813 - val_loss: 0.2333 - val_accuracy: 0.9444\n",
      "Epoch 167/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0813 - accuracy: 0.9817 - val_loss: 0.2211 - val_accuracy: 0.9460\n",
      "Epoch 168/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0823 - accuracy: 0.9810 - val_loss: 0.2226 - val_accuracy: 0.9453\n",
      "Epoch 169/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0826 - accuracy: 0.9810 - val_loss: 0.2344 - val_accuracy: 0.9401\n",
      "Epoch 170/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0792 - accuracy: 0.9819 - val_loss: 0.2310 - val_accuracy: 0.9430\n",
      "Epoch 171/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0809 - accuracy: 0.9817 - val_loss: 0.2380 - val_accuracy: 0.9417\n",
      "Epoch 172/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0797 - accuracy: 0.9814 - val_loss: 0.2302 - val_accuracy: 0.9421\n",
      "Epoch 173/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0820 - accuracy: 0.9820 - val_loss: 0.2321 - val_accuracy: 0.9430\n",
      "Epoch 174/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0801 - accuracy: 0.9829 - val_loss: 0.2358 - val_accuracy: 0.9435\n",
      "Epoch 175/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0800 - accuracy: 0.9816 - val_loss: 0.2268 - val_accuracy: 0.9417\n",
      "Epoch 176/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0778 - accuracy: 0.9829 - val_loss: 0.2297 - val_accuracy: 0.9442\n",
      "Epoch 177/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0832 - accuracy: 0.9809 - val_loss: 0.2326 - val_accuracy: 0.9428\n",
      "Epoch 178/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0787 - accuracy: 0.9818 - val_loss: 0.2272 - val_accuracy: 0.9430\n",
      "Epoch 179/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0804 - accuracy: 0.9824 - val_loss: 0.2290 - val_accuracy: 0.9444\n",
      "Epoch 180/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0799 - accuracy: 0.9827 - val_loss: 0.2275 - val_accuracy: 0.9446\n",
      "Epoch 181/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0793 - accuracy: 0.9822 - val_loss: 0.2349 - val_accuracy: 0.9442\n",
      "Epoch 182/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0803 - accuracy: 0.9816 - val_loss: 0.2305 - val_accuracy: 0.9451\n",
      "Epoch 183/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0780 - accuracy: 0.9825 - val_loss: 0.2329 - val_accuracy: 0.9401\n",
      "Epoch 184/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9828 - val_loss: 0.2323 - val_accuracy: 0.9451\n",
      "Epoch 185/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0767 - accuracy: 0.9833 - val_loss: 0.2302 - val_accuracy: 0.9444\n",
      "Epoch 186/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0781 - accuracy: 0.9826 - val_loss: 0.2272 - val_accuracy: 0.9444\n",
      "Epoch 187/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0815 - accuracy: 0.9821 - val_loss: 0.2326 - val_accuracy: 0.9437\n",
      "Epoch 188/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0816 - accuracy: 0.9810 - val_loss: 0.2281 - val_accuracy: 0.9451\n",
      "Epoch 189/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0774 - accuracy: 0.9824 - val_loss: 0.2308 - val_accuracy: 0.9439\n",
      "Epoch 190/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0823 - accuracy: 0.9810 - val_loss: 0.2269 - val_accuracy: 0.9465\n",
      "Epoch 191/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0780 - accuracy: 0.9830 - val_loss: 0.2360 - val_accuracy: 0.9426\n",
      "Epoch 192/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0773 - accuracy: 0.9832 - val_loss: 0.2283 - val_accuracy: 0.9430\n",
      "Epoch 193/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0783 - accuracy: 0.9823 - val_loss: 0.2310 - val_accuracy: 0.9412\n",
      "Epoch 194/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0776 - accuracy: 0.9831 - val_loss: 0.2338 - val_accuracy: 0.9421\n",
      "Epoch 195/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0769 - accuracy: 0.9829 - val_loss: 0.2306 - val_accuracy: 0.9437\n",
      "Epoch 196/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0759 - accuracy: 0.9828 - val_loss: 0.2360 - val_accuracy: 0.9421\n",
      "Epoch 197/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0806 - accuracy: 0.9826 - val_loss: 0.2257 - val_accuracy: 0.9460\n",
      "Epoch 198/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0769 - accuracy: 0.9829 - val_loss: 0.2343 - val_accuracy: 0.9435\n",
      "Epoch 199/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0754 - accuracy: 0.9841 - val_loss: 0.2279 - val_accuracy: 0.9446\n",
      "Epoch 200/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0775 - accuracy: 0.9834 - val_loss: 0.2270 - val_accuracy: 0.9435\n",
      "Epoch 201/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9838 - val_loss: 0.2322 - val_accuracy: 0.9405\n",
      "Epoch 202/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0804 - accuracy: 0.9816 - val_loss: 0.2312 - val_accuracy: 0.9419\n",
      "Epoch 203/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0760 - accuracy: 0.9834 - val_loss: 0.2350 - val_accuracy: 0.9428\n",
      "Epoch 204/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0769 - accuracy: 0.9831 - val_loss: 0.2313 - val_accuracy: 0.9412\n",
      "Epoch 205/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0754 - accuracy: 0.9836 - val_loss: 0.2293 - val_accuracy: 0.9449\n",
      "Epoch 206/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0762 - accuracy: 0.9834 - val_loss: 0.2275 - val_accuracy: 0.9444\n",
      "Epoch 207/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0780 - accuracy: 0.9832 - val_loss: 0.2348 - val_accuracy: 0.9412\n",
      "Epoch 208/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0760 - accuracy: 0.9832 - val_loss: 0.2282 - val_accuracy: 0.9449\n",
      "Epoch 209/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0760 - accuracy: 0.9838 - val_loss: 0.2362 - val_accuracy: 0.9437\n",
      "Epoch 210/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0769 - accuracy: 0.9828 - val_loss: 0.2374 - val_accuracy: 0.9414\n",
      "Epoch 211/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0756 - accuracy: 0.9836 - val_loss: 0.2340 - val_accuracy: 0.9421\n",
      "Epoch 212/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0751 - accuracy: 0.9830 - val_loss: 0.2276 - val_accuracy: 0.9449\n",
      "Epoch 213/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0755 - accuracy: 0.9836 - val_loss: 0.2306 - val_accuracy: 0.9419\n",
      "Epoch 214/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9832 - val_loss: 0.2306 - val_accuracy: 0.9433\n",
      "Epoch 215/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9834 - val_loss: 0.2297 - val_accuracy: 0.9421\n",
      "Epoch 216/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0784 - accuracy: 0.9825 - val_loss: 0.2312 - val_accuracy: 0.9426\n",
      "Epoch 217/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0782 - accuracy: 0.9834 - val_loss: 0.2246 - val_accuracy: 0.9435\n",
      "Epoch 218/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0758 - accuracy: 0.9836 - val_loss: 0.2308 - val_accuracy: 0.9421\n",
      "Epoch 219/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0757 - accuracy: 0.9832 - val_loss: 0.2257 - val_accuracy: 0.9426\n",
      "Epoch 220/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9829 - val_loss: 0.2254 - val_accuracy: 0.9439\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0778 - accuracy: 0.9828 - val_loss: 0.2281 - val_accuracy: 0.9449\n",
      "Epoch 222/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0759 - accuracy: 0.9836 - val_loss: 0.2327 - val_accuracy: 0.9423\n",
      "Epoch 223/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0778 - accuracy: 0.9827 - val_loss: 0.2356 - val_accuracy: 0.9403\n",
      "Epoch 224/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0736 - accuracy: 0.9843 - val_loss: 0.2284 - val_accuracy: 0.9437\n",
      "Epoch 225/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0775 - accuracy: 0.9834 - val_loss: 0.2311 - val_accuracy: 0.9417\n",
      "Epoch 226/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0765 - accuracy: 0.9833 - val_loss: 0.2287 - val_accuracy: 0.9437\n",
      "Epoch 227/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0765 - accuracy: 0.9833 - val_loss: 0.2351 - val_accuracy: 0.9426\n",
      "Epoch 228/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0755 - accuracy: 0.9833 - val_loss: 0.2354 - val_accuracy: 0.9437\n",
      "Epoch 229/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0751 - accuracy: 0.9837 - val_loss: 0.2318 - val_accuracy: 0.9423\n",
      "Epoch 230/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0768 - accuracy: 0.9828 - val_loss: 0.2237 - val_accuracy: 0.9442\n",
      "Epoch 231/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0749 - accuracy: 0.9835 - val_loss: 0.2349 - val_accuracy: 0.9412\n",
      "Epoch 232/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0766 - accuracy: 0.9830 - val_loss: 0.2355 - val_accuracy: 0.9442\n",
      "Epoch 233/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0756 - accuracy: 0.9838 - val_loss: 0.2314 - val_accuracy: 0.9437\n",
      "Epoch 234/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0766 - accuracy: 0.9832 - val_loss: 0.2307 - val_accuracy: 0.9428\n",
      "Epoch 235/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0752 - accuracy: 0.9841 - val_loss: 0.2346 - val_accuracy: 0.9433\n",
      "Epoch 236/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0775 - accuracy: 0.9826 - val_loss: 0.2341 - val_accuracy: 0.9412\n",
      "Epoch 237/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0762 - accuracy: 0.9829 - val_loss: 0.2340 - val_accuracy: 0.9403\n",
      "Epoch 238/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0746 - accuracy: 0.9842 - val_loss: 0.2345 - val_accuracy: 0.9446\n",
      "Epoch 239/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0722 - accuracy: 0.9852 - val_loss: 0.2319 - val_accuracy: 0.9430\n",
      "Epoch 240/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0755 - accuracy: 0.9830 - val_loss: 0.2274 - val_accuracy: 0.9460\n",
      "Epoch 241/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0730 - accuracy: 0.9841 - val_loss: 0.2334 - val_accuracy: 0.9401\n",
      "Epoch 242/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0747 - accuracy: 0.9838 - val_loss: 0.2376 - val_accuracy: 0.9396\n",
      "Epoch 243/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0755 - accuracy: 0.9836 - val_loss: 0.2304 - val_accuracy: 0.9417\n",
      "Epoch 244/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0763 - accuracy: 0.9841 - val_loss: 0.2278 - val_accuracy: 0.9458\n",
      "Epoch 245/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0768 - accuracy: 0.9828 - val_loss: 0.2306 - val_accuracy: 0.9414\n",
      "Epoch 246/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0726 - accuracy: 0.9847 - val_loss: 0.2239 - val_accuracy: 0.9458\n",
      "Epoch 247/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0732 - accuracy: 0.9846 - val_loss: 0.2298 - val_accuracy: 0.9451\n",
      "Epoch 248/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0752 - accuracy: 0.9839 - val_loss: 0.2403 - val_accuracy: 0.9403\n",
      "Epoch 249/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0740 - accuracy: 0.9839 - val_loss: 0.2325 - val_accuracy: 0.9433\n",
      "Epoch 250/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0740 - accuracy: 0.9841 - val_loss: 0.2294 - val_accuracy: 0.9435\n",
      "Epoch 251/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0743 - accuracy: 0.9838 - val_loss: 0.2345 - val_accuracy: 0.9433\n",
      "Epoch 252/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0741 - accuracy: 0.9844 - val_loss: 0.2282 - val_accuracy: 0.9442\n",
      "Epoch 253/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0745 - accuracy: 0.9846 - val_loss: 0.2279 - val_accuracy: 0.9446\n",
      "Epoch 254/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0718 - accuracy: 0.9845 - val_loss: 0.2281 - val_accuracy: 0.9458\n",
      "Epoch 255/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0741 - accuracy: 0.9838 - val_loss: 0.2376 - val_accuracy: 0.9421\n",
      "Epoch 256/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0728 - accuracy: 0.9838 - val_loss: 0.2309 - val_accuracy: 0.9449\n",
      "Epoch 257/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0734 - accuracy: 0.9846 - val_loss: 0.2288 - val_accuracy: 0.9437\n",
      "Epoch 258/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0716 - accuracy: 0.9853 - val_loss: 0.2367 - val_accuracy: 0.9419\n",
      "Epoch 259/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0716 - accuracy: 0.9847 - val_loss: 0.2357 - val_accuracy: 0.9442\n",
      "Epoch 260/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0747 - accuracy: 0.9840 - val_loss: 0.2388 - val_accuracy: 0.9414\n",
      "Epoch 261/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0741 - accuracy: 0.9844 - val_loss: 0.2339 - val_accuracy: 0.9410\n",
      "Epoch 262/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0723 - accuracy: 0.9851 - val_loss: 0.2416 - val_accuracy: 0.9414\n",
      "Epoch 263/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0727 - accuracy: 0.9848 - val_loss: 0.2304 - val_accuracy: 0.9437\n",
      "Epoch 264/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0724 - accuracy: 0.9850 - val_loss: 0.2452 - val_accuracy: 0.9391\n",
      "Epoch 265/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0707 - accuracy: 0.9851 - val_loss: 0.2405 - val_accuracy: 0.9405\n",
      "Epoch 266/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0708 - accuracy: 0.9845 - val_loss: 0.2337 - val_accuracy: 0.9442\n",
      "Epoch 267/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0726 - accuracy: 0.9846 - val_loss: 0.2312 - val_accuracy: 0.9421\n",
      "Epoch 268/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0727 - accuracy: 0.9844 - val_loss: 0.2402 - val_accuracy: 0.9433\n",
      "Epoch 269/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0728 - accuracy: 0.9844 - val_loss: 0.2311 - val_accuracy: 0.9451\n",
      "Epoch 270/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0722 - accuracy: 0.9848 - val_loss: 0.2369 - val_accuracy: 0.9437\n",
      "Epoch 271/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0699 - accuracy: 0.9856 - val_loss: 0.2380 - val_accuracy: 0.9426\n",
      "Epoch 272/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0722 - accuracy: 0.9844 - val_loss: 0.2342 - val_accuracy: 0.9451\n",
      "Epoch 273/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0713 - accuracy: 0.9851 - val_loss: 0.2291 - val_accuracy: 0.9439\n",
      "Epoch 274/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0736 - accuracy: 0.9847 - val_loss: 0.2371 - val_accuracy: 0.9428\n",
      "Epoch 275/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0693 - accuracy: 0.9863 - val_loss: 0.2401 - val_accuracy: 0.9414\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0699 - accuracy: 0.9860 - val_loss: 0.2273 - val_accuracy: 0.9456\n",
      "Epoch 277/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0697 - accuracy: 0.9855 - val_loss: 0.2332 - val_accuracy: 0.9446\n",
      "Epoch 278/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0699 - accuracy: 0.9857 - val_loss: 0.2299 - val_accuracy: 0.9430\n",
      "Epoch 279/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0713 - accuracy: 0.9851 - val_loss: 0.2289 - val_accuracy: 0.9469\n",
      "Epoch 280/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0712 - accuracy: 0.9851 - val_loss: 0.2395 - val_accuracy: 0.9433\n",
      "Epoch 281/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0705 - accuracy: 0.9862 - val_loss: 0.2332 - val_accuracy: 0.9398\n",
      "Epoch 282/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0694 - accuracy: 0.9857 - val_loss: 0.2420 - val_accuracy: 0.9417\n",
      "Epoch 283/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0709 - accuracy: 0.9846 - val_loss: 0.2342 - val_accuracy: 0.9446\n",
      "Epoch 284/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0713 - accuracy: 0.9848 - val_loss: 0.2382 - val_accuracy: 0.9428\n",
      "Epoch 285/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0704 - accuracy: 0.9855 - val_loss: 0.2414 - val_accuracy: 0.9428\n",
      "Epoch 286/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0732 - accuracy: 0.9841 - val_loss: 0.2298 - val_accuracy: 0.9451\n",
      "Epoch 287/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0693 - accuracy: 0.9852 - val_loss: 0.2298 - val_accuracy: 0.9451\n",
      "Epoch 288/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0705 - accuracy: 0.9856 - val_loss: 0.2383 - val_accuracy: 0.9430\n",
      "Epoch 289/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0716 - accuracy: 0.9852 - val_loss: 0.2303 - val_accuracy: 0.9465\n",
      "Epoch 290/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0687 - accuracy: 0.9865 - val_loss: 0.2296 - val_accuracy: 0.9442\n",
      "Epoch 291/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0697 - accuracy: 0.9854 - val_loss: 0.2285 - val_accuracy: 0.9462\n",
      "Epoch 292/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0665 - accuracy: 0.9874 - val_loss: 0.2315 - val_accuracy: 0.9428\n",
      "Epoch 293/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0685 - accuracy: 0.9861 - val_loss: 0.2352 - val_accuracy: 0.9451\n",
      "Epoch 294/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0662 - accuracy: 0.9867 - val_loss: 0.2338 - val_accuracy: 0.9428\n",
      "Epoch 295/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0688 - accuracy: 0.9857 - val_loss: 0.2360 - val_accuracy: 0.9437\n",
      "Epoch 296/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0686 - accuracy: 0.9857 - val_loss: 0.2353 - val_accuracy: 0.9458\n",
      "Epoch 297/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0675 - accuracy: 0.9874 - val_loss: 0.2379 - val_accuracy: 0.9451\n",
      "Epoch 298/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0667 - accuracy: 0.9869 - val_loss: 0.2302 - val_accuracy: 0.9442\n",
      "Epoch 299/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0677 - accuracy: 0.9866 - val_loss: 0.2342 - val_accuracy: 0.9453\n",
      "Epoch 300/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0653 - accuracy: 0.9867 - val_loss: 0.2333 - val_accuracy: 0.9449\n",
      "Epoch 301/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0678 - accuracy: 0.9868 - val_loss: 0.2387 - val_accuracy: 0.9405\n",
      "Epoch 302/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0679 - accuracy: 0.9863 - val_loss: 0.2388 - val_accuracy: 0.9430\n",
      "Epoch 303/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0679 - accuracy: 0.9866 - val_loss: 0.2405 - val_accuracy: 0.9426\n",
      "Epoch 304/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0639 - accuracy: 0.9876 - val_loss: 0.2535 - val_accuracy: 0.9403\n",
      "Epoch 305/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0660 - accuracy: 0.9874 - val_loss: 0.2356 - val_accuracy: 0.9453\n",
      "Epoch 306/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0643 - accuracy: 0.9876 - val_loss: 0.2409 - val_accuracy: 0.9417\n",
      "Epoch 307/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0676 - accuracy: 0.9867 - val_loss: 0.2291 - val_accuracy: 0.9414\n",
      "Epoch 308/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0640 - accuracy: 0.9882 - val_loss: 0.2362 - val_accuracy: 0.9426\n",
      "Epoch 309/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0633 - accuracy: 0.9880 - val_loss: 0.2350 - val_accuracy: 0.9437\n",
      "Epoch 310/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0664 - accuracy: 0.9872 - val_loss: 0.2387 - val_accuracy: 0.9421\n",
      "Epoch 311/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0628 - accuracy: 0.9886 - val_loss: 0.2375 - val_accuracy: 0.9426\n",
      "Epoch 312/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0827 - accuracy: 0.9817 - val_loss: 0.2444 - val_accuracy: 0.9423\n",
      "Epoch 313/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0816 - accuracy: 0.9818 - val_loss: 0.2408 - val_accuracy: 0.9421\n",
      "Epoch 314/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0830 - accuracy: 0.9810 - val_loss: 0.2297 - val_accuracy: 0.9444\n",
      "Epoch 315/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0798 - accuracy: 0.9811 - val_loss: 0.2345 - val_accuracy: 0.9403\n",
      "Epoch 316/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0836 - accuracy: 0.9802 - val_loss: 0.2348 - val_accuracy: 0.9446\n",
      "Epoch 317/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0803 - accuracy: 0.9819 - val_loss: 0.2350 - val_accuracy: 0.9433\n",
      "Epoch 318/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0808 - accuracy: 0.9820 - val_loss: 0.2373 - val_accuracy: 0.9433\n",
      "Epoch 319/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0807 - accuracy: 0.9819 - val_loss: 0.2297 - val_accuracy: 0.9449\n",
      "Epoch 320/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0800 - accuracy: 0.9816 - val_loss: 0.2353 - val_accuracy: 0.9423\n",
      "Epoch 321/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0794 - accuracy: 0.9822 - val_loss: 0.2360 - val_accuracy: 0.9446\n",
      "Epoch 322/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0818 - accuracy: 0.9809 - val_loss: 0.2404 - val_accuracy: 0.9435\n",
      "Epoch 323/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0813 - accuracy: 0.9820 - val_loss: 0.2328 - val_accuracy: 0.9446\n",
      "Epoch 324/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0819 - accuracy: 0.9816 - val_loss: 0.2415 - val_accuracy: 0.9417\n",
      "Epoch 325/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0827 - accuracy: 0.9806 - val_loss: 0.2345 - val_accuracy: 0.9430\n",
      "Epoch 326/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0805 - accuracy: 0.9816 - val_loss: 0.2371 - val_accuracy: 0.9453\n",
      "Epoch 327/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0799 - accuracy: 0.9819 - val_loss: 0.2403 - val_accuracy: 0.9417\n",
      "Epoch 328/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0801 - accuracy: 0.9823 - val_loss: 0.2315 - val_accuracy: 0.9433\n",
      "Epoch 329/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0794 - accuracy: 0.9822 - val_loss: 0.2407 - val_accuracy: 0.9410\n",
      "Epoch 330/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0801 - accuracy: 0.9821 - val_loss: 0.2330 - val_accuracy: 0.9433\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0821 - accuracy: 0.9813 - val_loss: 0.2338 - val_accuracy: 0.9430\n",
      "Epoch 332/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0798 - accuracy: 0.9829 - val_loss: 0.2306 - val_accuracy: 0.9439\n",
      "Epoch 333/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0805 - accuracy: 0.9820 - val_loss: 0.2310 - val_accuracy: 0.9433\n",
      "Epoch 334/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9826 - val_loss: 0.2318 - val_accuracy: 0.9419\n",
      "Epoch 335/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0817 - accuracy: 0.9820 - val_loss: 0.2329 - val_accuracy: 0.9430\n",
      "Epoch 336/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0803 - accuracy: 0.9819 - val_loss: 0.2354 - val_accuracy: 0.9439\n",
      "Epoch 337/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0824 - accuracy: 0.9812 - val_loss: 0.2353 - val_accuracy: 0.9421\n",
      "Epoch 338/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0785 - accuracy: 0.9824 - val_loss: 0.2347 - val_accuracy: 0.9421\n",
      "Epoch 339/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0780 - accuracy: 0.9823 - val_loss: 0.2367 - val_accuracy: 0.9433\n",
      "Epoch 340/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0810 - accuracy: 0.9823 - val_loss: 0.2416 - val_accuracy: 0.9426\n",
      "Epoch 341/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9822 - val_loss: 0.2442 - val_accuracy: 0.9398\n",
      "Epoch 342/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0783 - accuracy: 0.9827 - val_loss: 0.2404 - val_accuracy: 0.9423\n",
      "Epoch 343/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0823 - accuracy: 0.9822 - val_loss: 0.2355 - val_accuracy: 0.9414\n",
      "Epoch 344/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9829 - val_loss: 0.2406 - val_accuracy: 0.9417\n",
      "Epoch 345/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0802 - accuracy: 0.9816 - val_loss: 0.2337 - val_accuracy: 0.9444\n",
      "Epoch 346/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0796 - accuracy: 0.9819 - val_loss: 0.2298 - val_accuracy: 0.9444\n",
      "Epoch 347/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0826 - accuracy: 0.9812 - val_loss: 0.2298 - val_accuracy: 0.9453\n",
      "Epoch 348/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0784 - accuracy: 0.9824 - val_loss: 0.2314 - val_accuracy: 0.9462\n",
      "Epoch 349/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0813 - accuracy: 0.9815 - val_loss: 0.2378 - val_accuracy: 0.9401\n",
      "Epoch 350/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0825 - accuracy: 0.9812 - val_loss: 0.2308 - val_accuracy: 0.9467\n",
      "Epoch 351/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0774 - accuracy: 0.9831 - val_loss: 0.2331 - val_accuracy: 0.9439\n",
      "Epoch 352/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0824 - accuracy: 0.9810 - val_loss: 0.2343 - val_accuracy: 0.9426\n",
      "Epoch 353/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0805 - accuracy: 0.9820 - val_loss: 0.2283 - val_accuracy: 0.9442\n",
      "Epoch 354/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0818 - accuracy: 0.9809 - val_loss: 0.2288 - val_accuracy: 0.9446\n",
      "Epoch 355/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0800 - accuracy: 0.9831 - val_loss: 0.2358 - val_accuracy: 0.9446\n",
      "Epoch 356/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0832 - accuracy: 0.9808 - val_loss: 0.2337 - val_accuracy: 0.9423\n",
      "Epoch 357/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0798 - accuracy: 0.9825 - val_loss: 0.2344 - val_accuracy: 0.9435\n",
      "Epoch 358/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0791 - accuracy: 0.9825 - val_loss: 0.2372 - val_accuracy: 0.9405\n",
      "Epoch 359/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9832 - val_loss: 0.2325 - val_accuracy: 0.9430\n",
      "Epoch 360/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0799 - accuracy: 0.9815 - val_loss: 0.2392 - val_accuracy: 0.9446\n",
      "Epoch 361/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0799 - accuracy: 0.9813 - val_loss: 0.2372 - val_accuracy: 0.9428\n",
      "Epoch 362/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0805 - accuracy: 0.9816 - val_loss: 0.2409 - val_accuracy: 0.9423\n",
      "Epoch 363/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0823 - accuracy: 0.9816 - val_loss: 0.2365 - val_accuracy: 0.9421\n",
      "Epoch 364/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0776 - accuracy: 0.9826 - val_loss: 0.2316 - val_accuracy: 0.9449\n",
      "Epoch 365/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0808 - accuracy: 0.9813 - val_loss: 0.2298 - val_accuracy: 0.9453\n",
      "Epoch 366/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0817 - accuracy: 0.9809 - val_loss: 0.2349 - val_accuracy: 0.9451\n",
      "Epoch 367/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0821 - accuracy: 0.9807 - val_loss: 0.2365 - val_accuracy: 0.9449\n",
      "Epoch 368/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0790 - accuracy: 0.9822 - val_loss: 0.2347 - val_accuracy: 0.9446\n",
      "Epoch 369/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0785 - accuracy: 0.9822 - val_loss: 0.2411 - val_accuracy: 0.9442\n",
      "Epoch 370/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0799 - accuracy: 0.9815 - val_loss: 0.2383 - val_accuracy: 0.9412\n",
      "Epoch 371/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0797 - accuracy: 0.9822 - val_loss: 0.2348 - val_accuracy: 0.9460\n",
      "Epoch 372/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0785 - accuracy: 0.9826 - val_loss: 0.2360 - val_accuracy: 0.9449\n",
      "Epoch 373/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0794 - accuracy: 0.9822 - val_loss: 0.2382 - val_accuracy: 0.9435\n",
      "Epoch 374/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0813 - accuracy: 0.9823 - val_loss: 0.2346 - val_accuracy: 0.9428\n",
      "Epoch 375/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0783 - accuracy: 0.9832 - val_loss: 0.2349 - val_accuracy: 0.9426\n",
      "Epoch 376/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0810 - accuracy: 0.9819 - val_loss: 0.2351 - val_accuracy: 0.9451\n",
      "Epoch 377/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0776 - accuracy: 0.9827 - val_loss: 0.2393 - val_accuracy: 0.9414\n",
      "Epoch 378/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0774 - accuracy: 0.9829 - val_loss: 0.2368 - val_accuracy: 0.9439\n",
      "Epoch 379/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0787 - accuracy: 0.9820 - val_loss: 0.2394 - val_accuracy: 0.9417\n",
      "Epoch 380/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0771 - accuracy: 0.9834 - val_loss: 0.2381 - val_accuracy: 0.9421\n",
      "Epoch 381/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0764 - accuracy: 0.9834 - val_loss: 0.2352 - val_accuracy: 0.9430\n",
      "Epoch 382/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0765 - accuracy: 0.9829 - val_loss: 0.2397 - val_accuracy: 0.9419\n",
      "Epoch 383/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0785 - accuracy: 0.9823 - val_loss: 0.2376 - val_accuracy: 0.9433\n",
      "Epoch 384/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9820 - val_loss: 0.2303 - val_accuracy: 0.9421\n",
      "Epoch 385/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0744 - accuracy: 0.9833 - val_loss: 0.2356 - val_accuracy: 0.9423\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0792 - accuracy: 0.9825 - val_loss: 0.2380 - val_accuracy: 0.9430\n",
      "Epoch 387/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0783 - accuracy: 0.9816 - val_loss: 0.2362 - val_accuracy: 0.9435\n",
      "Epoch 388/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0812 - accuracy: 0.9817 - val_loss: 0.2345 - val_accuracy: 0.9444\n",
      "Epoch 389/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0759 - accuracy: 0.9836 - val_loss: 0.2309 - val_accuracy: 0.9449\n",
      "Epoch 390/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0783 - accuracy: 0.9831 - val_loss: 0.2428 - val_accuracy: 0.9428\n",
      "Epoch 391/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0790 - accuracy: 0.9817 - val_loss: 0.2354 - val_accuracy: 0.9412\n",
      "Epoch 392/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0807 - accuracy: 0.9814 - val_loss: 0.2348 - val_accuracy: 0.9417\n",
      "Epoch 393/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0771 - accuracy: 0.9825 - val_loss: 0.2371 - val_accuracy: 0.9423\n",
      "Epoch 394/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0796 - accuracy: 0.9816 - val_loss: 0.2487 - val_accuracy: 0.9407\n",
      "Epoch 395/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0805 - accuracy: 0.9818 - val_loss: 0.2400 - val_accuracy: 0.9426\n",
      "Epoch 396/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0770 - accuracy: 0.9829 - val_loss: 0.2309 - val_accuracy: 0.9437\n",
      "Epoch 397/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0768 - accuracy: 0.9836 - val_loss: 0.2399 - val_accuracy: 0.9417\n",
      "Epoch 398/500\n",
      "1093/1093 [==============================] - 13s 12ms/step - loss: 0.0798 - accuracy: 0.9816 - val_loss: 0.2350 - val_accuracy: 0.9421\n",
      "Epoch 399/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0795 - accuracy: 0.9820 - val_loss: 0.2369 - val_accuracy: 0.9426\n",
      "Epoch 400/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9820 - val_loss: 0.2320 - val_accuracy: 0.9439\n",
      "Epoch 401/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0774 - accuracy: 0.9821 - val_loss: 0.2324 - val_accuracy: 0.9412\n",
      "Epoch 402/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0797 - accuracy: 0.9818 - val_loss: 0.2360 - val_accuracy: 0.9419\n",
      "Epoch 403/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9825 - val_loss: 0.2412 - val_accuracy: 0.9414\n",
      "Epoch 404/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0775 - accuracy: 0.9830 - val_loss: 0.2352 - val_accuracy: 0.9417\n",
      "Epoch 405/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0811 - accuracy: 0.9820 - val_loss: 0.2335 - val_accuracy: 0.9414\n",
      "Epoch 406/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0770 - accuracy: 0.9832 - val_loss: 0.2380 - val_accuracy: 0.9426\n",
      "Epoch 407/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0789 - accuracy: 0.9814 - val_loss: 0.2361 - val_accuracy: 0.9430\n",
      "Epoch 408/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0788 - accuracy: 0.9817 - val_loss: 0.2373 - val_accuracy: 0.9417\n",
      "Epoch 409/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0782 - accuracy: 0.9825 - val_loss: 0.2274 - val_accuracy: 0.9444\n",
      "Epoch 410/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9831 - val_loss: 0.2283 - val_accuracy: 0.9458\n",
      "Epoch 411/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9822 - val_loss: 0.2379 - val_accuracy: 0.9426\n",
      "Epoch 412/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0779 - accuracy: 0.9820 - val_loss: 0.2317 - val_accuracy: 0.9433\n",
      "Epoch 413/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0784 - accuracy: 0.9821 - val_loss: 0.2339 - val_accuracy: 0.9426\n",
      "Epoch 414/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0779 - accuracy: 0.9825 - val_loss: 0.2363 - val_accuracy: 0.9398\n",
      "Epoch 415/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0761 - accuracy: 0.9834 - val_loss: 0.2336 - val_accuracy: 0.9442\n",
      "Epoch 416/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0788 - accuracy: 0.9827 - val_loss: 0.2340 - val_accuracy: 0.9433\n",
      "Epoch 417/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0775 - accuracy: 0.9832 - val_loss: 0.2385 - val_accuracy: 0.9423\n",
      "Epoch 418/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0785 - accuracy: 0.9821 - val_loss: 0.2364 - val_accuracy: 0.9442\n",
      "Epoch 419/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9826 - val_loss: 0.2378 - val_accuracy: 0.9433\n",
      "Epoch 420/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0790 - accuracy: 0.9824 - val_loss: 0.2340 - val_accuracy: 0.9449\n",
      "Epoch 421/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0776 - accuracy: 0.9826 - val_loss: 0.2333 - val_accuracy: 0.9423\n",
      "Epoch 422/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0789 - accuracy: 0.9822 - val_loss: 0.2307 - val_accuracy: 0.9446\n",
      "Epoch 423/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0798 - accuracy: 0.9818 - val_loss: 0.2225 - val_accuracy: 0.9469\n",
      "Epoch 424/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0769 - accuracy: 0.9835 - val_loss: 0.2373 - val_accuracy: 0.9414\n",
      "Epoch 425/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0787 - accuracy: 0.9824 - val_loss: 0.2306 - val_accuracy: 0.9437\n",
      "Epoch 426/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0757 - accuracy: 0.9842 - val_loss: 0.2346 - val_accuracy: 0.9428\n",
      "Epoch 427/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0787 - accuracy: 0.9823 - val_loss: 0.2379 - val_accuracy: 0.9410\n",
      "Epoch 428/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0784 - accuracy: 0.9827 - val_loss: 0.2345 - val_accuracy: 0.9439\n",
      "Epoch 429/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0769 - accuracy: 0.9831 - val_loss: 0.2318 - val_accuracy: 0.9460\n",
      "Epoch 430/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0786 - accuracy: 0.9827 - val_loss: 0.2404 - val_accuracy: 0.9433\n",
      "Epoch 431/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0758 - accuracy: 0.9834 - val_loss: 0.2351 - val_accuracy: 0.9430\n",
      "Epoch 432/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0796 - accuracy: 0.9823 - val_loss: 0.2314 - val_accuracy: 0.9442\n",
      "Epoch 433/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0793 - accuracy: 0.9825 - val_loss: 0.2436 - val_accuracy: 0.9405\n",
      "Epoch 434/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0801 - accuracy: 0.9813 - val_loss: 0.2301 - val_accuracy: 0.9437\n",
      "Epoch 435/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0794 - accuracy: 0.9818 - val_loss: 0.2296 - val_accuracy: 0.9439\n",
      "Epoch 436/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0784 - accuracy: 0.9821 - val_loss: 0.2309 - val_accuracy: 0.9433\n",
      "Epoch 437/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0779 - accuracy: 0.9826 - val_loss: 0.2298 - val_accuracy: 0.9453\n",
      "Epoch 438/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0809 - accuracy: 0.9811 - val_loss: 0.2277 - val_accuracy: 0.9465\n",
      "Epoch 439/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0780 - accuracy: 0.9827 - val_loss: 0.2317 - val_accuracy: 0.9430\n",
      "Epoch 440/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0813 - accuracy: 0.9820 - val_loss: 0.2218 - val_accuracy: 0.9456\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0787 - accuracy: 0.9824 - val_loss: 0.2358 - val_accuracy: 0.9423\n",
      "Epoch 442/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0761 - accuracy: 0.9832 - val_loss: 0.2328 - val_accuracy: 0.9410\n",
      "Epoch 443/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0750 - accuracy: 0.9842 - val_loss: 0.2319 - val_accuracy: 0.9435\n",
      "Epoch 444/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0745 - accuracy: 0.9839 - val_loss: 0.2311 - val_accuracy: 0.9442\n",
      "Epoch 445/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0764 - accuracy: 0.9833 - val_loss: 0.2287 - val_accuracy: 0.9442\n",
      "Epoch 446/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0777 - accuracy: 0.9822 - val_loss: 0.2307 - val_accuracy: 0.9433\n",
      "Epoch 447/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0774 - accuracy: 0.9829 - val_loss: 0.2365 - val_accuracy: 0.9421\n",
      "Epoch 448/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0800 - accuracy: 0.9818 - val_loss: 0.2405 - val_accuracy: 0.9421\n",
      "Epoch 449/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0773 - accuracy: 0.9832 - val_loss: 0.2340 - val_accuracy: 0.9435\n",
      "Epoch 450/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0805 - accuracy: 0.9807 - val_loss: 0.2250 - val_accuracy: 0.9439\n",
      "Epoch 451/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0759 - accuracy: 0.9831 - val_loss: 0.2291 - val_accuracy: 0.9437\n",
      "Epoch 452/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9821 - val_loss: 0.2334 - val_accuracy: 0.9430\n",
      "Epoch 453/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0735 - accuracy: 0.9844 - val_loss: 0.2276 - val_accuracy: 0.9437\n",
      "Epoch 454/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0767 - accuracy: 0.9825 - val_loss: 0.2386 - val_accuracy: 0.9430\n",
      "Epoch 455/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0782 - accuracy: 0.9830 - val_loss: 0.2377 - val_accuracy: 0.9405\n",
      "Epoch 456/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0790 - accuracy: 0.9815 - val_loss: 0.2312 - val_accuracy: 0.9444\n",
      "Epoch 457/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0776 - accuracy: 0.9826 - val_loss: 0.2365 - val_accuracy: 0.9423\n",
      "Epoch 458/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0798 - accuracy: 0.9830 - val_loss: 0.2345 - val_accuracy: 0.9421\n",
      "Epoch 459/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0750 - accuracy: 0.9830 - val_loss: 0.2350 - val_accuracy: 0.9437\n",
      "Epoch 460/500\n",
      "1093/1093 [==============================] - 13s 12ms/step - loss: 0.0763 - accuracy: 0.9835 - val_loss: 0.2301 - val_accuracy: 0.9421\n",
      "Epoch 461/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0780 - accuracy: 0.9827 - val_loss: 0.2263 - val_accuracy: 0.9435\n",
      "Epoch 462/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0772 - accuracy: 0.9828 - val_loss: 0.2342 - val_accuracy: 0.9407\n",
      "Epoch 463/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0778 - accuracy: 0.9830 - val_loss: 0.2299 - val_accuracy: 0.9437\n",
      "Epoch 464/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0767 - accuracy: 0.9832 - val_loss: 0.2303 - val_accuracy: 0.9435\n",
      "Epoch 465/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0774 - accuracy: 0.9827 - val_loss: 0.2356 - val_accuracy: 0.9439\n",
      "Epoch 466/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0767 - accuracy: 0.9833 - val_loss: 0.2249 - val_accuracy: 0.9460\n",
      "Epoch 467/500\n",
      "1093/1093 [==============================] - 13s 12ms/step - loss: 0.0758 - accuracy: 0.9836 - val_loss: 0.2313 - val_accuracy: 0.9423\n",
      "Epoch 468/500\n",
      "1093/1093 [==============================] - 13s 12ms/step - loss: 0.0792 - accuracy: 0.9823 - val_loss: 0.2227 - val_accuracy: 0.9435\n",
      "Epoch 469/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0756 - accuracy: 0.9832 - val_loss: 0.2305 - val_accuracy: 0.9419\n",
      "Epoch 470/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0758 - accuracy: 0.9833 - val_loss: 0.2348 - val_accuracy: 0.9433\n",
      "Epoch 471/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0777 - accuracy: 0.9832 - val_loss: 0.2363 - val_accuracy: 0.9423\n",
      "Epoch 472/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0752 - accuracy: 0.9842 - val_loss: 0.2292 - val_accuracy: 0.9433\n",
      "Epoch 473/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0794 - accuracy: 0.9818 - val_loss: 0.2312 - val_accuracy: 0.9451\n",
      "Epoch 474/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0770 - accuracy: 0.9828 - val_loss: 0.2330 - val_accuracy: 0.9435\n",
      "Epoch 475/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0769 - accuracy: 0.9831 - val_loss: 0.2334 - val_accuracy: 0.9430\n",
      "Epoch 476/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0749 - accuracy: 0.9836 - val_loss: 0.2332 - val_accuracy: 0.9439\n",
      "Epoch 477/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0776 - accuracy: 0.9828 - val_loss: 0.2347 - val_accuracy: 0.9426\n",
      "Epoch 478/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0750 - accuracy: 0.9838 - val_loss: 0.2303 - val_accuracy: 0.9446\n",
      "Epoch 479/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0765 - accuracy: 0.9833 - val_loss: 0.2279 - val_accuracy: 0.9449\n",
      "Epoch 480/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0762 - accuracy: 0.9833 - val_loss: 0.2394 - val_accuracy: 0.9403\n",
      "Epoch 481/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0745 - accuracy: 0.9835 - val_loss: 0.2343 - val_accuracy: 0.9435\n",
      "Epoch 482/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0766 - accuracy: 0.9839 - val_loss: 0.2405 - val_accuracy: 0.9437\n",
      "Epoch 483/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0777 - accuracy: 0.9828 - val_loss: 0.2333 - val_accuracy: 0.9435\n",
      "Epoch 484/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0818 - accuracy: 0.9813 - val_loss: 0.2325 - val_accuracy: 0.9419\n",
      "Epoch 485/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0773 - accuracy: 0.9828 - val_loss: 0.2325 - val_accuracy: 0.9437\n",
      "Epoch 486/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0740 - accuracy: 0.9839 - val_loss: 0.2272 - val_accuracy: 0.9451\n",
      "Epoch 487/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0756 - accuracy: 0.9839 - val_loss: 0.2397 - val_accuracy: 0.9407\n",
      "Epoch 488/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0776 - accuracy: 0.9826 - val_loss: 0.2274 - val_accuracy: 0.9453\n",
      "Epoch 489/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0764 - accuracy: 0.9833 - val_loss: 0.2357 - val_accuracy: 0.9428\n",
      "Epoch 490/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0774 - accuracy: 0.9822 - val_loss: 0.2288 - val_accuracy: 0.9421\n",
      "Epoch 491/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0775 - accuracy: 0.9828 - val_loss: 0.2267 - val_accuracy: 0.9444\n",
      "Epoch 492/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0770 - accuracy: 0.9830 - val_loss: 0.2399 - val_accuracy: 0.9421\n",
      "Epoch 493/500\n",
      "1093/1093 [==============================] - 14s 12ms/step - loss: 0.0776 - accuracy: 0.9826 - val_loss: 0.2376 - val_accuracy: 0.9417\n",
      "Epoch 494/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9829 - val_loss: 0.2324 - val_accuracy: 0.9428\n",
      "Epoch 495/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0777 - accuracy: 0.9826 - val_loss: 0.2385 - val_accuracy: 0.9439\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0745 - accuracy: 0.9838 - val_loss: 0.2326 - val_accuracy: 0.9423\n",
      "Epoch 497/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0758 - accuracy: 0.9836 - val_loss: 0.2295 - val_accuracy: 0.9451\n",
      "Epoch 498/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0767 - accuracy: 0.9830 - val_loss: 0.2294 - val_accuracy: 0.9426\n",
      "Epoch 499/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0767 - accuracy: 0.9831 - val_loss: 0.2317 - val_accuracy: 0.9437\n",
      "Epoch 500/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0760 - accuracy: 0.9834 - val_loss: 0.2318 - val_accuracy: 0.9430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8ec0ac9e20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantization aware training, in which the best model is saved\n",
    "\n",
    "EPOCHS = 500\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "history = quantized_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),  \n",
    "    epochs=EPOCHS,\n",
    "    batch_size = 32,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "quantized_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38d549d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106266/897927363.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
      "/tmp/ipykernel_106266/897927363.py:11: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
      "/tmp/ipykernel_106266/897927363.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
      "/tmp/ipykernel_106266/897927363.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d116b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized CNN model\n",
    "\n",
    "models.save_model(quantized_model, Quantized_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4037feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Optional if pretrained ##########\n",
    "\n",
    "quantized_model.load_weights(Quantized_model_filename)\n",
    "quantized_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63d68f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of quantized CNN: 99.97426867485046 %\n",
      "Accuracy on validation set of quantized CNN: 94.69228982925415 %\n",
      "Accuracy on test set with SNR of 1 of quantized CNN: 77.76252627372742 %\n",
      "Accuracy on test set with SNR of 10 of quantized CNN: 91.19194746017456 %\n",
      "Accuracy on test set with SNR of 20 of quantized CNN: 93.80004405975342 %\n",
      "Accuracy on test set with SNR of 100 of quantized CNN: 94.44063305854797 %\n",
      "Accuracy on test set with SNR of 1000 of quantized CNN: 94.50926780700684 %\n"
     ]
    }
   ],
   "source": [
    "# Print peformance of the quantized CNN after quantization aware training\n",
    "\n",
    "score = quantized_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of quantized CNN:', score[1] * 100,'%')\n",
    "\n",
    "score = quantized_model.evaluate(x_test1, y_test1, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test10, y_test10, verbose=0)\n",
    "print('Accuracy on test set with SNR of 10 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test20, y_test20, verbose=0)\n",
    "print('Accuracy on test set with SNR of 20 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test100, y_test100, verbose=0)\n",
    "print('Accuracy on test set with SNR of 100 of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test1000, y_test1000, verbose=0)\n",
    "print('Accuracy on test set with SNR of 1000 of quantized CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae62e5",
   "metadata": {},
   "source": [
    "<font size=\"5\">4. Akida Model Conversion</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4efc22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Summary                 \n",
      "_______________________________________________\n",
      "Input shape   Output shape  Sequences  Layers\n",
      "===============================================\n",
      "[40, 101, 1]  [1, 1, 12]    1          10    \n",
      "_______________________________________________\n",
      "\n",
      "                SW/conv_0-dense (Software)                 \n",
      "___________________________________________________________\n",
      "Layer (type)             Output shape   Kernel shape     \n",
      "===========================================================\n",
      "conv_0 (InputConv.)      [51, 20, 32]   (3, 3, 1, 32)    \n",
      "___________________________________________________________\n",
      "separable_1 (Sep.Conv.)  [51, 20, 32]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 32)   \n",
      "___________________________________________________________\n",
      "separable_2 (Sep.Conv.)  [26, 10, 64]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 64)   \n",
      "___________________________________________________________\n",
      "separable_3 (Sep.Conv.)  [26, 10, 128]  (3, 3, 64, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 64, 128)  \n",
      "___________________________________________________________\n",
      "separable_4 (Sep.Conv.)  [13, 5, 128]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 128) \n",
      "___________________________________________________________\n",
      "separable_5 (Sep.Conv.)  [13, 5, 256]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 256) \n",
      "___________________________________________________________\n",
      "separable_6 (Sep.Conv.)  [7, 3, 256]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 256) \n",
      "___________________________________________________________\n",
      "separable_7 (Sep.Conv.)  [4, 2, 512]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 512) \n",
      "___________________________________________________________\n",
      "separable_8 (Sep.Conv.)  [1, 1, 1024]   (3, 3, 512, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 512, 1024)\n",
      "___________________________________________________________\n",
      "dense (Fully.)           [1, 1, 12]     (1, 1, 1024, 12) \n",
      "___________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Convert to an Akida model\n",
    "\n",
    "akida_model = convert(quantized_model)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6c944ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN accuracy on training set after conversion: 99.9742680695334 %\n",
      "SNN accuracy on validation set after conversion: 94.71516815374056 %\n",
      "SNN accuracy on test set with SNR of 1 after conversion: 77.3278425989476 %\n",
      "SNN accuracy on test set with SNR of 10 after conversion: 91.12331274307938 %\n",
      "SNN accuracy on test set with SNR of 20 after conversion: 93.98307023564402 %\n",
      "SNN accuracy on test set with SNR of 100 after conversion: 94.55502173415694 %\n",
      "SNN accuracy on test set with SNR of 1000 after conversion: 94.69229009380004 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the final Akida model\n",
    "\n",
    "results = akida_model.predict(x_train)\n",
    "accuracy = (y_train == results).mean()\n",
    "\n",
    "print('SNN accuracy on training set after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_val)\n",
    "accuracy = (y_val == results).mean()\n",
    "\n",
    "print('SNN accuracy on validation set after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test1)\n",
    "accuracy = (y_test1 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 1 after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test10)\n",
    "accuracy = (y_test10 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 10 after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test20)\n",
    "accuracy = (y_test20 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 20 after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test100)\n",
    "accuracy = (y_test100 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 100 after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test1000)\n",
    "accuracy = (y_test1000 == results).mean()\n",
    "print('SNN accuracy on test set with SNR of 1000 after conversion:', accuracy * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb59492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
