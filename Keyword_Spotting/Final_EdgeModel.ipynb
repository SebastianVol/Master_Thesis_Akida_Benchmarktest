{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c5a3c65",
   "metadata": {},
   "source": [
    "<font size=\"5\">Edge Model</font>\n",
    "\n",
    "In this notebook, a model gets trained on the Google Speech Command Dataset V2 without the keywords backward, forward, and follow. These three keywords get added later when trained on the Akida neural processor from BrainChip. The code was inspired by the official code from BrainChip (https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d98b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and dependencies\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "import akida\n",
    "from akida import FullyConnected\n",
    "from akida import evaluate_sparsity\n",
    "import cnn2snn\n",
    "from cnn2snn import check_model_compatibility\n",
    "from cnn2snn import quantize\n",
    "from cnn2snn import quantize_layer\n",
    "from cnn2snn import convert\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import (Input, Reshape, Activation, Flatten, Rescaling, Add, Dropout)\n",
    "\n",
    "import akida_models\n",
    "from akida_models import layer_blocks\n",
    "from akida_models.layer_blocks import conv_block, separable_conv_block, dense_block\n",
    "\n",
    "from time import time\n",
    "\n",
    "from math import ceil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004de406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, set seed for experiment reproducibility\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f2e3e",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 1. Load the Data Set</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7801fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories of the data\n",
    "\n",
    "data_dir = pathlib.Path('data/Modded_Google_wEdge')\n",
    "data_dir_edge = pathlib.Path('data/Modded_Google_Edge')\n",
    "edge_dir = pathlib.Path('data/Edge_Categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c09dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known and unknown commands: ['off' 'up' 'down' 'on' 'stop' 'yes' 'right' 'unknown' 'left' 'go' 'no'\n",
      " 'silence' 'forward' 'follow' 'backward']\n",
      "Newly added commands for edge learning: ['forward' 'follow' 'backward']\n"
     ]
    }
   ],
   "source": [
    "# Print commands\n",
    "\n",
    "targets = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "\n",
    "targets = targets[targets != 'README.md']\n",
    "\n",
    "targets = targets[targets != 'follow']\n",
    "targets = targets[targets != 'forward']\n",
    "targets = targets[targets != 'backward']\n",
    "\n",
    "targets_edge = np.array(tf.io.gfile.listdir(str(edge_dir)))\n",
    "\n",
    "targets = np.append(targets, targets_edge)\n",
    "\n",
    "print('Known and unknown commands:', targets)\n",
    "print('Newly added commands for edge learning:', targets_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf58b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories, and names of the model and data sets\n",
    "\n",
    "feature_sets_path = '/home/sebastian/Schreibtisch/Masterarbeit/Audio/'\n",
    "feature_sets_filename = 'final_stored_files_targets_int_normalized_wedge.npz'\n",
    "feature_sets_filename_edge = 'final_stored_files_targets_int_normalized_edge.npz'\n",
    "\n",
    "CNN_model_filename = 'final_CNN_edge_model.h5'\n",
    "Quantized_model_filename = 'final_quantized_edge_model.h5'\n",
    "Akida_model_filename = 'final_akida_edge_variable_bits_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7da8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Sets:  ['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']\n",
      "Feature Sets for Edge:  ['x_train', 'y_train', 'x_val', 'y_val']\n"
     ]
    }
   ],
   "source": [
    "# Load data sets\n",
    "\n",
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "feature_sets_edge = np.load(join(feature_sets_path, feature_sets_filename_edge))\n",
    "print('Feature Sets: ', feature_sets.files)\n",
    "print('Feature Sets for Edge: ', feature_sets_edge.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d22817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets\n",
    "\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac6c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets for the edge categories\n",
    "# There is no test set in the data set of the edge categories. \n",
    "\n",
    "x_train_edge = feature_sets_edge['x_train']\n",
    "y_train_edge = feature_sets_edge['y_train']\n",
    "x_val_edge = feature_sets_edge['x_val']\n",
    "y_val_edge = feature_sets_edge['y_val']\n",
    "#x_test_edge = feature_sets_edge['x_test']\n",
    "#y_test_edge = feature_sets_edge['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3614c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (34972, 40, 101)\n",
      "x_val shape:  (4371, 40, 101)\n",
      "x_test shape:  (4371, 40, 101)\n",
      "x_train_edge shape:  (714, 40, 101)\n",
      "x_val_edge shape:  (85, 40, 101)\n"
     ]
    }
   ],
   "source": [
    "# Look at tensor dimensions\n",
    "\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('x_val shape: ', x_val.shape)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "print('x_train_edge shape: ', x_train_edge.shape)\n",
    "print('x_val_edge shape: ', x_val_edge.shape)\n",
    "#print('x_test_edge shape: ', x_test_edge.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834f237",
   "metadata": {},
   "source": [
    "Check the dimensions of the data set. \n",
    "Is the unknown and silence category roughly 10% (Category 7 and 11)?\n",
    "In the edge data set, are there only 5 utterances of each new target in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7391d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 2735,\n",
       " 1.0: 2621,\n",
       " 2.0: 2880,\n",
       " 3.0: 2763,\n",
       " 4.0: 2874,\n",
       " 5.0: 2972,\n",
       " 6.0: 2750,\n",
       " 7.0: 3500,\n",
       " 8.0: 2783,\n",
       " 9.0: 2776,\n",
       " 10.0: 2852,\n",
       " 11.0: 3466}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training set dimensions of the initial training set, without the keywords\n",
    "# backward, forward, follow. \n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e59bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 340,\n",
       " 1.0: 340,\n",
       " 2.0: 348,\n",
       " 3.0: 358,\n",
       " 4.0: 353,\n",
       " 5.0: 347,\n",
       " 6.0: 335,\n",
       " 7.0: 438,\n",
       " 8.0: 343,\n",
       " 9.0: 360,\n",
       " 10.0: 349,\n",
       " 11.0: 460}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training set dimensions of the initial validation set, without the keywords\n",
    "# backward, forward, follow. \n",
    "\n",
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4a5de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 352,\n",
       " 1.0: 308,\n",
       " 2.0: 352,\n",
       " 3.0: 350,\n",
       " 4.0: 336,\n",
       " 5.0: 373,\n",
       " 6.0: 363,\n",
       " 7.0: 433,\n",
       " 8.0: 376,\n",
       " 9.0: 342,\n",
       " 10.0: 344,\n",
       " 11.0: 442}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training set dimensions of the initial test set, without the keywords\n",
    "# backward, forward, follow. \n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df2e911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 45,\n",
       " 1.0: 45,\n",
       " 2.0: 45,\n",
       " 3.0: 45,\n",
       " 4.0: 45,\n",
       " 5.0: 45,\n",
       " 6.0: 45,\n",
       " 7.0: 72,\n",
       " 8.0: 45,\n",
       " 9.0: 45,\n",
       " 10.0: 45,\n",
       " 11.0: 72,\n",
       " 12.0: 40,\n",
       " 13.0: 40,\n",
       " 14.0: 40}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training set dimensions of the data set with the edge categories backward, forward, follow. \n",
    "\n",
    "unique_edge, counts_edge = np.unique(y_train_edge, return_counts=True)\n",
    "dict(zip(unique_edge, counts_edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c8d46fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 5,\n",
       " 1.0: 5,\n",
       " 2.0: 5,\n",
       " 3.0: 5,\n",
       " 4.0: 5,\n",
       " 5.0: 5,\n",
       " 6.0: 5,\n",
       " 7.0: 8,\n",
       " 8.0: 5,\n",
       " 9.0: 5,\n",
       " 10.0: 5,\n",
       " 11.0: 8,\n",
       " 12.0: 6,\n",
       " 13.0: 7,\n",
       " 14.0: 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check validation set dimensions of the data set with the edge categories backward, forward, follow. \n",
    "\n",
    "unique_edge, counts_edge = np.unique(y_val_edge, return_counts=True)\n",
    "dict(zip(unique_edge, counts_edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe971e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels:  12\n",
      "number of edge labels:  15\n"
     ]
    }
   ],
   "source": [
    "# Define the number of labels for both data sets. \n",
    "\n",
    "num_labels = len(unique)\n",
    "num_labels_edge = len(unique_edge)\n",
    "print('number of labels: ', num_labels)\n",
    "print('number of edge labels: ', num_labels_edge)\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc71662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add dimension to all data: Order Train, Val, Test, Train_edge, Val_edge: \n",
      "(34972, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(714, 40, 101, 1)\n",
      "(85, 40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN for conversion expects (batch, height, width, channels)\n",
    "# The channels can either be 1 for gray-scaled images or 3 for RGB-images\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "x_val = x_val.reshape(x_val.shape[0], \n",
    "                      x_val.shape[1], \n",
    "                      x_val.shape[2], \n",
    "                      1)\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)\n",
    "\n",
    "x_train_edge = x_train_edge.reshape(x_train_edge.shape[0], \n",
    "                          x_train_edge.shape[1], \n",
    "                          x_train_edge.shape[2], \n",
    "                          1)\n",
    "x_val_edge = x_val_edge.reshape(x_val_edge.shape[0], \n",
    "                      x_val_edge.shape[1], \n",
    "                      x_val_edge.shape[2], \n",
    "                      1)\n",
    "\n",
    "\n",
    "\n",
    "print('Add dimension to all data: Order Train, Val, Test, Train_edge, Val_edge: ')\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "print(x_train_edge.shape)\n",
    "print(x_val_edge.shape)\n",
    "#print(x_test_edge.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a5cc2",
   "metadata": {},
   "source": [
    "<font size=\"5\">2. Train and Save the CNN-Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0476781a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of 1 Tensor/MFCC:  (40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape for the CNN, namely the dimension of 1 MFCC\n",
    "\n",
    "input_shape = x_test.shape[1:]\n",
    "print('Input shape of 1 Tensor/MFCC: ', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bbeb2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 20, 51, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_0_BN (BatchNormalizatio (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ReLU)           (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (SeparableConv2D (None, 20, 51, 32)        1312      \n",
      "_________________________________________________________________\n",
      "separable_1_BN (BatchNormali (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "separable_1_relu (ReLU)      (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (SeparableConv2D (None, 10, 26, 64)        2336      \n",
      "_________________________________________________________________\n",
      "separable_2_BN (BatchNormali (None, 10, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_2_relu (ReLU)      (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (SeparableConv2D (None, 10, 26, 128)       8768      \n",
      "_________________________________________________________________\n",
      "separable_3_BN (BatchNormali (None, 10, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_3_relu (ReLU)      (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (SeparableConv2D (None, 5, 13, 128)        17536     \n",
      "_________________________________________________________________\n",
      "separable_4_BN (BatchNormali (None, 5, 13, 128)        512       \n",
      "_________________________________________________________________\n",
      "separable_4_relu (ReLU)      (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (SeparableConv2D (None, 5, 13, 256)        33920     \n",
      "_________________________________________________________________\n",
      "separable_5_BN (BatchNormali (None, 5, 13, 256)        1024      \n",
      "_________________________________________________________________\n",
      "separable_5_relu (ReLU)      (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (SeparableConv2D (None, 3, 7, 256)         67840     \n",
      "_________________________________________________________________\n",
      "separable_6_BN (BatchNormali (None, 3, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "separable_6_relu (ReLU)      (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (SeparableConv2D (None, 2, 4, 512)         133376    \n",
      "_________________________________________________________________\n",
      "separable_7_BN (BatchNormali (None, 2, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "separable_7_relu (ReLU)      (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (SeparableConv2D (None, 2, 4, 1024)        528896    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_BN (BatchNormali (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "separable_8_relu (ReLU)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 816,348\n",
      "Trainable params: 811,460\n",
      "Non-trainable params: 4,888\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 19:33:13.202150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.243270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.243430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.243767: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-15 19:33:13.244173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.244328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.244438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.575667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.575817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.575924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 19:33:13.576022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# CNN created with the functional API and from akida_models layer_blocks\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Rescaling(1. / 255)(inputs)\n",
    "x = conv_block(x,\n",
    "               filters=32,\n",
    "               kernel_size=(3, 3),\n",
    "               padding='same',\n",
    "               strides=(2, 2),\n",
    "               use_bias=False,\n",
    "               name='conv_0',\n",
    "               add_batchnorm=True)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=32,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_1',\n",
    "                         add_batchnorm=True)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=64,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_2',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=128,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_3',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=128,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_4',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=256,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_5',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=256,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_6',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=512,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_7',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=1024,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_8',\n",
    "                         pooling='global_avg',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "shape = (1, 1, int(1024))\n",
    "x = Reshape(shape, name='reshape_1')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = layers.Dense(units = 12, activation='linear', use_bias = True)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "outputs = layers.Activation('softmax')(x)\n",
    "\n",
    "CNN_model = keras.Model(inputs=inputs, outputs=outputs, name='CNN_model')\n",
    "\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0a1e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compatible for Akida conversion: True\n"
     ]
    }
   ],
   "source": [
    "# Check if model is compatible\n",
    "\n",
    "print(\"Model compatible for Akida conversion:\", check_model_compatibility(CNN_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cec7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN model\n",
    "\n",
    "CNN_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "360da738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 19:33:33.510254: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 19:33:35.220936: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8301\n",
      "2022-04-15 19:33:36.117505: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-15 19:33:36.303208: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 15s 11ms/step - loss: 2.1544 - accuracy: 0.2556 - val_loss: 1.5314 - val_accuracy: 0.4981\n",
      "Epoch 2/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 1.2486 - accuracy: 0.6075 - val_loss: 0.8020 - val_accuracy: 0.7440\n",
      "Epoch 3/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.9142 - accuracy: 0.7170 - val_loss: 0.5844 - val_accuracy: 0.8229\n",
      "Epoch 4/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.7936 - accuracy: 0.7540 - val_loss: 0.5315 - val_accuracy: 0.8280\n",
      "Epoch 5/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.7019 - accuracy: 0.7825 - val_loss: 0.5451 - val_accuracy: 0.8428\n",
      "Epoch 6/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.6443 - accuracy: 0.8035 - val_loss: 0.3971 - val_accuracy: 0.8742\n",
      "Epoch 7/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.5984 - accuracy: 0.8164 - val_loss: 0.4038 - val_accuracy: 0.8703\n",
      "Epoch 8/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.5550 - accuracy: 0.8313 - val_loss: 0.3589 - val_accuracy: 0.8886\n",
      "Epoch 9/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.5264 - accuracy: 0.8370 - val_loss: 0.3261 - val_accuracy: 0.8987\n",
      "Epoch 10/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.5078 - accuracy: 0.8453 - val_loss: 0.4942 - val_accuracy: 0.8582\n",
      "Epoch 11/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.4803 - accuracy: 0.8519 - val_loss: 0.2924 - val_accuracy: 0.9067\n",
      "Epoch 12/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.4589 - accuracy: 0.8595 - val_loss: 0.3606 - val_accuracy: 0.8966\n",
      "Epoch 13/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.4422 - accuracy: 0.8646 - val_loss: 0.2837 - val_accuracy: 0.9089\n",
      "Epoch 14/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.4278 - accuracy: 0.8679 - val_loss: 0.3051 - val_accuracy: 0.9083\n",
      "Epoch 15/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.4114 - accuracy: 0.8729 - val_loss: 0.4314 - val_accuracy: 0.8776\n",
      "Epoch 16/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3976 - accuracy: 0.8756 - val_loss: 0.2851 - val_accuracy: 0.9112\n",
      "Epoch 17/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3884 - accuracy: 0.8795 - val_loss: 0.2928 - val_accuracy: 0.9078\n",
      "Epoch 18/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3759 - accuracy: 0.8836 - val_loss: 0.2882 - val_accuracy: 0.9119\n",
      "Epoch 19/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3683 - accuracy: 0.8848 - val_loss: 0.2567 - val_accuracy: 0.9167\n",
      "Epoch 20/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3564 - accuracy: 0.8869 - val_loss: 0.3013 - val_accuracy: 0.9057\n",
      "Epoch 21/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3527 - accuracy: 0.8886 - val_loss: 0.2644 - val_accuracy: 0.9190\n",
      "Epoch 22/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3392 - accuracy: 0.8932 - val_loss: 0.2661 - val_accuracy: 0.9137\n",
      "Epoch 23/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3331 - accuracy: 0.8960 - val_loss: 0.2419 - val_accuracy: 0.9234\n",
      "Epoch 24/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3236 - accuracy: 0.8971 - val_loss: 0.2378 - val_accuracy: 0.9284\n",
      "Epoch 25/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3187 - accuracy: 0.8994 - val_loss: 0.2346 - val_accuracy: 0.9259\n",
      "Epoch 26/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3150 - accuracy: 0.8993 - val_loss: 0.2446 - val_accuracy: 0.9236\n",
      "Epoch 27/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.3078 - accuracy: 0.9029 - val_loss: 0.2381 - val_accuracy: 0.9252\n",
      "Epoch 28/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3060 - accuracy: 0.9031 - val_loss: 0.2563 - val_accuracy: 0.9170\n",
      "Epoch 29/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2991 - accuracy: 0.9056 - val_loss: 0.2556 - val_accuracy: 0.9240\n",
      "Epoch 30/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2947 - accuracy: 0.9056 - val_loss: 0.2604 - val_accuracy: 0.9234\n",
      "Epoch 31/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2867 - accuracy: 0.9088 - val_loss: 0.2137 - val_accuracy: 0.9309\n",
      "Epoch 32/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.2859 - accuracy: 0.9105 - val_loss: 0.2232 - val_accuracy: 0.9275\n",
      "Epoch 33/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2797 - accuracy: 0.9118 - val_loss: 0.2431 - val_accuracy: 0.9211\n",
      "Epoch 34/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2742 - accuracy: 0.9134 - val_loss: 0.2300 - val_accuracy: 0.9293\n",
      "Epoch 35/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2747 - accuracy: 0.9119 - val_loss: 0.2218 - val_accuracy: 0.9316\n",
      "Epoch 36/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2721 - accuracy: 0.9133 - val_loss: 0.2252 - val_accuracy: 0.9256\n",
      "Epoch 37/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2689 - accuracy: 0.9141 - val_loss: 0.2277 - val_accuracy: 0.9263\n",
      "Epoch 38/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2642 - accuracy: 0.9166 - val_loss: 0.2015 - val_accuracy: 0.9332\n",
      "Epoch 39/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2576 - accuracy: 0.9169 - val_loss: 0.2193 - val_accuracy: 0.9302\n",
      "Epoch 40/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2528 - accuracy: 0.9170 - val_loss: 0.2395 - val_accuracy: 0.9318\n",
      "Epoch 41/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2551 - accuracy: 0.9183 - val_loss: 0.2318 - val_accuracy: 0.9286\n",
      "Epoch 42/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2497 - accuracy: 0.9196 - val_loss: 0.2199 - val_accuracy: 0.9318\n",
      "Epoch 43/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2504 - accuracy: 0.9197 - val_loss: 0.2237 - val_accuracy: 0.9270\n",
      "Epoch 44/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2457 - accuracy: 0.9215 - val_loss: 0.2053 - val_accuracy: 0.9323\n",
      "Epoch 45/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2451 - accuracy: 0.9224 - val_loss: 0.2212 - val_accuracy: 0.9321\n",
      "Epoch 46/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2368 - accuracy: 0.9240 - val_loss: 0.2218 - val_accuracy: 0.9302\n",
      "Epoch 47/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2369 - accuracy: 0.9240 - val_loss: 0.1976 - val_accuracy: 0.9353\n",
      "Epoch 48/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2317 - accuracy: 0.9241 - val_loss: 0.2154 - val_accuracy: 0.9332\n",
      "Epoch 49/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2323 - accuracy: 0.9239 - val_loss: 0.2145 - val_accuracy: 0.9339\n",
      "Epoch 50/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2288 - accuracy: 0.9259 - val_loss: 0.2057 - val_accuracy: 0.9343\n",
      "Epoch 51/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2304 - accuracy: 0.9241 - val_loss: 0.2240 - val_accuracy: 0.9323\n",
      "Epoch 52/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2262 - accuracy: 0.9258 - val_loss: 0.2157 - val_accuracy: 0.9323\n",
      "Epoch 53/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2229 - accuracy: 0.9267 - val_loss: 0.2100 - val_accuracy: 0.9396\n",
      "Epoch 54/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2220 - accuracy: 0.9263 - val_loss: 0.2076 - val_accuracy: 0.9364\n",
      "Epoch 55/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2211 - accuracy: 0.9272 - val_loss: 0.2178 - val_accuracy: 0.9350\n",
      "Epoch 56/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2173 - accuracy: 0.9286 - val_loss: 0.1953 - val_accuracy: 0.9357\n",
      "Epoch 57/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2109 - accuracy: 0.9304 - val_loss: 0.2100 - val_accuracy: 0.9330\n",
      "Epoch 58/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2184 - accuracy: 0.9284 - val_loss: 0.2195 - val_accuracy: 0.9325\n",
      "Epoch 59/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2187 - accuracy: 0.9289 - val_loss: 0.2001 - val_accuracy: 0.9378\n",
      "Epoch 60/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2137 - accuracy: 0.9317 - val_loss: 0.2074 - val_accuracy: 0.9357\n",
      "Epoch 61/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.2092 - accuracy: 0.9311 - val_loss: 0.2201 - val_accuracy: 0.9339\n",
      "Epoch 62/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2114 - accuracy: 0.9313 - val_loss: 0.1993 - val_accuracy: 0.9385\n",
      "Epoch 63/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2016 - accuracy: 0.9336 - val_loss: 0.1970 - val_accuracy: 0.9371\n",
      "Epoch 64/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2093 - accuracy: 0.9314 - val_loss: 0.2061 - val_accuracy: 0.9357\n",
      "Epoch 65/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2041 - accuracy: 0.9336 - val_loss: 0.2165 - val_accuracy: 0.9339\n",
      "Epoch 66/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2028 - accuracy: 0.9341 - val_loss: 0.2150 - val_accuracy: 0.9341\n",
      "Epoch 67/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1977 - accuracy: 0.9370 - val_loss: 0.2218 - val_accuracy: 0.9348\n",
      "Epoch 68/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1964 - accuracy: 0.9353 - val_loss: 0.2096 - val_accuracy: 0.9353\n",
      "Epoch 69/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1932 - accuracy: 0.9358 - val_loss: 0.2134 - val_accuracy: 0.9359\n",
      "Epoch 70/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1929 - accuracy: 0.9377 - val_loss: 0.2153 - val_accuracy: 0.9330\n",
      "Epoch 71/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1946 - accuracy: 0.9369 - val_loss: 0.1984 - val_accuracy: 0.9391\n",
      "Epoch 72/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1905 - accuracy: 0.9382 - val_loss: 0.2187 - val_accuracy: 0.9318\n",
      "Epoch 73/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1903 - accuracy: 0.9382 - val_loss: 0.2097 - val_accuracy: 0.9364\n",
      "Epoch 74/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1871 - accuracy: 0.9394 - val_loss: 0.2227 - val_accuracy: 0.9318\n",
      "Epoch 75/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1915 - accuracy: 0.9362 - val_loss: 0.2009 - val_accuracy: 0.9398\n",
      "Epoch 76/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1824 - accuracy: 0.9394 - val_loss: 0.2161 - val_accuracy: 0.9357\n",
      "Epoch 77/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1871 - accuracy: 0.9370 - val_loss: 0.2017 - val_accuracy: 0.9380\n",
      "Epoch 78/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1879 - accuracy: 0.9380 - val_loss: 0.2110 - val_accuracy: 0.9391\n",
      "Epoch 79/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1792 - accuracy: 0.9409 - val_loss: 0.2308 - val_accuracy: 0.9323\n",
      "Epoch 80/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1810 - accuracy: 0.9398 - val_loss: 0.2078 - val_accuracy: 0.9369\n",
      "Epoch 81/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1794 - accuracy: 0.9406 - val_loss: 0.2029 - val_accuracy: 0.9359\n",
      "Epoch 82/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1741 - accuracy: 0.9416 - val_loss: 0.2038 - val_accuracy: 0.9371\n",
      "Epoch 83/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1794 - accuracy: 0.9409 - val_loss: 0.1894 - val_accuracy: 0.9405\n",
      "Epoch 84/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1795 - accuracy: 0.9399 - val_loss: 0.2061 - val_accuracy: 0.9394\n",
      "Epoch 85/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.1750 - accuracy: 0.9428 - val_loss: 0.2017 - val_accuracy: 0.9419\n",
      "Epoch 86/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1775 - accuracy: 0.9415 - val_loss: 0.2046 - val_accuracy: 0.9382\n",
      "Epoch 87/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.1731 - accuracy: 0.9421 - val_loss: 0.2087 - val_accuracy: 0.9387\n",
      "Epoch 88/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1711 - accuracy: 0.9429 - val_loss: 0.2061 - val_accuracy: 0.9364\n",
      "Epoch 89/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1708 - accuracy: 0.9435 - val_loss: 0.2160 - val_accuracy: 0.9332\n",
      "Epoch 90/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1745 - accuracy: 0.9426 - val_loss: 0.1911 - val_accuracy: 0.9419\n",
      "Epoch 91/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1659 - accuracy: 0.9453 - val_loss: 0.2195 - val_accuracy: 0.9380\n",
      "Epoch 92/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1692 - accuracy: 0.9430 - val_loss: 0.2048 - val_accuracy: 0.9387\n",
      "Epoch 93/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1728 - accuracy: 0.9422 - val_loss: 0.2003 - val_accuracy: 0.9394\n",
      "Epoch 94/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1678 - accuracy: 0.9453 - val_loss: 0.1972 - val_accuracy: 0.9419\n",
      "Epoch 95/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1691 - accuracy: 0.9447 - val_loss: 0.2053 - val_accuracy: 0.9371\n",
      "Epoch 96/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1674 - accuracy: 0.9433 - val_loss: 0.1930 - val_accuracy: 0.9423\n",
      "Epoch 97/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1642 - accuracy: 0.9441 - val_loss: 0.2032 - val_accuracy: 0.9362\n",
      "Epoch 98/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1656 - accuracy: 0.9450 - val_loss: 0.2004 - val_accuracy: 0.9389\n",
      "Epoch 99/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1668 - accuracy: 0.9450 - val_loss: 0.1969 - val_accuracy: 0.9403\n",
      "Epoch 100/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1603 - accuracy: 0.9459 - val_loss: 0.2200 - val_accuracy: 0.9364\n",
      "Epoch 101/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1617 - accuracy: 0.9454 - val_loss: 0.1983 - val_accuracy: 0.9394\n",
      "Epoch 102/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1552 - accuracy: 0.9474 - val_loss: 0.2085 - val_accuracy: 0.9391\n",
      "Epoch 103/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1629 - accuracy: 0.9460 - val_loss: 0.2012 - val_accuracy: 0.9414\n",
      "Epoch 104/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1597 - accuracy: 0.9476 - val_loss: 0.2017 - val_accuracy: 0.9403\n",
      "Epoch 105/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1558 - accuracy: 0.9488 - val_loss: 0.1952 - val_accuracy: 0.9426\n",
      "Epoch 106/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1566 - accuracy: 0.9475 - val_loss: 0.1874 - val_accuracy: 0.9423\n",
      "Epoch 107/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1533 - accuracy: 0.9490 - val_loss: 0.2007 - val_accuracy: 0.9382\n",
      "Epoch 108/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1548 - accuracy: 0.9486 - val_loss: 0.2071 - val_accuracy: 0.9396\n",
      "Epoch 109/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1505 - accuracy: 0.9494 - val_loss: 0.2076 - val_accuracy: 0.9414\n",
      "Epoch 110/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1565 - accuracy: 0.9469 - val_loss: 0.1937 - val_accuracy: 0.9417\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1547 - accuracy: 0.9482 - val_loss: 0.1967 - val_accuracy: 0.9414\n",
      "Epoch 112/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1484 - accuracy: 0.9502 - val_loss: 0.1965 - val_accuracy: 0.9398\n",
      "Epoch 113/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.1462 - accuracy: 0.9507 - val_loss: 0.1990 - val_accuracy: 0.9412\n",
      "Epoch 114/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1497 - accuracy: 0.9504 - val_loss: 0.1968 - val_accuracy: 0.9403\n",
      "Epoch 115/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1468 - accuracy: 0.9509 - val_loss: 0.2048 - val_accuracy: 0.9369\n",
      "Epoch 116/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1493 - accuracy: 0.9495 - val_loss: 0.1969 - val_accuracy: 0.9414\n",
      "Epoch 117/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1476 - accuracy: 0.9496 - val_loss: 0.1966 - val_accuracy: 0.9387\n",
      "Epoch 118/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1497 - accuracy: 0.9495 - val_loss: 0.1980 - val_accuracy: 0.9394\n",
      "Epoch 119/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1423 - accuracy: 0.9515 - val_loss: 0.1978 - val_accuracy: 0.9419\n",
      "Epoch 120/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1460 - accuracy: 0.9520 - val_loss: 0.1874 - val_accuracy: 0.9412\n",
      "Epoch 121/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1469 - accuracy: 0.9506 - val_loss: 0.2042 - val_accuracy: 0.9396\n",
      "Epoch 122/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1461 - accuracy: 0.9510 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
      "Epoch 123/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1474 - accuracy: 0.9492 - val_loss: 0.1976 - val_accuracy: 0.9405\n",
      "Epoch 124/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1457 - accuracy: 0.9514 - val_loss: 0.1914 - val_accuracy: 0.9435\n",
      "Epoch 125/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1401 - accuracy: 0.9528 - val_loss: 0.2032 - val_accuracy: 0.9378\n",
      "Epoch 126/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1420 - accuracy: 0.9521 - val_loss: 0.1949 - val_accuracy: 0.9423\n",
      "Epoch 127/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1436 - accuracy: 0.9515 - val_loss: 0.1968 - val_accuracy: 0.9412\n",
      "Epoch 128/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1416 - accuracy: 0.9531 - val_loss: 0.1899 - val_accuracy: 0.9446\n",
      "Epoch 129/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1415 - accuracy: 0.9503 - val_loss: 0.1853 - val_accuracy: 0.9421\n",
      "Epoch 130/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1402 - accuracy: 0.9524 - val_loss: 0.2090 - val_accuracy: 0.9401\n",
      "Epoch 131/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1359 - accuracy: 0.9543 - val_loss: 0.2029 - val_accuracy: 0.9401\n",
      "Epoch 132/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1384 - accuracy: 0.9537 - val_loss: 0.2023 - val_accuracy: 0.9405\n",
      "Epoch 133/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1400 - accuracy: 0.9535 - val_loss: 0.2068 - val_accuracy: 0.9357\n",
      "Epoch 134/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1357 - accuracy: 0.9547 - val_loss: 0.2021 - val_accuracy: 0.9419\n",
      "Epoch 135/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1357 - accuracy: 0.9535 - val_loss: 0.2166 - val_accuracy: 0.9389\n",
      "Epoch 136/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1371 - accuracy: 0.9541 - val_loss: 0.1981 - val_accuracy: 0.9417\n",
      "Epoch 137/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1387 - accuracy: 0.9532 - val_loss: 0.2053 - val_accuracy: 0.9414\n",
      "Epoch 138/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1320 - accuracy: 0.9542 - val_loss: 0.2112 - val_accuracy: 0.9389\n",
      "Epoch 139/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1311 - accuracy: 0.9550 - val_loss: 0.1884 - val_accuracy: 0.9467\n",
      "Epoch 140/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1365 - accuracy: 0.9529 - val_loss: 0.1997 - val_accuracy: 0.9417\n",
      "Epoch 141/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1381 - accuracy: 0.9534 - val_loss: 0.1953 - val_accuracy: 0.9410\n",
      "Epoch 142/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1350 - accuracy: 0.9553 - val_loss: 0.1992 - val_accuracy: 0.9419\n",
      "Epoch 143/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1287 - accuracy: 0.9557 - val_loss: 0.2075 - val_accuracy: 0.9401\n",
      "Epoch 144/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1351 - accuracy: 0.9543 - val_loss: 0.2142 - val_accuracy: 0.9375\n",
      "Epoch 145/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1296 - accuracy: 0.9559 - val_loss: 0.2125 - val_accuracy: 0.9391\n",
      "Epoch 146/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1343 - accuracy: 0.9551 - val_loss: 0.2044 - val_accuracy: 0.9428\n",
      "Epoch 147/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1281 - accuracy: 0.9563 - val_loss: 0.2035 - val_accuracy: 0.9426\n",
      "Epoch 148/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1277 - accuracy: 0.9567 - val_loss: 0.1959 - val_accuracy: 0.9403\n",
      "Epoch 149/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1310 - accuracy: 0.9555 - val_loss: 0.2103 - val_accuracy: 0.9391\n",
      "Epoch 150/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1321 - accuracy: 0.9548 - val_loss: 0.2136 - val_accuracy: 0.9375\n",
      "Epoch 151/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1257 - accuracy: 0.9577 - val_loss: 0.1993 - val_accuracy: 0.9437\n",
      "Epoch 152/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1287 - accuracy: 0.9560 - val_loss: 0.1966 - val_accuracy: 0.9405\n",
      "Epoch 153/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1246 - accuracy: 0.9577 - val_loss: 0.1970 - val_accuracy: 0.9437\n",
      "Epoch 154/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1237 - accuracy: 0.9582 - val_loss: 0.2011 - val_accuracy: 0.9433\n",
      "Epoch 155/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1280 - accuracy: 0.9566 - val_loss: 0.1931 - val_accuracy: 0.9435\n",
      "Epoch 156/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1285 - accuracy: 0.9574 - val_loss: 0.2064 - val_accuracy: 0.9412\n",
      "Epoch 157/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.1230 - accuracy: 0.9581 - val_loss: 0.2079 - val_accuracy: 0.9421\n",
      "Epoch 158/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1286 - accuracy: 0.9564 - val_loss: 0.2083 - val_accuracy: 0.9435\n",
      "Epoch 159/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1270 - accuracy: 0.9565 - val_loss: 0.2056 - val_accuracy: 0.9428\n",
      "Epoch 160/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1243 - accuracy: 0.9593 - val_loss: 0.2110 - val_accuracy: 0.9391\n",
      "Epoch 161/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1244 - accuracy: 0.9576 - val_loss: 0.2049 - val_accuracy: 0.9380\n",
      "Epoch 162/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1180 - accuracy: 0.9596 - val_loss: 0.1976 - val_accuracy: 0.9435\n",
      "Epoch 163/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1298 - accuracy: 0.9569 - val_loss: 0.2027 - val_accuracy: 0.9430\n",
      "Epoch 164/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1236 - accuracy: 0.9586 - val_loss: 0.2079 - val_accuracy: 0.9410\n",
      "Epoch 165/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1202 - accuracy: 0.9582 - val_loss: 0.2184 - val_accuracy: 0.9387\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1230 - accuracy: 0.9583 - val_loss: 0.2121 - val_accuracy: 0.9407\n",
      "Epoch 167/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1205 - accuracy: 0.9594 - val_loss: 0.2089 - val_accuracy: 0.9419\n",
      "Epoch 168/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1223 - accuracy: 0.9589 - val_loss: 0.1977 - val_accuracy: 0.9435\n",
      "Epoch 169/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1174 - accuracy: 0.9605 - val_loss: 0.2061 - val_accuracy: 0.9437\n",
      "Epoch 170/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1214 - accuracy: 0.9585 - val_loss: 0.2035 - val_accuracy: 0.9391\n",
      "Epoch 171/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1181 - accuracy: 0.9594 - val_loss: 0.2105 - val_accuracy: 0.9419\n",
      "Epoch 172/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1198 - accuracy: 0.9594 - val_loss: 0.2149 - val_accuracy: 0.9371\n",
      "Epoch 173/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1209 - accuracy: 0.9588 - val_loss: 0.2036 - val_accuracy: 0.9410\n",
      "Epoch 174/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1165 - accuracy: 0.9606 - val_loss: 0.2023 - val_accuracy: 0.9391\n",
      "Epoch 175/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1190 - accuracy: 0.9603 - val_loss: 0.2068 - val_accuracy: 0.9405\n",
      "Epoch 176/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1149 - accuracy: 0.9610 - val_loss: 0.2055 - val_accuracy: 0.9410\n",
      "Epoch 177/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1187 - accuracy: 0.9600 - val_loss: 0.2048 - val_accuracy: 0.9426\n",
      "Epoch 178/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1176 - accuracy: 0.9607 - val_loss: 0.2016 - val_accuracy: 0.9426\n",
      "Epoch 179/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1168 - accuracy: 0.9608 - val_loss: 0.2058 - val_accuracy: 0.9412\n",
      "Epoch 180/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1094 - accuracy: 0.9636 - val_loss: 0.2027 - val_accuracy: 0.9426\n",
      "Epoch 181/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1165 - accuracy: 0.9601 - val_loss: 0.2150 - val_accuracy: 0.9398\n",
      "Epoch 182/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1139 - accuracy: 0.9615 - val_loss: 0.2016 - val_accuracy: 0.9437\n",
      "Epoch 183/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1135 - accuracy: 0.9606 - val_loss: 0.2072 - val_accuracy: 0.9446\n",
      "Epoch 184/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1131 - accuracy: 0.9613 - val_loss: 0.2105 - val_accuracy: 0.9426\n",
      "Epoch 185/500\n",
      "1093/1093 [==============================] - 13s 12ms/step - loss: 0.1157 - accuracy: 0.9614 - val_loss: 0.1985 - val_accuracy: 0.9430\n",
      "Epoch 186/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1116 - accuracy: 0.9623 - val_loss: 0.1964 - val_accuracy: 0.9453\n",
      "Epoch 187/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1134 - accuracy: 0.9617 - val_loss: 0.1970 - val_accuracy: 0.9442\n",
      "Epoch 188/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1157 - accuracy: 0.9600 - val_loss: 0.2110 - val_accuracy: 0.9428\n",
      "Epoch 189/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1163 - accuracy: 0.9601 - val_loss: 0.2014 - val_accuracy: 0.9433\n",
      "Epoch 190/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1128 - accuracy: 0.9606 - val_loss: 0.2057 - val_accuracy: 0.9433\n",
      "Epoch 191/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1122 - accuracy: 0.9621 - val_loss: 0.1983 - val_accuracy: 0.9472\n",
      "Epoch 192/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1110 - accuracy: 0.9625 - val_loss: 0.2012 - val_accuracy: 0.9428\n",
      "Epoch 193/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1071 - accuracy: 0.9649 - val_loss: 0.2234 - val_accuracy: 0.9417\n",
      "Epoch 194/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1104 - accuracy: 0.9631 - val_loss: 0.2093 - val_accuracy: 0.9428\n",
      "Epoch 195/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1118 - accuracy: 0.9618 - val_loss: 0.2057 - val_accuracy: 0.9423\n",
      "Epoch 196/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1066 - accuracy: 0.9641 - val_loss: 0.2194 - val_accuracy: 0.9419\n",
      "Epoch 197/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1079 - accuracy: 0.9632 - val_loss: 0.2045 - val_accuracy: 0.9430\n",
      "Epoch 198/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1078 - accuracy: 0.9637 - val_loss: 0.2149 - val_accuracy: 0.9451\n",
      "Epoch 199/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1107 - accuracy: 0.9612 - val_loss: 0.2127 - val_accuracy: 0.9419\n",
      "Epoch 200/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1105 - accuracy: 0.9623 - val_loss: 0.2096 - val_accuracy: 0.9453\n",
      "Epoch 201/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1072 - accuracy: 0.9644 - val_loss: 0.2132 - val_accuracy: 0.9442\n",
      "Epoch 202/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1057 - accuracy: 0.9628 - val_loss: 0.2155 - val_accuracy: 0.9437\n",
      "Epoch 203/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1090 - accuracy: 0.9633 - val_loss: 0.2127 - val_accuracy: 0.9421\n",
      "Epoch 204/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1047 - accuracy: 0.9638 - val_loss: 0.2244 - val_accuracy: 0.9403\n",
      "Epoch 205/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1061 - accuracy: 0.9631 - val_loss: 0.2227 - val_accuracy: 0.9394\n",
      "Epoch 206/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1070 - accuracy: 0.9635 - val_loss: 0.2078 - val_accuracy: 0.9453\n",
      "Epoch 207/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1104 - accuracy: 0.9629 - val_loss: 0.2032 - val_accuracy: 0.9430\n",
      "Epoch 208/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1020 - accuracy: 0.9648 - val_loss: 0.2032 - val_accuracy: 0.9449\n",
      "Epoch 209/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1047 - accuracy: 0.9642 - val_loss: 0.2129 - val_accuracy: 0.9426\n",
      "Epoch 210/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1084 - accuracy: 0.9640 - val_loss: 0.2120 - val_accuracy: 0.9442\n",
      "Epoch 211/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1055 - accuracy: 0.9639 - val_loss: 0.2192 - val_accuracy: 0.9398\n",
      "Epoch 212/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1052 - accuracy: 0.9639 - val_loss: 0.1991 - val_accuracy: 0.9428\n",
      "Epoch 213/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1066 - accuracy: 0.9633 - val_loss: 0.2127 - val_accuracy: 0.9419\n",
      "Epoch 214/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1016 - accuracy: 0.9644 - val_loss: 0.2106 - val_accuracy: 0.9444\n",
      "Epoch 215/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1013 - accuracy: 0.9656 - val_loss: 0.2157 - val_accuracy: 0.9396\n",
      "Epoch 216/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1085 - accuracy: 0.9634 - val_loss: 0.2170 - val_accuracy: 0.9423\n",
      "Epoch 217/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1013 - accuracy: 0.9653 - val_loss: 0.2171 - val_accuracy: 0.9423\n",
      "Epoch 218/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1006 - accuracy: 0.9667 - val_loss: 0.2250 - val_accuracy: 0.9412\n",
      "Epoch 219/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1033 - accuracy: 0.9650 - val_loss: 0.2139 - val_accuracy: 0.9439\n",
      "Epoch 220/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1032 - accuracy: 0.9656 - val_loss: 0.2087 - val_accuracy: 0.9419\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1048 - accuracy: 0.9653 - val_loss: 0.2098 - val_accuracy: 0.9421\n",
      "Epoch 222/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1039 - accuracy: 0.9652 - val_loss: 0.2100 - val_accuracy: 0.9435\n",
      "Epoch 223/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1059 - accuracy: 0.9647 - val_loss: 0.2133 - val_accuracy: 0.9417\n",
      "Epoch 224/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1037 - accuracy: 0.9665 - val_loss: 0.2079 - val_accuracy: 0.9435\n",
      "Epoch 225/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1025 - accuracy: 0.9658 - val_loss: 0.2145 - val_accuracy: 0.9419\n",
      "Epoch 226/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1013 - accuracy: 0.9656 - val_loss: 0.2114 - val_accuracy: 0.9451\n",
      "Epoch 227/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1008 - accuracy: 0.9672 - val_loss: 0.2104 - val_accuracy: 0.9453\n",
      "Epoch 228/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0991 - accuracy: 0.9668 - val_loss: 0.2230 - val_accuracy: 0.9419\n",
      "Epoch 229/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1030 - accuracy: 0.9650 - val_loss: 0.2128 - val_accuracy: 0.9419\n",
      "Epoch 230/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0984 - accuracy: 0.9665 - val_loss: 0.2204 - val_accuracy: 0.9433\n",
      "Epoch 231/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1000 - accuracy: 0.9665 - val_loss: 0.2159 - val_accuracy: 0.9426\n",
      "Epoch 232/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0995 - accuracy: 0.9678 - val_loss: 0.2044 - val_accuracy: 0.9449\n",
      "Epoch 233/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.1031 - accuracy: 0.9651 - val_loss: 0.2114 - val_accuracy: 0.9437\n",
      "Epoch 234/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1000 - accuracy: 0.9662 - val_loss: 0.2128 - val_accuracy: 0.9446\n",
      "Epoch 235/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0958 - accuracy: 0.9679 - val_loss: 0.2160 - val_accuracy: 0.9456\n",
      "Epoch 236/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1003 - accuracy: 0.9653 - val_loss: 0.2036 - val_accuracy: 0.9442\n",
      "Epoch 237/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0985 - accuracy: 0.9659 - val_loss: 0.2190 - val_accuracy: 0.9435\n",
      "Epoch 238/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0941 - accuracy: 0.9680 - val_loss: 0.2323 - val_accuracy: 0.9359\n",
      "Epoch 239/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.2240 - val_accuracy: 0.9403\n",
      "Epoch 240/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1004 - accuracy: 0.9657 - val_loss: 0.2138 - val_accuracy: 0.9428\n",
      "Epoch 241/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0961 - accuracy: 0.9685 - val_loss: 0.2208 - val_accuracy: 0.9430\n",
      "Epoch 242/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0982 - accuracy: 0.9671 - val_loss: 0.2094 - val_accuracy: 0.9417\n",
      "Epoch 243/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0923 - accuracy: 0.9687 - val_loss: 0.2111 - val_accuracy: 0.9433\n",
      "Epoch 244/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0993 - accuracy: 0.9647 - val_loss: 0.2120 - val_accuracy: 0.9428\n",
      "Epoch 245/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0978 - accuracy: 0.9678 - val_loss: 0.2243 - val_accuracy: 0.9391\n",
      "Epoch 246/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0964 - accuracy: 0.9678 - val_loss: 0.2204 - val_accuracy: 0.9394\n",
      "Epoch 247/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0947 - accuracy: 0.9678 - val_loss: 0.2188 - val_accuracy: 0.9433\n",
      "Epoch 248/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0984 - accuracy: 0.9655 - val_loss: 0.2110 - val_accuracy: 0.9435\n",
      "Epoch 249/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0979 - accuracy: 0.9677 - val_loss: 0.2106 - val_accuracy: 0.9421\n",
      "Epoch 250/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0973 - accuracy: 0.9677 - val_loss: 0.2166 - val_accuracy: 0.9403\n",
      "Epoch 251/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0964 - accuracy: 0.9679 - val_loss: 0.2255 - val_accuracy: 0.9403\n",
      "Epoch 252/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0958 - accuracy: 0.9674 - val_loss: 0.2116 - val_accuracy: 0.9442\n",
      "Epoch 253/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0972 - accuracy: 0.9667 - val_loss: 0.2290 - val_accuracy: 0.9417\n",
      "Epoch 254/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0929 - accuracy: 0.9685 - val_loss: 0.2056 - val_accuracy: 0.9465\n",
      "Epoch 255/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0948 - accuracy: 0.9679 - val_loss: 0.2095 - val_accuracy: 0.9437\n",
      "Epoch 256/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0930 - accuracy: 0.9697 - val_loss: 0.2014 - val_accuracy: 0.9467\n",
      "Epoch 257/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0920 - accuracy: 0.9696 - val_loss: 0.2191 - val_accuracy: 0.9426\n",
      "Epoch 258/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0940 - accuracy: 0.9673 - val_loss: 0.2046 - val_accuracy: 0.9467\n",
      "Epoch 259/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0907 - accuracy: 0.9689 - val_loss: 0.2176 - val_accuracy: 0.9414\n",
      "Epoch 260/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0927 - accuracy: 0.9681 - val_loss: 0.2264 - val_accuracy: 0.9396\n",
      "Epoch 261/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0899 - accuracy: 0.9701 - val_loss: 0.2166 - val_accuracy: 0.9458\n",
      "Epoch 262/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0933 - accuracy: 0.9692 - val_loss: 0.2117 - val_accuracy: 0.9444\n",
      "Epoch 263/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0904 - accuracy: 0.9690 - val_loss: 0.2090 - val_accuracy: 0.9465\n",
      "Epoch 264/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0926 - accuracy: 0.9689 - val_loss: 0.2010 - val_accuracy: 0.9449\n",
      "Epoch 265/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0942 - accuracy: 0.9676 - val_loss: 0.2108 - val_accuracy: 0.9433\n",
      "Epoch 266/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0921 - accuracy: 0.9688 - val_loss: 0.2104 - val_accuracy: 0.9442\n",
      "Epoch 267/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0890 - accuracy: 0.9694 - val_loss: 0.2180 - val_accuracy: 0.9421\n",
      "Epoch 268/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0943 - accuracy: 0.9687 - val_loss: 0.2097 - val_accuracy: 0.9449\n",
      "Epoch 269/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0893 - accuracy: 0.9698 - val_loss: 0.2154 - val_accuracy: 0.9426\n",
      "Epoch 270/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0909 - accuracy: 0.9694 - val_loss: 0.2301 - val_accuracy: 0.9403\n",
      "Epoch 271/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0906 - accuracy: 0.9700 - val_loss: 0.2205 - val_accuracy: 0.9430\n",
      "Epoch 272/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0919 - accuracy: 0.9686 - val_loss: 0.1989 - val_accuracy: 0.9453\n",
      "Epoch 273/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0903 - accuracy: 0.9691 - val_loss: 0.2043 - val_accuracy: 0.9456\n",
      "Epoch 274/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0908 - accuracy: 0.9690 - val_loss: 0.2281 - val_accuracy: 0.9401\n",
      "Epoch 275/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0875 - accuracy: 0.9711 - val_loss: 0.2250 - val_accuracy: 0.9423\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.0880 - accuracy: 0.9689 - val_loss: 0.2207 - val_accuracy: 0.9426\n",
      "Epoch 277/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0884 - accuracy: 0.9697 - val_loss: 0.2174 - val_accuracy: 0.9453\n",
      "Epoch 278/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0880 - accuracy: 0.9698 - val_loss: 0.2111 - val_accuracy: 0.9412\n",
      "Epoch 279/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0904 - accuracy: 0.9705 - val_loss: 0.2142 - val_accuracy: 0.9449\n",
      "Epoch 280/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0891 - accuracy: 0.9696 - val_loss: 0.2099 - val_accuracy: 0.9451\n",
      "Epoch 281/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0901 - accuracy: 0.9696 - val_loss: 0.2121 - val_accuracy: 0.9421\n",
      "Epoch 282/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0883 - accuracy: 0.9699 - val_loss: 0.2164 - val_accuracy: 0.9419\n",
      "Epoch 283/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0902 - accuracy: 0.9695 - val_loss: 0.2197 - val_accuracy: 0.9405\n",
      "Epoch 284/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0909 - accuracy: 0.9696 - val_loss: 0.2233 - val_accuracy: 0.9437\n",
      "Epoch 285/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0919 - accuracy: 0.9687 - val_loss: 0.2326 - val_accuracy: 0.9433\n",
      "Epoch 286/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0881 - accuracy: 0.9700 - val_loss: 0.2220 - val_accuracy: 0.9407\n",
      "Epoch 287/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0843 - accuracy: 0.9715 - val_loss: 0.2199 - val_accuracy: 0.9419\n",
      "Epoch 288/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0891 - accuracy: 0.9689 - val_loss: 0.2252 - val_accuracy: 0.9414\n",
      "Epoch 289/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0874 - accuracy: 0.9691 - val_loss: 0.2195 - val_accuracy: 0.9417\n",
      "Epoch 290/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0833 - accuracy: 0.9721 - val_loss: 0.2239 - val_accuracy: 0.9410\n",
      "Epoch 291/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0848 - accuracy: 0.9712 - val_loss: 0.2251 - val_accuracy: 0.9446\n",
      "Epoch 292/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0850 - accuracy: 0.9709 - val_loss: 0.2145 - val_accuracy: 0.9462\n",
      "Epoch 293/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0847 - accuracy: 0.9715 - val_loss: 0.2200 - val_accuracy: 0.9407\n",
      "Epoch 294/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0863 - accuracy: 0.9705 - val_loss: 0.2229 - val_accuracy: 0.9423\n",
      "Epoch 295/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0861 - accuracy: 0.9711 - val_loss: 0.2155 - val_accuracy: 0.9439\n",
      "Epoch 296/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0861 - accuracy: 0.9715 - val_loss: 0.2104 - val_accuracy: 0.9437\n",
      "Epoch 297/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0862 - accuracy: 0.9709 - val_loss: 0.2085 - val_accuracy: 0.9430\n",
      "Epoch 298/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0840 - accuracy: 0.9715 - val_loss: 0.2082 - val_accuracy: 0.9467\n",
      "Epoch 299/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0813 - accuracy: 0.9733 - val_loss: 0.2142 - val_accuracy: 0.9437\n",
      "Epoch 300/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0837 - accuracy: 0.9722 - val_loss: 0.2151 - val_accuracy: 0.9465\n",
      "Epoch 301/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0836 - accuracy: 0.9717 - val_loss: 0.2102 - val_accuracy: 0.9430\n",
      "Epoch 302/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0881 - accuracy: 0.9712 - val_loss: 0.2091 - val_accuracy: 0.9430\n",
      "Epoch 303/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0862 - accuracy: 0.9705 - val_loss: 0.2043 - val_accuracy: 0.9419\n",
      "Epoch 304/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0841 - accuracy: 0.9716 - val_loss: 0.2052 - val_accuracy: 0.9439\n",
      "Epoch 305/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0876 - accuracy: 0.9698 - val_loss: 0.2169 - val_accuracy: 0.9423\n",
      "Epoch 306/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0819 - accuracy: 0.9721 - val_loss: 0.2220 - val_accuracy: 0.9442\n",
      "Epoch 307/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0810 - accuracy: 0.9734 - val_loss: 0.2121 - val_accuracy: 0.9439\n",
      "Epoch 308/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0868 - accuracy: 0.9702 - val_loss: 0.2127 - val_accuracy: 0.9451\n",
      "Epoch 309/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0817 - accuracy: 0.9720 - val_loss: 0.2346 - val_accuracy: 0.9391\n",
      "Epoch 310/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0821 - accuracy: 0.9723 - val_loss: 0.2238 - val_accuracy: 0.9407\n",
      "Epoch 311/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0841 - accuracy: 0.9716 - val_loss: 0.2262 - val_accuracy: 0.9423\n",
      "Epoch 312/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0801 - accuracy: 0.9731 - val_loss: 0.2353 - val_accuracy: 0.9389\n",
      "Epoch 313/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0837 - accuracy: 0.9715 - val_loss: 0.2282 - val_accuracy: 0.9419\n",
      "Epoch 314/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0815 - accuracy: 0.9728 - val_loss: 0.2250 - val_accuracy: 0.9442\n",
      "Epoch 315/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0818 - accuracy: 0.9722 - val_loss: 0.2347 - val_accuracy: 0.9407\n",
      "Epoch 316/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0830 - accuracy: 0.9719 - val_loss: 0.2210 - val_accuracy: 0.9426\n",
      "Epoch 317/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0797 - accuracy: 0.9727 - val_loss: 0.2267 - val_accuracy: 0.9421\n",
      "Epoch 318/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0863 - accuracy: 0.9710 - val_loss: 0.2134 - val_accuracy: 0.9419\n",
      "Epoch 319/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0779 - accuracy: 0.9736 - val_loss: 0.2303 - val_accuracy: 0.9403\n",
      "Epoch 320/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0786 - accuracy: 0.9731 - val_loss: 0.2248 - val_accuracy: 0.9428\n",
      "Epoch 321/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0817 - accuracy: 0.9727 - val_loss: 0.2161 - val_accuracy: 0.9453\n",
      "Epoch 322/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0798 - accuracy: 0.9731 - val_loss: 0.2259 - val_accuracy: 0.9405\n",
      "Epoch 323/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0863 - accuracy: 0.9711 - val_loss: 0.2254 - val_accuracy: 0.9428\n",
      "Epoch 324/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.0783 - accuracy: 0.9730 - val_loss: 0.2248 - val_accuracy: 0.9426\n",
      "Epoch 325/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0789 - accuracy: 0.9739 - val_loss: 0.2319 - val_accuracy: 0.9391\n",
      "Epoch 326/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0837 - accuracy: 0.9719 - val_loss: 0.2263 - val_accuracy: 0.9435\n",
      "Epoch 327/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0832 - accuracy: 0.9717 - val_loss: 0.2192 - val_accuracy: 0.9412\n",
      "Epoch 328/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0806 - accuracy: 0.9720 - val_loss: 0.2307 - val_accuracy: 0.9423\n",
      "Epoch 329/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0816 - accuracy: 0.9716 - val_loss: 0.2210 - val_accuracy: 0.9417\n",
      "Epoch 330/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0791 - accuracy: 0.9739 - val_loss: 0.2207 - val_accuracy: 0.9423\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0798 - accuracy: 0.9739 - val_loss: 0.2257 - val_accuracy: 0.9437\n",
      "Epoch 332/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.0827 - accuracy: 0.9718 - val_loss: 0.2156 - val_accuracy: 0.9444\n",
      "Epoch 333/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0797 - accuracy: 0.9735 - val_loss: 0.2238 - val_accuracy: 0.9435\n",
      "Epoch 334/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0797 - accuracy: 0.9734 - val_loss: 0.2275 - val_accuracy: 0.9417\n",
      "Epoch 335/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0791 - accuracy: 0.9725 - val_loss: 0.2289 - val_accuracy: 0.9403\n",
      "Epoch 336/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0767 - accuracy: 0.9748 - val_loss: 0.2242 - val_accuracy: 0.9433\n",
      "Epoch 337/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0778 - accuracy: 0.9743 - val_loss: 0.2299 - val_accuracy: 0.9385\n",
      "Epoch 338/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0832 - accuracy: 0.9725 - val_loss: 0.2323 - val_accuracy: 0.9398\n",
      "Epoch 339/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0787 - accuracy: 0.9734 - val_loss: 0.2262 - val_accuracy: 0.9439\n",
      "Epoch 340/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0810 - accuracy: 0.9728 - val_loss: 0.2157 - val_accuracy: 0.9453\n",
      "Epoch 341/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0782 - accuracy: 0.9734 - val_loss: 0.2202 - val_accuracy: 0.9451\n",
      "Epoch 342/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0789 - accuracy: 0.9745 - val_loss: 0.2162 - val_accuracy: 0.9465\n",
      "Epoch 343/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0782 - accuracy: 0.9751 - val_loss: 0.2304 - val_accuracy: 0.9437\n",
      "Epoch 344/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0808 - accuracy: 0.9724 - val_loss: 0.2232 - val_accuracy: 0.9435\n",
      "Epoch 345/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0800 - accuracy: 0.9723 - val_loss: 0.2276 - val_accuracy: 0.9435\n",
      "Epoch 346/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0795 - accuracy: 0.9747 - val_loss: 0.2289 - val_accuracy: 0.9428\n",
      "Epoch 347/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0763 - accuracy: 0.9742 - val_loss: 0.2164 - val_accuracy: 0.9437\n",
      "Epoch 348/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0790 - accuracy: 0.9744 - val_loss: 0.2203 - val_accuracy: 0.9442\n",
      "Epoch 349/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0784 - accuracy: 0.9725 - val_loss: 0.2275 - val_accuracy: 0.9430\n",
      "Epoch 350/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0788 - accuracy: 0.9740 - val_loss: 0.2227 - val_accuracy: 0.9412\n",
      "Epoch 351/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0785 - accuracy: 0.9740 - val_loss: 0.2100 - val_accuracy: 0.9439\n",
      "Epoch 352/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0756 - accuracy: 0.9736 - val_loss: 0.2283 - val_accuracy: 0.9426\n",
      "Epoch 353/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0723 - accuracy: 0.9755 - val_loss: 0.2364 - val_accuracy: 0.9426\n",
      "Epoch 354/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0789 - accuracy: 0.9737 - val_loss: 0.2130 - val_accuracy: 0.9449\n",
      "Epoch 355/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0759 - accuracy: 0.9740 - val_loss: 0.2131 - val_accuracy: 0.9453\n",
      "Epoch 356/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0806 - accuracy: 0.9715 - val_loss: 0.2203 - val_accuracy: 0.9451\n",
      "Epoch 357/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0803 - accuracy: 0.9732 - val_loss: 0.2222 - val_accuracy: 0.9439\n",
      "Epoch 358/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0756 - accuracy: 0.9746 - val_loss: 0.2166 - val_accuracy: 0.9456\n",
      "Epoch 359/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0769 - accuracy: 0.9733 - val_loss: 0.2201 - val_accuracy: 0.9426\n",
      "Epoch 360/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0754 - accuracy: 0.9740 - val_loss: 0.2278 - val_accuracy: 0.9396\n",
      "Epoch 361/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.2326 - val_accuracy: 0.9428\n",
      "Epoch 362/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0773 - accuracy: 0.9746 - val_loss: 0.2230 - val_accuracy: 0.9469\n",
      "Epoch 363/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0744 - accuracy: 0.9754 - val_loss: 0.2393 - val_accuracy: 0.9437\n",
      "Epoch 364/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0753 - accuracy: 0.9749 - val_loss: 0.2236 - val_accuracy: 0.9428\n",
      "Epoch 365/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0767 - accuracy: 0.9740 - val_loss: 0.2468 - val_accuracy: 0.9437\n",
      "Epoch 366/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0771 - accuracy: 0.9731 - val_loss: 0.2342 - val_accuracy: 0.9433\n",
      "Epoch 367/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0748 - accuracy: 0.9744 - val_loss: 0.2337 - val_accuracy: 0.9412\n",
      "Epoch 368/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0761 - accuracy: 0.9746 - val_loss: 0.2225 - val_accuracy: 0.9472\n",
      "Epoch 369/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0731 - accuracy: 0.9752 - val_loss: 0.2126 - val_accuracy: 0.9456\n",
      "Epoch 370/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0722 - accuracy: 0.9752 - val_loss: 0.2152 - val_accuracy: 0.9472\n",
      "Epoch 371/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0803 - accuracy: 0.9729 - val_loss: 0.2289 - val_accuracy: 0.9419\n",
      "Epoch 372/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0727 - accuracy: 0.9762 - val_loss: 0.2239 - val_accuracy: 0.9462\n",
      "Epoch 373/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0751 - accuracy: 0.9744 - val_loss: 0.2327 - val_accuracy: 0.9433\n",
      "Epoch 374/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0745 - accuracy: 0.9750 - val_loss: 0.2182 - val_accuracy: 0.9446\n",
      "Epoch 375/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0736 - accuracy: 0.9750 - val_loss: 0.2334 - val_accuracy: 0.9430\n",
      "Epoch 376/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0719 - accuracy: 0.9754 - val_loss: 0.2357 - val_accuracy: 0.9437\n",
      "Epoch 377/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0705 - accuracy: 0.9756 - val_loss: 0.2333 - val_accuracy: 0.9430\n",
      "Epoch 378/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0773 - accuracy: 0.9738 - val_loss: 0.2335 - val_accuracy: 0.9439\n",
      "Epoch 379/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0711 - accuracy: 0.9758 - val_loss: 0.2230 - val_accuracy: 0.9474\n",
      "Epoch 380/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0764 - accuracy: 0.9748 - val_loss: 0.2182 - val_accuracy: 0.9433\n",
      "Epoch 381/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0724 - accuracy: 0.9752 - val_loss: 0.2278 - val_accuracy: 0.9444\n",
      "Epoch 382/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0728 - accuracy: 0.9754 - val_loss: 0.2232 - val_accuracy: 0.9467\n",
      "Epoch 383/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0728 - accuracy: 0.9758 - val_loss: 0.2305 - val_accuracy: 0.9403\n",
      "Epoch 384/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0719 - accuracy: 0.9753 - val_loss: 0.2352 - val_accuracy: 0.9435\n",
      "Epoch 385/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.2354 - val_accuracy: 0.9433\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0733 - accuracy: 0.9755 - val_loss: 0.2172 - val_accuracy: 0.9433\n",
      "Epoch 387/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0733 - accuracy: 0.9754 - val_loss: 0.2189 - val_accuracy: 0.9451\n",
      "Epoch 388/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0695 - accuracy: 0.9765 - val_loss: 0.2247 - val_accuracy: 0.9458\n",
      "Epoch 389/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0744 - accuracy: 0.9762 - val_loss: 0.2199 - val_accuracy: 0.9446\n",
      "Epoch 390/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0717 - accuracy: 0.9760 - val_loss: 0.2349 - val_accuracy: 0.9423\n",
      "Epoch 391/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0743 - accuracy: 0.9741 - val_loss: 0.2277 - val_accuracy: 0.9442\n",
      "Epoch 392/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0741 - accuracy: 0.9745 - val_loss: 0.2228 - val_accuracy: 0.9423\n",
      "Epoch 393/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0709 - accuracy: 0.9759 - val_loss: 0.2230 - val_accuracy: 0.9430\n",
      "Epoch 394/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0731 - accuracy: 0.9750 - val_loss: 0.2080 - val_accuracy: 0.9490\n",
      "Epoch 395/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0722 - accuracy: 0.9761 - val_loss: 0.2255 - val_accuracy: 0.9446\n",
      "Epoch 396/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0715 - accuracy: 0.9753 - val_loss: 0.2220 - val_accuracy: 0.9462\n",
      "Epoch 397/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0718 - accuracy: 0.9751 - val_loss: 0.2457 - val_accuracy: 0.9385\n",
      "Epoch 398/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0724 - accuracy: 0.9759 - val_loss: 0.2271 - val_accuracy: 0.9428\n",
      "Epoch 399/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0717 - accuracy: 0.9750 - val_loss: 0.2176 - val_accuracy: 0.9465\n",
      "Epoch 400/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0727 - accuracy: 0.9758 - val_loss: 0.2257 - val_accuracy: 0.9451\n",
      "Epoch 401/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0705 - accuracy: 0.9757 - val_loss: 0.2249 - val_accuracy: 0.9444\n",
      "Epoch 402/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0700 - accuracy: 0.9759 - val_loss: 0.2325 - val_accuracy: 0.9430\n",
      "Epoch 403/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0743 - accuracy: 0.9758 - val_loss: 0.2211 - val_accuracy: 0.9444\n",
      "Epoch 404/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0732 - accuracy: 0.9757 - val_loss: 0.2279 - val_accuracy: 0.9414\n",
      "Epoch 405/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0671 - accuracy: 0.9769 - val_loss: 0.2332 - val_accuracy: 0.9428\n",
      "Epoch 406/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0753 - accuracy: 0.9747 - val_loss: 0.2344 - val_accuracy: 0.9410\n",
      "Epoch 407/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0721 - accuracy: 0.9768 - val_loss: 0.2359 - val_accuracy: 0.9428\n",
      "Epoch 408/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0717 - accuracy: 0.9763 - val_loss: 0.2335 - val_accuracy: 0.9449\n",
      "Epoch 409/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0682 - accuracy: 0.9772 - val_loss: 0.2503 - val_accuracy: 0.9419\n",
      "Epoch 410/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0692 - accuracy: 0.9762 - val_loss: 0.2365 - val_accuracy: 0.9437\n",
      "Epoch 411/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0704 - accuracy: 0.9766 - val_loss: 0.2393 - val_accuracy: 0.9435\n",
      "Epoch 412/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 0.2281 - val_accuracy: 0.9412\n",
      "Epoch 413/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0677 - accuracy: 0.9766 - val_loss: 0.2327 - val_accuracy: 0.9444\n",
      "Epoch 414/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.2377 - val_accuracy: 0.9433\n",
      "Epoch 415/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.0740 - accuracy: 0.9753 - val_loss: 0.2246 - val_accuracy: 0.9414\n",
      "Epoch 416/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0693 - accuracy: 0.9769 - val_loss: 0.2311 - val_accuracy: 0.9426\n",
      "Epoch 417/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0696 - accuracy: 0.9761 - val_loss: 0.2161 - val_accuracy: 0.9483\n",
      "Epoch 418/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0728 - accuracy: 0.9748 - val_loss: 0.2410 - val_accuracy: 0.9403\n",
      "Epoch 419/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0693 - accuracy: 0.9773 - val_loss: 0.2239 - val_accuracy: 0.9423\n",
      "Epoch 420/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0684 - accuracy: 0.9769 - val_loss: 0.2271 - val_accuracy: 0.9423\n",
      "Epoch 421/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 0.2219 - val_accuracy: 0.9426\n",
      "Epoch 422/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0692 - accuracy: 0.9766 - val_loss: 0.2239 - val_accuracy: 0.9439\n",
      "Epoch 423/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0679 - accuracy: 0.9765 - val_loss: 0.2318 - val_accuracy: 0.9403\n",
      "Epoch 424/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0689 - accuracy: 0.9765 - val_loss: 0.2227 - val_accuracy: 0.9449\n",
      "Epoch 425/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0684 - accuracy: 0.9772 - val_loss: 0.2164 - val_accuracy: 0.9465\n",
      "Epoch 426/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0671 - accuracy: 0.9778 - val_loss: 0.2259 - val_accuracy: 0.9449\n",
      "Epoch 427/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0693 - accuracy: 0.9767 - val_loss: 0.2273 - val_accuracy: 0.9426\n",
      "Epoch 428/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0689 - accuracy: 0.9763 - val_loss: 0.2297 - val_accuracy: 0.9444\n",
      "Epoch 429/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0700 - accuracy: 0.9769 - val_loss: 0.2238 - val_accuracy: 0.9458\n",
      "Epoch 430/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0655 - accuracy: 0.9768 - val_loss: 0.2358 - val_accuracy: 0.9433\n",
      "Epoch 431/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0717 - accuracy: 0.9757 - val_loss: 0.2309 - val_accuracy: 0.9401\n",
      "Epoch 432/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0668 - accuracy: 0.9773 - val_loss: 0.2320 - val_accuracy: 0.9444\n",
      "Epoch 433/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.2312 - val_accuracy: 0.9378\n",
      "Epoch 434/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0694 - accuracy: 0.9765 - val_loss: 0.2294 - val_accuracy: 0.9433\n",
      "Epoch 435/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0723 - accuracy: 0.9757 - val_loss: 0.2258 - val_accuracy: 0.9442\n",
      "Epoch 436/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0661 - accuracy: 0.9780 - val_loss: 0.2250 - val_accuracy: 0.9446\n",
      "Epoch 437/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0693 - accuracy: 0.9762 - val_loss: 0.2228 - val_accuracy: 0.9439\n",
      "Epoch 438/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0663 - accuracy: 0.9774 - val_loss: 0.2261 - val_accuracy: 0.9462\n",
      "Epoch 439/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0674 - accuracy: 0.9780 - val_loss: 0.2308 - val_accuracy: 0.9410\n",
      "Epoch 440/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 0.2287 - val_accuracy: 0.9430\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0677 - accuracy: 0.9772 - val_loss: 0.2319 - val_accuracy: 0.9430\n",
      "Epoch 442/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0668 - accuracy: 0.9770 - val_loss: 0.2305 - val_accuracy: 0.9426\n",
      "Epoch 443/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0677 - accuracy: 0.9776 - val_loss: 0.2290 - val_accuracy: 0.9435\n",
      "Epoch 444/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0680 - accuracy: 0.9775 - val_loss: 0.2566 - val_accuracy: 0.9387\n",
      "Epoch 445/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0702 - accuracy: 0.9763 - val_loss: 0.2277 - val_accuracy: 0.9446\n",
      "Epoch 446/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0695 - accuracy: 0.9774 - val_loss: 0.2332 - val_accuracy: 0.9407\n",
      "Epoch 447/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0655 - accuracy: 0.9769 - val_loss: 0.2350 - val_accuracy: 0.9421\n",
      "Epoch 448/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0662 - accuracy: 0.9773 - val_loss: 0.2336 - val_accuracy: 0.9435\n",
      "Epoch 449/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0683 - accuracy: 0.9766 - val_loss: 0.2312 - val_accuracy: 0.9453\n",
      "Epoch 450/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0672 - accuracy: 0.9776 - val_loss: 0.2308 - val_accuracy: 0.9433\n",
      "Epoch 451/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0666 - accuracy: 0.9783 - val_loss: 0.2396 - val_accuracy: 0.9439\n",
      "Epoch 452/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.2424 - val_accuracy: 0.9421\n",
      "Epoch 453/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0681 - accuracy: 0.9770 - val_loss: 0.2259 - val_accuracy: 0.9478\n",
      "Epoch 454/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0664 - accuracy: 0.9773 - val_loss: 0.2434 - val_accuracy: 0.9435\n",
      "Epoch 455/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0645 - accuracy: 0.9781 - val_loss: 0.2408 - val_accuracy: 0.9435\n",
      "Epoch 456/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0655 - accuracy: 0.9783 - val_loss: 0.2300 - val_accuracy: 0.9465\n",
      "Epoch 457/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0658 - accuracy: 0.9784 - val_loss: 0.2378 - val_accuracy: 0.9419\n",
      "Epoch 458/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0689 - accuracy: 0.9769 - val_loss: 0.2532 - val_accuracy: 0.9401\n",
      "Epoch 459/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.0642 - accuracy: 0.9772 - val_loss: 0.2365 - val_accuracy: 0.9458\n",
      "Epoch 460/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0629 - accuracy: 0.9790 - val_loss: 0.2354 - val_accuracy: 0.9437\n",
      "Epoch 461/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0655 - accuracy: 0.9787 - val_loss: 0.2504 - val_accuracy: 0.9405\n",
      "Epoch 462/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0641 - accuracy: 0.9794 - val_loss: 0.2252 - val_accuracy: 0.9435\n",
      "Epoch 463/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 0.2566 - val_accuracy: 0.9396\n",
      "Epoch 464/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0651 - accuracy: 0.9778 - val_loss: 0.2653 - val_accuracy: 0.9410\n",
      "Epoch 465/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0648 - accuracy: 0.9780 - val_loss: 0.2510 - val_accuracy: 0.9430\n",
      "Epoch 466/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0643 - accuracy: 0.9785 - val_loss: 0.2395 - val_accuracy: 0.9398\n",
      "Epoch 467/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0671 - accuracy: 0.9773 - val_loss: 0.2259 - val_accuracy: 0.9433\n",
      "Epoch 468/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0597 - accuracy: 0.9796 - val_loss: 0.2286 - val_accuracy: 0.9442\n",
      "Epoch 469/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0659 - accuracy: 0.9778 - val_loss: 0.2296 - val_accuracy: 0.9446\n",
      "Epoch 470/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0631 - accuracy: 0.9792 - val_loss: 0.2324 - val_accuracy: 0.9414\n",
      "Epoch 471/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0688 - accuracy: 0.9768 - val_loss: 0.2376 - val_accuracy: 0.9437\n",
      "Epoch 472/500\n",
      "1093/1093 [==============================] - 11s 11ms/step - loss: 0.0634 - accuracy: 0.9787 - val_loss: 0.2445 - val_accuracy: 0.9407\n",
      "Epoch 473/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0666 - accuracy: 0.9776 - val_loss: 0.2330 - val_accuracy: 0.9442\n",
      "Epoch 474/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0664 - accuracy: 0.9781 - val_loss: 0.2263 - val_accuracy: 0.9419\n",
      "Epoch 475/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0622 - accuracy: 0.9793 - val_loss: 0.2311 - val_accuracy: 0.9421\n",
      "Epoch 476/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0626 - accuracy: 0.9798 - val_loss: 0.2396 - val_accuracy: 0.9419\n",
      "Epoch 477/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0638 - accuracy: 0.9778 - val_loss: 0.2310 - val_accuracy: 0.9444\n",
      "Epoch 478/500\n",
      "1093/1093 [==============================] - 12s 11ms/step - loss: 0.0627 - accuracy: 0.9794 - val_loss: 0.2408 - val_accuracy: 0.9428\n",
      "Epoch 479/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0621 - accuracy: 0.9788 - val_loss: 0.2322 - val_accuracy: 0.9428\n",
      "Epoch 480/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0625 - accuracy: 0.9786 - val_loss: 0.2447 - val_accuracy: 0.9412\n",
      "Epoch 481/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 0.2342 - val_accuracy: 0.9405\n",
      "Epoch 482/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0623 - accuracy: 0.9788 - val_loss: 0.2245 - val_accuracy: 0.9417\n",
      "Epoch 483/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0654 - accuracy: 0.9781 - val_loss: 0.2298 - val_accuracy: 0.9428\n",
      "Epoch 484/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0626 - accuracy: 0.9788 - val_loss: 0.2373 - val_accuracy: 0.9433\n",
      "Epoch 485/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0621 - accuracy: 0.9788 - val_loss: 0.2370 - val_accuracy: 0.9458\n",
      "Epoch 486/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0638 - accuracy: 0.9786 - val_loss: 0.2344 - val_accuracy: 0.9419\n",
      "Epoch 487/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0661 - accuracy: 0.9774 - val_loss: 0.2306 - val_accuracy: 0.9435\n",
      "Epoch 488/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0622 - accuracy: 0.9788 - val_loss: 0.2325 - val_accuracy: 0.9439\n",
      "Epoch 489/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0639 - accuracy: 0.9782 - val_loss: 0.2438 - val_accuracy: 0.9423\n",
      "Epoch 490/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0636 - accuracy: 0.9784 - val_loss: 0.2287 - val_accuracy: 0.9398\n",
      "Epoch 491/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0635 - accuracy: 0.9792 - val_loss: 0.2296 - val_accuracy: 0.9439\n",
      "Epoch 492/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0603 - accuracy: 0.9795 - val_loss: 0.2211 - val_accuracy: 0.9460\n",
      "Epoch 493/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0623 - accuracy: 0.9788 - val_loss: 0.2284 - val_accuracy: 0.9430\n",
      "Epoch 494/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0632 - accuracy: 0.9789 - val_loss: 0.2270 - val_accuracy: 0.9439\n",
      "Epoch 495/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0624 - accuracy: 0.9789 - val_loss: 0.2373 - val_accuracy: 0.9458\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0613 - accuracy: 0.9783 - val_loss: 0.2335 - val_accuracy: 0.9437\n",
      "Epoch 497/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0630 - accuracy: 0.9779 - val_loss: 0.2435 - val_accuracy: 0.9430\n",
      "Epoch 498/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0613 - accuracy: 0.9791 - val_loss: 0.2328 - val_accuracy: 0.9430\n",
      "Epoch 499/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0658 - accuracy: 0.9779 - val_loss: 0.2288 - val_accuracy: 0.9446\n",
      "Epoch 500/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0618 - accuracy: 0.9796 - val_loss: 0.2434 - val_accuracy: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9f1410c700>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model for 500 epochs and keep the best model measured on the validation accuracy. \n",
    "\n",
    "EPOCHS = 500\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = CNN_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),  \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "CNN_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92367c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37066/897927363.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
      "/tmp/ipykernel_37066/897927363.py:11: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
      "/tmp/ipykernel_37066/897927363.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
      "/tmp/ipykernel_37066/897927363.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c141c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of CNN: 99.97140765190125 %\n",
      "Accuracy on validation set of CNN: 94.89819407463074 %\n",
      "Accuracy on test set of CNN: 93.93731355667114 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the CNN model \n",
    "\n",
    "score = CNN_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy on test set of CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86bdf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNN-Model\n",
    "\n",
    "models.save_model(CNN_model, CNN_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f52951",
   "metadata": {},
   "source": [
    "<font size=\"5\">3. Quantize the CNN-Model</font>\n",
    "\n",
    "Quantize the model first with 4-bit activations, then with 1-bit activations.\n",
    "These models are then merged in such a way that the final model employs all layers of the quantized model with 4-bit activations, with the exception of the layer preceding the last layer, which uses layers of the 1-bit quantized model.\n",
    "This was done to achieve the maximum bit-width while still allowing for on-chip edge learning.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6800f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (QuantizedConv2D)     (None, 20, 51, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ActivationDiscr (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (QuantizedSepara (None, 20, 51, 32)        1344      \n",
      "_________________________________________________________________\n",
      "separable_1_relu (Activation (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (QuantizedSepara (None, 10, 26, 64)        2400      \n",
      "_________________________________________________________________\n",
      "separable_2_relu (Activation (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (QuantizedSepara (None, 10, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "separable_3_relu (Activation (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (QuantizedSepara (None, 5, 13, 128)        17664     \n",
      "_________________________________________________________________\n",
      "separable_4_relu (Activation (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (QuantizedSepara (None, 5, 13, 256)        34176     \n",
      "_________________________________________________________________\n",
      "separable_5_relu (Activation (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (QuantizedSepara (None, 3, 7, 256)         68096     \n",
      "_________________________________________________________________\n",
      "separable_6_relu (Activation (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (QuantizedSepara (None, 2, 4, 512)         133888    \n",
      "_________________________________________________________________\n",
      "separable_7_relu (Activation (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (QuantizedSepara (None, 2, 4, 1024)        529920    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_relu (Activation (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (QuantizedDense)       (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "re_lu (ActivationDiscreteRel (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 809,004\n",
      "Trainable params: 809,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Quantize the CNN-model with 4-Bit activations\n",
    "\n",
    "quantized_model4 = quantize(CNN_model,\n",
    "                           input_weight_quantization=8,\n",
    "                           weight_quantization=4,\n",
    "                           activ_quantization=4)\n",
    "quantized_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "896efe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (QuantizedConv2D)     (None, 20, 51, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ActivationDiscr (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (QuantizedSepara (None, 20, 51, 32)        1344      \n",
      "_________________________________________________________________\n",
      "separable_1_relu (Activation (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (QuantizedSepara (None, 10, 26, 64)        2400      \n",
      "_________________________________________________________________\n",
      "separable_2_relu (Activation (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (QuantizedSepara (None, 10, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "separable_3_relu (Activation (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (QuantizedSepara (None, 5, 13, 128)        17664     \n",
      "_________________________________________________________________\n",
      "separable_4_relu (Activation (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (QuantizedSepara (None, 5, 13, 256)        34176     \n",
      "_________________________________________________________________\n",
      "separable_5_relu (Activation (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (QuantizedSepara (None, 3, 7, 256)         68096     \n",
      "_________________________________________________________________\n",
      "separable_6_relu (Activation (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (QuantizedSepara (None, 2, 4, 512)         133888    \n",
      "_________________________________________________________________\n",
      "separable_7_relu (Activation (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (QuantizedSepara (None, 2, 4, 1024)        529920    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_relu (Activation (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (QuantizedDense)       (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "re_lu (ActivationDiscreteRel (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 809,004\n",
      "Trainable params: 809,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Quantize the CNN-model with 1-Bit activations\n",
    "\n",
    "quantized_model1 = quantize(quantized_model4,\n",
    "                           input_weight_quantization=8,\n",
    "                           weight_quantization=4,\n",
    "                           activ_quantization=1)\n",
    "quantized_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ee5b28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (QuantizedConv2D)     (None, 20, 51, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ActivationDiscr (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (QuantizedSepara (None, 20, 51, 32)        1344      \n",
      "_________________________________________________________________\n",
      "separable_1_relu (Activation (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (QuantizedSepara (None, 10, 26, 64)        2400      \n",
      "_________________________________________________________________\n",
      "separable_2_relu (Activation (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (QuantizedSepara (None, 10, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "separable_3_relu (Activation (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (QuantizedSepara (None, 5, 13, 128)        17664     \n",
      "_________________________________________________________________\n",
      "separable_4_relu (Activation (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (QuantizedSepara (None, 5, 13, 256)        34176     \n",
      "_________________________________________________________________\n",
      "separable_5_relu (Activation (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (QuantizedSepara (None, 3, 7, 256)         68096     \n",
      "_________________________________________________________________\n",
      "separable_6_relu (Activation (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (QuantizedSepara (None, 2, 4, 512)         133888    \n",
      "_________________________________________________________________\n",
      "separable_7_relu (Activation (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (QuantizedSepara (None, 2, 4, 1024)        529920    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_relu (Activation (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (QuantizedDense)       (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "re_lu (ActivationDiscreteRel (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 809,004\n",
      "Trainable params: 809,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Merge both quantized models\n",
    "\n",
    "quantized_model = models.Sequential()\n",
    "\n",
    "inputs_layer = Input(shape=input_shape)\n",
    "quantized_model.add(inputs_layer)\n",
    "\n",
    "for i in range(1, 25, 1):\n",
    "    layer = quantized_model4.get_layer(index=i)\n",
    "    quantized_model.add(layer)\n",
    "\n",
    "layer1 = quantized_model1.get_layer('separable_8')\n",
    "layer2 = quantized_model1.get_layer('separable_8_global_avg')\n",
    "layer3 = quantized_model1.get_layer('separable_8_relu')\n",
    "layer4 = quantized_model1.get_layer('dropout_7')\n",
    "layer5 = quantized_model4.get_layer('reshape_1')\n",
    "layer6 = quantized_model4.get_layer('flatten')\n",
    "layer7 = quantized_model4.get_layer('dense')\n",
    "layer8 = quantized_model4.get_layer('re_lu')\n",
    "layer9 = quantized_model4.get_layer('activation')\n",
    "\n",
    "\n",
    "\n",
    "quantized_model.add(layer1)\n",
    "quantized_model.add(layer2)\n",
    "quantized_model.add(layer3)\n",
    "quantized_model.add(layer4)\n",
    "quantized_model.add(layer5)\n",
    "quantized_model.add(layer6)\n",
    "quantized_model.add(layer7)\n",
    "quantized_model.add(layer8)\n",
    "quantized_model.add(layer9)\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03527f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy after quantization\n",
    "\n",
    "quantized_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc83d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of quantized CNN: 61.78085207939148 %\n",
      "Accuracy on validation set of quantized CNN: 57.08075761795044 %\n",
      "Accuracy on test set of quantized CNN: 55.73095679283142 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the quantized model before quantization aware training\n",
    "\n",
    "score = quantized_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy on test set of quantized CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39e4d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1093/1093 [==============================] - 19s 15ms/step - loss: 0.1910 - accuracy: 0.9450 - val_loss: 0.2378 - val_accuracy: 0.9382\n",
      "Epoch 2/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1545 - accuracy: 0.9576 - val_loss: 0.2410 - val_accuracy: 0.9382\n",
      "Epoch 3/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1417 - accuracy: 0.9613 - val_loss: 0.2341 - val_accuracy: 0.9378\n",
      "Epoch 4/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1468 - accuracy: 0.9596 - val_loss: 0.2384 - val_accuracy: 0.9375\n",
      "Epoch 5/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1420 - accuracy: 0.9606 - val_loss: 0.2397 - val_accuracy: 0.9321\n",
      "Epoch 6/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1384 - accuracy: 0.9616 - val_loss: 0.2330 - val_accuracy: 0.9417\n",
      "Epoch 7/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1344 - accuracy: 0.9636 - val_loss: 0.2393 - val_accuracy: 0.9398\n",
      "Epoch 8/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1365 - accuracy: 0.9639 - val_loss: 0.2563 - val_accuracy: 0.9348\n",
      "Epoch 9/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1360 - accuracy: 0.9628 - val_loss: 0.2366 - val_accuracy: 0.9389\n",
      "Epoch 10/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1370 - accuracy: 0.9622 - val_loss: 0.2464 - val_accuracy: 0.9355\n",
      "Epoch 11/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1326 - accuracy: 0.9648 - val_loss: 0.2368 - val_accuracy: 0.9382\n",
      "Epoch 12/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1370 - accuracy: 0.9625 - val_loss: 0.2395 - val_accuracy: 0.9369\n",
      "Epoch 13/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1306 - accuracy: 0.9637 - val_loss: 0.2434 - val_accuracy: 0.9378\n",
      "Epoch 14/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1304 - accuracy: 0.9652 - val_loss: 0.2549 - val_accuracy: 0.9357\n",
      "Epoch 15/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1379 - accuracy: 0.9633 - val_loss: 0.2349 - val_accuracy: 0.9337\n",
      "Epoch 16/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1293 - accuracy: 0.9650 - val_loss: 0.2310 - val_accuracy: 0.9373\n",
      "Epoch 17/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1341 - accuracy: 0.9634 - val_loss: 0.2407 - val_accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1318 - accuracy: 0.9639 - val_loss: 0.2335 - val_accuracy: 0.9380\n",
      "Epoch 19/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1272 - accuracy: 0.9654 - val_loss: 0.2398 - val_accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1338 - accuracy: 0.9631 - val_loss: 0.2330 - val_accuracy: 0.9387\n",
      "Epoch 21/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1296 - accuracy: 0.9648 - val_loss: 0.2408 - val_accuracy: 0.9391\n",
      "Epoch 22/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1315 - accuracy: 0.9640 - val_loss: 0.2362 - val_accuracy: 0.9421\n",
      "Epoch 23/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1292 - accuracy: 0.9648 - val_loss: 0.2494 - val_accuracy: 0.9382\n",
      "Epoch 24/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1321 - accuracy: 0.9644 - val_loss: 0.2421 - val_accuracy: 0.9375\n",
      "Epoch 25/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1276 - accuracy: 0.9654 - val_loss: 0.2417 - val_accuracy: 0.9339\n",
      "Epoch 26/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1266 - accuracy: 0.9646 - val_loss: 0.2425 - val_accuracy: 0.9396\n",
      "Epoch 27/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1272 - accuracy: 0.9659 - val_loss: 0.2400 - val_accuracy: 0.9405\n",
      "Epoch 28/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1262 - accuracy: 0.9648 - val_loss: 0.2435 - val_accuracy: 0.9362\n",
      "Epoch 29/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1242 - accuracy: 0.9658 - val_loss: 0.2313 - val_accuracy: 0.9401\n",
      "Epoch 30/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1248 - accuracy: 0.9655 - val_loss: 0.2508 - val_accuracy: 0.9375\n",
      "Epoch 31/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1259 - accuracy: 0.9659 - val_loss: 0.2438 - val_accuracy: 0.9394\n",
      "Epoch 32/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1262 - accuracy: 0.9646 - val_loss: 0.2411 - val_accuracy: 0.9385\n",
      "Epoch 33/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1287 - accuracy: 0.9646 - val_loss: 0.2381 - val_accuracy: 0.9403\n",
      "Epoch 34/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1223 - accuracy: 0.9677 - val_loss: 0.2434 - val_accuracy: 0.9378\n",
      "Epoch 35/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1252 - accuracy: 0.9662 - val_loss: 0.2458 - val_accuracy: 0.9380\n",
      "Epoch 36/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1239 - accuracy: 0.9669 - val_loss: 0.2362 - val_accuracy: 0.9391\n",
      "Epoch 37/100\n",
      "1093/1093 [==============================] - 16s 15ms/step - loss: 0.1254 - accuracy: 0.9659 - val_loss: 0.2381 - val_accuracy: 0.9419\n",
      "Epoch 38/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1254 - accuracy: 0.9653 - val_loss: 0.2396 - val_accuracy: 0.9373\n",
      "Epoch 39/100\n",
      "1093/1093 [==============================] - 16s 15ms/step - loss: 0.1262 - accuracy: 0.9657 - val_loss: 0.2391 - val_accuracy: 0.9382\n",
      "Epoch 40/100\n",
      "1093/1093 [==============================] - 16s 15ms/step - loss: 0.1234 - accuracy: 0.9659 - val_loss: 0.2525 - val_accuracy: 0.9362\n",
      "Epoch 41/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1246 - accuracy: 0.9665 - val_loss: 0.2478 - val_accuracy: 0.9373\n",
      "Epoch 42/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1252 - accuracy: 0.9664 - val_loss: 0.2488 - val_accuracy: 0.9373\n",
      "Epoch 43/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1237 - accuracy: 0.9665 - val_loss: 0.2374 - val_accuracy: 0.9382\n",
      "Epoch 44/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1239 - accuracy: 0.9660 - val_loss: 0.2643 - val_accuracy: 0.9346\n",
      "Epoch 45/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1193 - accuracy: 0.9675 - val_loss: 0.2373 - val_accuracy: 0.9378\n",
      "Epoch 46/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1222 - accuracy: 0.9678 - val_loss: 0.2604 - val_accuracy: 0.9318\n",
      "Epoch 47/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1237 - accuracy: 0.9666 - val_loss: 0.2376 - val_accuracy: 0.9366\n",
      "Epoch 48/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1207 - accuracy: 0.9668 - val_loss: 0.2396 - val_accuracy: 0.9366\n",
      "Epoch 49/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1189 - accuracy: 0.9678 - val_loss: 0.2431 - val_accuracy: 0.9389\n",
      "Epoch 50/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1230 - accuracy: 0.9671 - val_loss: 0.2379 - val_accuracy: 0.9398\n",
      "Epoch 51/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1177 - accuracy: 0.9689 - val_loss: 0.2441 - val_accuracy: 0.9362\n",
      "Epoch 52/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1204 - accuracy: 0.9684 - val_loss: 0.2483 - val_accuracy: 0.9378\n",
      "Epoch 53/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1204 - accuracy: 0.9676 - val_loss: 0.2431 - val_accuracy: 0.9369\n",
      "Epoch 54/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1220 - accuracy: 0.9667 - val_loss: 0.2522 - val_accuracy: 0.9350\n",
      "Epoch 55/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1217 - accuracy: 0.9679 - val_loss: 0.2365 - val_accuracy: 0.9382\n",
      "Epoch 56/100\n",
      "1093/1093 [==============================] - 18s 16ms/step - loss: 0.1186 - accuracy: 0.9671 - val_loss: 0.2393 - val_accuracy: 0.9369\n",
      "Epoch 57/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1173 - accuracy: 0.9685 - val_loss: 0.2422 - val_accuracy: 0.9401\n",
      "Epoch 58/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1249 - accuracy: 0.9654 - val_loss: 0.2339 - val_accuracy: 0.9391\n",
      "Epoch 59/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1240 - accuracy: 0.9662 - val_loss: 0.2479 - val_accuracy: 0.9348\n",
      "Epoch 60/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1241 - accuracy: 0.9666 - val_loss: 0.2424 - val_accuracy: 0.9369\n",
      "Epoch 61/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1211 - accuracy: 0.9671 - val_loss: 0.2476 - val_accuracy: 0.9366\n",
      "Epoch 62/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1205 - accuracy: 0.9666 - val_loss: 0.2405 - val_accuracy: 0.9364\n",
      "Epoch 63/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1204 - accuracy: 0.9678 - val_loss: 0.2469 - val_accuracy: 0.9410\n",
      "Epoch 64/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1182 - accuracy: 0.9682 - val_loss: 0.2473 - val_accuracy: 0.9382\n",
      "Epoch 65/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1172 - accuracy: 0.9680 - val_loss: 0.2513 - val_accuracy: 0.9357\n",
      "Epoch 66/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1175 - accuracy: 0.9678 - val_loss: 0.2455 - val_accuracy: 0.9359\n",
      "Epoch 67/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1165 - accuracy: 0.9682 - val_loss: 0.2436 - val_accuracy: 0.9387\n",
      "Epoch 68/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1181 - accuracy: 0.9688 - val_loss: 0.2422 - val_accuracy: 0.9394\n",
      "Epoch 69/100\n",
      "1093/1093 [==============================] - 16s 15ms/step - loss: 0.1164 - accuracy: 0.9693 - val_loss: 0.2456 - val_accuracy: 0.9366\n",
      "Epoch 70/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1197 - accuracy: 0.9681 - val_loss: 0.2353 - val_accuracy: 0.9401\n",
      "Epoch 71/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1188 - accuracy: 0.9673 - val_loss: 0.2478 - val_accuracy: 0.9298\n",
      "Epoch 72/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1190 - accuracy: 0.9677 - val_loss: 0.2381 - val_accuracy: 0.9382\n",
      "Epoch 73/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1168 - accuracy: 0.9693 - val_loss: 0.2538 - val_accuracy: 0.9332\n",
      "Epoch 74/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1155 - accuracy: 0.9687 - val_loss: 0.2400 - val_accuracy: 0.9378\n",
      "Epoch 75/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1213 - accuracy: 0.9671 - val_loss: 0.2472 - val_accuracy: 0.9382\n",
      "Epoch 76/100\n",
      "1093/1093 [==============================] - 16s 15ms/step - loss: 0.1228 - accuracy: 0.9668 - val_loss: 0.2531 - val_accuracy: 0.9373\n",
      "Epoch 77/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1170 - accuracy: 0.9685 - val_loss: 0.2471 - val_accuracy: 0.9380\n",
      "Epoch 78/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1143 - accuracy: 0.9698 - val_loss: 0.2464 - val_accuracy: 0.9387\n",
      "Epoch 79/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1212 - accuracy: 0.9670 - val_loss: 0.2266 - val_accuracy: 0.9414\n",
      "Epoch 80/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1156 - accuracy: 0.9690 - val_loss: 0.2341 - val_accuracy: 0.9407\n",
      "Epoch 81/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1195 - accuracy: 0.9666 - val_loss: 0.2315 - val_accuracy: 0.9391\n",
      "Epoch 82/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1185 - accuracy: 0.9685 - val_loss: 0.2252 - val_accuracy: 0.9405\n",
      "Epoch 83/100\n",
      "1093/1093 [==============================] - 18s 16ms/step - loss: 0.1211 - accuracy: 0.9674 - val_loss: 0.2324 - val_accuracy: 0.9396\n",
      "Epoch 84/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1186 - accuracy: 0.9677 - val_loss: 0.2443 - val_accuracy: 0.9407\n",
      "Epoch 85/100\n",
      "1093/1093 [==============================] - 18s 16ms/step - loss: 0.1199 - accuracy: 0.9683 - val_loss: 0.2336 - val_accuracy: 0.9401\n",
      "Epoch 86/100\n",
      "1093/1093 [==============================] - 18s 16ms/step - loss: 0.1186 - accuracy: 0.9678 - val_loss: 0.2384 - val_accuracy: 0.9417\n",
      "Epoch 87/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1145 - accuracy: 0.9693 - val_loss: 0.2305 - val_accuracy: 0.9396\n",
      "Epoch 88/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1159 - accuracy: 0.9688 - val_loss: 0.2386 - val_accuracy: 0.9414\n",
      "Epoch 89/100\n",
      "1093/1093 [==============================] - 18s 16ms/step - loss: 0.1165 - accuracy: 0.9694 - val_loss: 0.2394 - val_accuracy: 0.9389\n",
      "Epoch 90/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1162 - accuracy: 0.9679 - val_loss: 0.2457 - val_accuracy: 0.9385\n",
      "Epoch 91/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1161 - accuracy: 0.9683 - val_loss: 0.2426 - val_accuracy: 0.9389\n",
      "Epoch 92/100\n",
      "1093/1093 [==============================] - 18s 16ms/step - loss: 0.1173 - accuracy: 0.9677 - val_loss: 0.2443 - val_accuracy: 0.9366\n",
      "Epoch 93/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1168 - accuracy: 0.9682 - val_loss: 0.2286 - val_accuracy: 0.9417\n",
      "Epoch 94/100\n",
      "1093/1093 [==============================] - 18s 16ms/step - loss: 0.1173 - accuracy: 0.9685 - val_loss: 0.2267 - val_accuracy: 0.9389\n",
      "Epoch 95/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1172 - accuracy: 0.9687 - val_loss: 0.2358 - val_accuracy: 0.9398\n",
      "Epoch 96/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1129 - accuracy: 0.9702 - val_loss: 0.2398 - val_accuracy: 0.9417\n",
      "Epoch 97/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1155 - accuracy: 0.9695 - val_loss: 0.2361 - val_accuracy: 0.9401\n",
      "Epoch 98/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1171 - accuracy: 0.9696 - val_loss: 0.2442 - val_accuracy: 0.9414\n",
      "Epoch 99/100\n",
      "1093/1093 [==============================] - 17s 16ms/step - loss: 0.1166 - accuracy: 0.9681 - val_loss: 0.2463 - val_accuracy: 0.9327\n",
      "Epoch 100/100\n",
      "1093/1093 [==============================] - 17s 15ms/step - loss: 0.1110 - accuracy: 0.9710 - val_loss: 0.2343 - val_accuracy: 0.9405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9e4c237be0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = quantized_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),  \n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback])\n",
    "\n",
    "quantized_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f848d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of quantized CNN: 99.85131025314331 %\n",
      "Accuracy on validation set of quantized CNN: 94.21185255050659 %\n",
      "Accuracy on test set of quantized CNN: 93.50262880325317 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the quantized model after quantization aware training\n",
    "\n",
    "score = quantized_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy on test set of quantized CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "506a33da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37066/897927363.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
      "/tmp/ipykernel_37066/897927363.py:11: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
      "/tmp/ipykernel_37066/897927363.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
      "/tmp/ipykernel_37066/897927363.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffc61add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized-model\n",
    "\n",
    "models.save_model(quantized_model, Quantized_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e325f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 21:52:30.377597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:30.535312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:30.535468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:30.535976: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-15 21:52:30.536394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:30.536535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:30.536646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:31.904240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:31.904407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:31.904516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 21:52:31.905229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9511 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "####### If pretrained the quantized model can be loaded ########\n",
    "\n",
    "quantized_model = cnn2snn.load_quantized_model('final_quantized_edge_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b4727",
   "metadata": {},
   "source": [
    "<font size=\"5\">4. Akida Model Conversion</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4efc22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Summary                 \n",
      "_______________________________________________\n",
      "Input shape   Output shape  Sequences  Layers\n",
      "===============================================\n",
      "[40, 101, 1]  [1, 1, 12]    1          10    \n",
      "_______________________________________________\n",
      "\n",
      "                SW/conv_0-dense (Software)                 \n",
      "___________________________________________________________\n",
      "Layer (type)             Output shape   Kernel shape     \n",
      "===========================================================\n",
      "conv_0 (InputConv.)      [51, 20, 32]   (3, 3, 1, 32)    \n",
      "___________________________________________________________\n",
      "separable_1 (Sep.Conv.)  [51, 20, 32]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 32)   \n",
      "___________________________________________________________\n",
      "separable_2 (Sep.Conv.)  [26, 10, 64]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 64)   \n",
      "___________________________________________________________\n",
      "separable_3 (Sep.Conv.)  [26, 10, 128]  (3, 3, 64, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 64, 128)  \n",
      "___________________________________________________________\n",
      "separable_4 (Sep.Conv.)  [13, 5, 128]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 128) \n",
      "___________________________________________________________\n",
      "separable_5 (Sep.Conv.)  [13, 5, 256]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 256) \n",
      "___________________________________________________________\n",
      "separable_6 (Sep.Conv.)  [7, 3, 256]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 256) \n",
      "___________________________________________________________\n",
      "separable_7 (Sep.Conv.)  [4, 2, 512]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 512) \n",
      "___________________________________________________________\n",
      "separable_8 (Sep.Conv.)  [1, 1, 1024]   (3, 3, 512, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 512, 1024)\n",
      "___________________________________________________________\n",
      "dense (Fully.)           [1, 1, 12]     (1, 1, 1024, 12) \n",
      "___________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Convert to an Akida model\n",
    "\n",
    "akida_model = convert(quantized_model)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6c944ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN accuracy on training set after conversion: 99.84845018872241 %\n",
      "SNN accuracy on validation set after conversion: 94.00594829558453 %\n",
      "SNN accuracy on test set after conversion: 93.4339967970716 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the final Akida model\n",
    "\n",
    "results = akida_model.predict(x_train)\n",
    "accuracy = (y_train == results).mean()\n",
    "\n",
    "print('SNN accuracy on training set after conversion:', accuracy * 100,'%')\n",
    "\n",
    "\n",
    "results = akida_model.predict(x_val)\n",
    "accuracy = (y_val == results).mean()\n",
    "\n",
    "print('SNN accuracy on validation set after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test)\n",
    "accuracy = (y_test == results).mean()\n",
    "\n",
    "\n",
    "print('SNN accuracy on test set after conversion:', accuracy * 100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf4ff0",
   "metadata": {},
   "source": [
    "<font size=\"5\">5. Edge Learning</font>\n",
    "\n",
    "This is the final section of the notebook.\n",
    "The results of this section are not included in the master thesis since edge learning was done on chip, namely the BrainChip development kit.\n",
    "However, the code was kept in to demonstrate the entire procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "623738b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of spikes: 250.38078902229847\n",
      "The number of weights is then set to: 300\n"
     ]
    }
   ],
   "source": [
    "# Estimate the hyperparameter \"number of weights\".\n",
    "# This hyperparameter describes the number of weights assigned for each neuron in the edge layer. \n",
    "# As described in the MetaTF documentation 10% of the training set is used to evaluate the sparsity. \n",
    "# Code Source: https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html\n",
    "\n",
    "num_samples = ceil(0.1 * x_train.shape[0])\n",
    "sparsities = evaluate_sparsity(akida_model, x_train[:num_samples])\n",
    "\n",
    "# Retrieve the number of output spikes from the feature extractor output\n",
    "output_density = 1 - sparsities[akida_model.get_layer('separable_8')]\n",
    "avg_spikes = quantized_model.get_layer('separable_8').output_shape[-1] * output_density\n",
    "print(f\"Average number of spikes: {avg_spikes}\")\n",
    "\n",
    "# Fix the number of weights to 1.2 times the average number of output spikes\n",
    "num_weights = int(1.2 * avg_spikes)\n",
    "print(\"The number of weights is then set to:\", num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "487848b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida inference 34972 MFCC took 53.96 with neurons per class: s.\n",
      " 2\n",
      "Akida validation set accuracy on initial data set: 93.50 % with neurons per class:  2\n",
      "Akida inference 34972 MFCC took 53.94 with neurons per class: s.\n",
      " 4\n",
      "Akida validation set accuracy on initial data set: 93.57 % with neurons per class:  4\n",
      "Akida inference 34972 MFCC took 55.16 with neurons per class: s.\n",
      " 8\n",
      "Akida validation set accuracy on initial data set: 93.48 % with neurons per class:  8\n",
      "Akida inference 34972 MFCC took 54.30 with neurons per class: s.\n",
      " 16\n",
      "Akida validation set accuracy on initial data set: 93.69 % with neurons per class:  16\n",
      "Akida inference 34972 MFCC took 54.80 with neurons per class: s.\n",
      " 32\n",
      "Akida validation set accuracy on initial data set: 93.78 % with neurons per class:  32\n",
      "Akida inference 34972 MFCC took 54.84 with neurons per class: s.\n",
      " 40\n",
      "Akida validation set accuracy on initial data set: 93.85 % with neurons per class:  40\n",
      "Akida inference 34972 MFCC took 56.31 with neurons per class: s.\n",
      " 50\n",
      "Akida validation set accuracy on initial data set: 93.78 % with neurons per class:  50\n",
      "Akida inference 34972 MFCC took 56.95 with neurons per class: s.\n",
      " 60\n",
      "Akida validation set accuracy on initial data set: 93.82 % with neurons per class:  60\n",
      "Akida inference 34972 MFCC took 57.01 with neurons per class: s.\n",
      " 70\n",
      "Akida validation set accuracy on initial data set: 93.75 % with neurons per class:  70\n",
      "Akida inference 34972 MFCC took 56.72 with neurons per class: s.\n",
      " 80\n",
      "Akida validation set accuracy on initial data set: 93.87 % with neurons per class:  80\n",
      "Akida inference 34972 MFCC took 57.25 with neurons per class: s.\n",
      " 90\n",
      "Akida validation set accuracy on initial data set: 93.98 % with neurons per class:  90\n",
      "Akida inference 34972 MFCC took 58.65 with neurons per class: s.\n",
      " 100\n",
      "Akida validation set accuracy on initial data set: 93.96 % with neurons per class:  100\n",
      "Akida inference 34972 MFCC took 59.78 with neurons per class: s.\n",
      " 150\n",
      "Akida validation set accuracy on initial data set: 93.91 % with neurons per class:  150\n",
      "Akida inference 34972 MFCC took 61.48 with neurons per class: s.\n",
      " 200\n",
      "Akida validation set accuracy on initial data set: 94.03 % with neurons per class:  200\n",
      "Akida inference 34972 MFCC took 63.14 with neurons per class: s.\n",
      " 300\n",
      "Akida validation set accuracy on initial data set: 93.91 % with neurons per class:  300\n",
      "Akida inference 34972 MFCC took 66.02 with neurons per class: s.\n",
      " 350\n",
      "Akida validation set accuracy on initial data set: 93.94 % with neurons per class:  350\n",
      "Akida inference 34972 MFCC took 66.92 with neurons per class: s.\n",
      " 400\n",
      "Akida validation set accuracy on initial data set: 93.85 % with neurons per class:  400\n",
      "Akida inference 34972 MFCC took 67.72 with neurons per class: s.\n",
      " 450\n",
      "Akida validation set accuracy on initial data set: 93.89 % with neurons per class:  450\n",
      "Akida inference 34972 MFCC took 73.75 with neurons per class: s.\n",
      " 500\n",
      "Akida validation set accuracy on initial data set: 93.96 % with neurons per class:  500\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters search for the hyperparameter \"neurons per class\".\n",
    "\n",
    "neurons_per_class = [2, 4, 8, 16, 32, 40, 50, 60, 70, 80, 90, 100, 150, 200, 300, 350, 400, 450, 500]\n",
    "\n",
    "for idx, n in enumerate(neurons_per_class):\n",
    "    \n",
    "    akida_model_test = convert(quantized_model)\n",
    "\n",
    "    akida_model_test.pop_layer()\n",
    "    layer_fc = FullyConnected(name='akida_edge_layer',\n",
    "                              units=num_labels * n,\n",
    "                              activation=False)\n",
    "    akida_model_test.add(layer_fc)\n",
    "\n",
    "    #akida_model_test.summary()\n",
    "    \n",
    "    akida_model_test.compile(num_weights=num_weights,\n",
    "                     num_classes=num_labels,\n",
    "                     learning_competition=0.1)\n",
    "\n",
    "    batch_size = 16\n",
    "    preds_ak = np.zeros(y_val.shape[0])\n",
    "    num_batches_val = ceil(x_val.shape[0] / batch_size)\n",
    "    num_batches = ceil(x_train.shape[0] / batch_size)\n",
    "    \n",
    "    \n",
    "    start = time()\n",
    "    for i in range(num_batches):\n",
    "        s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        akida_model_test.fit(x_train[s], y_train[s].astype(np.int32))\n",
    "    end = time()\n",
    "    \n",
    "    preds_val_ak = akida_model_test.predict(x_val, num_classes=num_labels)\n",
    "    acc_val_ak = np.sum(preds_val_ak == y_val) / y_val.shape[0]\n",
    "    print(f'Akida inference {len(x_train)} MFCC took {end-start:.2f} with neurons per class: s.\\n', n)\n",
    "    print(f\"Akida validation set accuracy on initial data set: {100 * acc_val_ak:.2f} %\", 'with neurons per class: ',n)\n",
    "    del akida_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef8862f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the last layer with the edge layer. \n",
    "# The edge layer is simply a fully connected layer.\n",
    "# Code Source: https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html\n",
    "\n",
    "num_neurons_per_class = 500\n",
    "\n",
    "akida_model.pop_layer()\n",
    "layer_fc = FullyConnected(name='akida_edge_layer',\n",
    "                          units=num_labels * num_neurons_per_class,\n",
    "                          activation=False)\n",
    "akida_model.add(layer_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1169be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN accuracy on training set after edge layer replacement: 7.820542148004117 %\n",
      "SNN accuracy on validation set after edge layer replacement: 7.778540379775794 %\n",
      "SNN accuracy on test set after edge layer replacement: 8.053077099062 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance of the Akida model before STDP\n",
    "\n",
    "results = akida_model.predict(x_train)\n",
    "accuracy = (y_train == results).mean()\n",
    "\n",
    "print('SNN accuracy on training set after edge layer replacement:', accuracy * 100,'%')\n",
    "\n",
    "\n",
    "results = akida_model.predict(x_val)\n",
    "accuracy = (y_val == results).mean()\n",
    "\n",
    "print('SNN accuracy on validation set after edge layer replacement:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test)\n",
    "accuracy = (y_test == results).mean()\n",
    "\n",
    "\n",
    "print('SNN accuracy on test set after edge layer replacement:', accuracy * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f975003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Summary                 \n",
      "_______________________________________________\n",
      "Input shape   Output shape  Sequences  Layers\n",
      "===============================================\n",
      "[40, 101, 1]  [1, 1, 6000]  1          10    \n",
      "_______________________________________________\n",
      "\n",
      "            SW/conv_0-akida_edge_layer (Software)             \n",
      "______________________________________________________________\n",
      "Layer (type)               Output shape   Kernel shape      \n",
      "==============================================================\n",
      "conv_0 (InputConv.)        [51, 20, 32]   (3, 3, 1, 32)     \n",
      "______________________________________________________________\n",
      "separable_1 (Sep.Conv.)    [51, 20, 32]   (3, 3, 32, 1)     \n",
      "______________________________________________________________\n",
      "                                          (1, 1, 32, 32)    \n",
      "______________________________________________________________\n",
      "separable_2 (Sep.Conv.)    [26, 10, 64]   (3, 3, 32, 1)     \n",
      "______________________________________________________________\n",
      "                                          (1, 1, 32, 64)    \n",
      "______________________________________________________________\n",
      "separable_3 (Sep.Conv.)    [26, 10, 128]  (3, 3, 64, 1)     \n",
      "______________________________________________________________\n",
      "                                          (1, 1, 64, 128)   \n",
      "______________________________________________________________\n",
      "separable_4 (Sep.Conv.)    [13, 5, 128]   (3, 3, 128, 1)    \n",
      "______________________________________________________________\n",
      "                                          (1, 1, 128, 128)  \n",
      "______________________________________________________________\n",
      "separable_5 (Sep.Conv.)    [13, 5, 256]   (3, 3, 128, 1)    \n",
      "______________________________________________________________\n",
      "                                          (1, 1, 128, 256)  \n",
      "______________________________________________________________\n",
      "separable_6 (Sep.Conv.)    [7, 3, 256]    (3, 3, 256, 1)    \n",
      "______________________________________________________________\n",
      "                                          (1, 1, 256, 256)  \n",
      "______________________________________________________________\n",
      "separable_7 (Sep.Conv.)    [4, 2, 512]    (3, 3, 256, 1)    \n",
      "______________________________________________________________\n",
      "                                          (1, 1, 256, 512)  \n",
      "______________________________________________________________\n",
      "separable_8 (Sep.Conv.)    [1, 1, 1024]   (3, 3, 512, 1)    \n",
      "______________________________________________________________\n",
      "                                          (1, 1, 512, 1024) \n",
      "______________________________________________________________\n",
      "akida_edge_layer (Fully.)  [1, 1, 6000]   (1, 1, 1024, 6000)\n",
      "______________________________________________________________\n",
      "\n",
      "              Learning Summary              \n",
      "____________________________________________\n",
      "Learning Layer    # Input Conn.  # Weights\n",
      "============================================\n",
      "akida_edge_layer  1024           300      \n",
      "____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile Akida model with hyperparameters\n",
    "\n",
    "akida_model.compile(num_weights=num_weights,\n",
    "                 num_classes=num_labels,\n",
    "                 learning_competition=0.1)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de1c4acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida learning with 12 classes...         (this step can take a few minutes)\n",
      "Elapsed time for Akida training: 70.51 s\n"
     ]
    }
   ],
   "source": [
    "# Train the Akida model\n",
    "# Code Source: https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html\n",
    "\n",
    "batch_size = 16\n",
    "preds_ak = np.zeros(y_val.shape[0])\n",
    "num_batches_val = ceil(x_val.shape[0] / batch_size)\n",
    "\n",
    "# Train the last layer using Akida `fit` method\n",
    "print(f\"Akida learning with {num_labels} classes... \\\n",
    "        (this step can take a few minutes)\")\n",
    "num_batches = ceil(x_train.shape[0] / batch_size)\n",
    "start = time()\n",
    "for i in range(num_batches):\n",
    "    s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "    akida_model.fit(x_train[s], y_train[s].astype(np.int32))\n",
    "end = time()\n",
    "\n",
    "print(f\"Elapsed time for Akida training: {end-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "496075fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida train set accuracy: 99.05 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance of the Akida model on the training set. \n",
    "\n",
    "preds_val_ak = akida_model.predict(x_train, num_classes=num_labels)\n",
    "acc_val_ak = np.sum(preds_val_ak == y_train) / y_train.shape[0]\n",
    "print(f\"Akida train set accuracy: {100 * acc_val_ak:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db71675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida validation set accuracy: 93.94 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance of the Akida model on the validation set. \n",
    "\n",
    "preds_val_ak = np.zeros(y_val.shape[0])\n",
    "for i in range(num_batches_val):\n",
    "    s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "    preds_val_ak[s] = akida_model.predict(x_val[s], num_classes=num_labels)\n",
    "\n",
    "acc_val_ak = np.sum(preds_val_ak == y_val) / y_val.shape[0]\n",
    "print(f\"Akida validation set accuracy: {100 * acc_val_ak:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc80d02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida test set accuracy: 93.27 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance of the Akida model on the test set. \n",
    "\n",
    "\n",
    "preds_val_ak = np.zeros(y_test.shape[0])\n",
    "for i in range(num_batches_val):\n",
    "    s = slice(i * batch_size, (i + 1) * batch_size)\n",
    "    preds_val_ak[s] = akida_model.predict(x_test[s], num_classes=num_labels)\n",
    "\n",
    "acc_val_ak = np.sum(preds_val_ak == y_test) / y_test.shape[0]\n",
    "print(f\"Akida test set accuracy: {100 * acc_val_ak:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9b55abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Edge learning with 3 new classes ...\n",
      "Elapsed time for Akida edge learning: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "# Add 3 new classes/keywords\n",
    "\n",
    "akida_model.add_classes(3)\n",
    "\n",
    "# Train the Akida on the new keywords\n",
    "# Code Source: https://doc.brainchipinc.com/examples/edge/plot_1_edge_learning_kws.html\n",
    "\n",
    "print(\"\\nEdge learning with 3 new classes ...\")\n",
    "start = time()\n",
    "akida_model.fit(x_train_edge, y_train_edge.astype(np.int32))\n",
    "end = time()\n",
    "print(f\"Elapsed time for Akida edge learning: {end-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "993666f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida train set accuracy on old data set: 99.04 %\n",
      "Akida validation set accuracy on old data set: 93.87 %\n",
      "Akida test set accuracy on old data set: 93.21 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance of the Akida model on the initial data set\n",
    "\n",
    "preds_val_ak = akida_model.predict(x_train, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak == y_train) / y_train.shape[0]\n",
    "print(f\"Akida train set accuracy on old data set: {100 * acc_val_ak:.2f} %\")\n",
    "preds_val_ak = akida_model.predict(x_val, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak == y_val) / y_val.shape[0]\n",
    "print(f\"Akida validation set accuracy on old data set: {100 * acc_val_ak:.2f} %\")\n",
    "preds_val_ak = akida_model.predict(x_test, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak == y_test) / y_test.shape[0]\n",
    "print(f\"Akida test set accuracy on old data set: {100 * acc_val_ak:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5794a4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida training set accuracy on new data set: 96.78 %\n",
      "Akida validation set accuracy on new data set: 90.59 %\n"
     ]
    }
   ],
   "source": [
    "# Print the performance of the Akida model on the edge data set\n",
    "\n",
    "preds_val_ak = akida_model.predict(x_train_edge, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak == y_train_edge) / y_train_edge.shape[0]\n",
    "print(f\"Akida training set accuracy on new data set: {100 * acc_val_ak:.2f} %\")\n",
    "preds_val_ak = akida_model.predict(x_val_edge, num_classes=num_labels_edge)\n",
    "acc_val_ak = np.sum(preds_val_ak == y_val_edge) / y_val_edge.shape[0]\n",
    "print(f\"Akida validation set accuracy on new data set: {100 * acc_val_ak:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9984218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
