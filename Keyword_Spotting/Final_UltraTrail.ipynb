{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06be9a78",
   "metadata": {},
   "source": [
    "<font size=\"5\">First UltraTrail Run</font>\n",
    "\n",
    "In this notebook the performance of an Akida model is evaluated on a data set according to the UltraTrail\n",
    "experimental setup. The noise in the data set is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d98b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and dependencies\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "import akida\n",
    "from akida import FullyConnected\n",
    "from akida import evaluate_sparsity\n",
    "import cnn2snn\n",
    "from cnn2snn import check_model_compatibility\n",
    "from cnn2snn import quantize\n",
    "from cnn2snn import quantize_layer\n",
    "from cnn2snn import convert\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import (Input, Reshape, Activation, Flatten, Rescaling, Add, Dropout)\n",
    "\n",
    "import akida_models\n",
    "from akida_models import layer_blocks\n",
    "from akida_models.layer_blocks import conv_block, separable_conv_block, dense_block\n",
    "\n",
    "\n",
    "from math import ceil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004de406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, set seed for experiment reproducibility\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9579864",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 1. Load the Data Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7801fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories of the data\n",
    "\n",
    "data_dir = pathlib.Path('data/Modded_Google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c09dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known and unknown commands: ['off' 'up' 'down' 'on' 'stop' 'yes' 'right' 'unknown' 'left' 'go' 'no'\n",
      " 'silence']\n"
     ]
    }
   ],
   "source": [
    "# Check commands\n",
    "\n",
    "targets = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "targets = targets[targets != 'README.md']\n",
    "\n",
    "print('Known and unknown commands:', targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf58b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories, and names of the model and data sets\n",
    "\n",
    "feature_sets_path = '/home/sebastian/Schreibtisch/Masterarbeit/Audio/'\n",
    "feature_sets_filename = 'final1_stored_files_targets_int_normalized.npz'\n",
    "\n",
    "CNN_model_filename = 'final_CNN_ultratrail_model.h5'\n",
    "Quantized_model_filename = 'final_quantized_ultratrail_model.h5'\n",
    "Akida_model_filename = 'final_akida_ultratrail_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7da8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Sets:  ['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "# Load feature sets\n",
    "\n",
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "\n",
    "print('Feature Sets: ', feature_sets.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d22817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets\n",
    "\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3614c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (34976, 40, 101)\n",
      "x_val shape:  (4371, 40, 101)\n",
      "x_test shape:  (4371, 40, 101)\n"
     ]
    }
   ],
   "source": [
    "# Look at tensor dimensions\n",
    "\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('x_val shape: ', x_val.shape)\n",
    "print('x_test shape: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a145fca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of one tensor: \n",
      " [[  9  10   8 ...  10  11   9]\n",
      " [129 133 128 ... 150 153 141]\n",
      " [138 142 132 ... 125 127 118]\n",
      " ...\n",
      " [145 149 123 ... 102 144 175]\n",
      " [ 91  91  83 ... 178 142 135]\n",
      " [ 99  94  94 ... 141 166 117]]\n"
     ]
    }
   ],
   "source": [
    "# Print an example tensor\n",
    "\n",
    "print('Example of one tensor: \\n', x_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834f237",
   "metadata": {},
   "source": [
    "Check the dimensions of the data set. \n",
    "Is the unknown and silence category roughly 10% (Category 7 and 11)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7391d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 2780,\n",
       " 1.0: 2610,\n",
       " 2.0: 2907,\n",
       " 3.0: 2737,\n",
       " 4.0: 2832,\n",
       " 5.0: 2900,\n",
       " 6.0: 2764,\n",
       " 7.0: 3497,\n",
       " 8.0: 2794,\n",
       " 9.0: 2796,\n",
       " 10.0: 2812,\n",
       " 11.0: 3547}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e59bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 318,\n",
       " 1.0: 320,\n",
       " 2.0: 346,\n",
       " 3.0: 358,\n",
       " 4.0: 369,\n",
       " 5.0: 386,\n",
       " 6.0: 332,\n",
       " 7.0: 471,\n",
       " 8.0: 358,\n",
       " 9.0: 325,\n",
       " 10.0: 380,\n",
       " 11.0: 408}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4a5de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 329,\n",
       " 1.0: 339,\n",
       " 2.0: 327,\n",
       " 3.0: 376,\n",
       " 4.0: 362,\n",
       " 5.0: 406,\n",
       " 6.0: 352,\n",
       " 7.0: 403,\n",
       " 8.0: 350,\n",
       " 9.0: 357,\n",
       " 10.0: 353,\n",
       " 11.0: 417}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe971e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels:  12\n"
     ]
    }
   ],
   "source": [
    "# Define the number of labels\n",
    "\n",
    "num_labels = len(unique)\n",
    "print('number of labels: ', num_labels)\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc71662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add dimension to all data: Order Train, Val, Test\n",
      "(34976, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n",
      "(4371, 40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN for conversion expects (batch, height, width, channels)\n",
    "# The channels can either be 1 for gray-scaled images or 3 for RGB-images\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "x_val = x_val.reshape(x_val.shape[0], \n",
    "                      x_val.shape[1], \n",
    "                      x_val.shape[2], \n",
    "                      1)\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)\n",
    "\n",
    "\n",
    "print('Add dimension to all data: Order Train, Val, Test')\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b892d92",
   "metadata": {},
   "source": [
    "<font size=\"5\">2. Train and Save the CNN-Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0476781a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of 1 Tensor/MFCC:  (40, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape for the CNN, namely the dimension of 1 MFCC\n",
    "\n",
    "input_shape = x_test.shape[1:]\n",
    "print('Input shape of 1 Tensor/MFCC: ', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "204c7998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 16:00:27.001426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.037531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.037694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.038383: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-12 16:00:27.038988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.039118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.039232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.374846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.374999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.375109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 16:00:27.375202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9936 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 20, 51, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_0_BN (BatchNormalizatio (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ReLU)           (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (SeparableConv2D (None, 20, 51, 32)        1312      \n",
      "_________________________________________________________________\n",
      "separable_1_BN (BatchNormali (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "separable_1_relu (ReLU)      (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (SeparableConv2D (None, 10, 26, 64)        2336      \n",
      "_________________________________________________________________\n",
      "separable_2_BN (BatchNormali (None, 10, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_2_relu (ReLU)      (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (SeparableConv2D (None, 10, 26, 128)       8768      \n",
      "_________________________________________________________________\n",
      "separable_3_BN (BatchNormali (None, 10, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_3_relu (ReLU)      (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (SeparableConv2D (None, 5, 13, 128)        17536     \n",
      "_________________________________________________________________\n",
      "separable_4_BN (BatchNormali (None, 5, 13, 128)        512       \n",
      "_________________________________________________________________\n",
      "separable_4_relu (ReLU)      (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (SeparableConv2D (None, 5, 13, 256)        33920     \n",
      "_________________________________________________________________\n",
      "separable_5_BN (BatchNormali (None, 5, 13, 256)        1024      \n",
      "_________________________________________________________________\n",
      "separable_5_relu (ReLU)      (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (SeparableConv2D (None, 3, 7, 256)         67840     \n",
      "_________________________________________________________________\n",
      "separable_6_BN (BatchNormali (None, 3, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "separable_6_relu (ReLU)      (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (SeparableConv2D (None, 2, 4, 512)         133376    \n",
      "_________________________________________________________________\n",
      "separable_7_BN (BatchNormali (None, 2, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "separable_7_relu (ReLU)      (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (SeparableConv2D (None, 2, 4, 1024)        528896    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_BN (BatchNormali (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "separable_8_relu (ReLU)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1024)              0         \n",
      "=================================================================\n",
      "Total params: 1,857,696\n",
      "Trainable params: 1,850,784\n",
      "Non-trainable params: 6,912\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "######## Optional if Pretrained ########\n",
    "\n",
    "CNN_model = tf.keras.models.load_model(CNN_model_filename)\n",
    "\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e285a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 20, 51, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_0_BN (BatchNormalizatio (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ReLU)           (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (SeparableConv2D (None, 20, 51, 32)        1312      \n",
      "_________________________________________________________________\n",
      "separable_1_BN (BatchNormali (None, 20, 51, 32)        128       \n",
      "_________________________________________________________________\n",
      "separable_1_relu (ReLU)      (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (SeparableConv2D (None, 10, 26, 64)        2336      \n",
      "_________________________________________________________________\n",
      "separable_2_BN (BatchNormali (None, 10, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_2_relu (ReLU)      (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (SeparableConv2D (None, 10, 26, 128)       8768      \n",
      "_________________________________________________________________\n",
      "separable_3_BN (BatchNormali (None, 10, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_3_relu (ReLU)      (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (SeparableConv2D (None, 5, 13, 128)        17536     \n",
      "_________________________________________________________________\n",
      "separable_4_BN (BatchNormali (None, 5, 13, 128)        512       \n",
      "_________________________________________________________________\n",
      "separable_4_relu (ReLU)      (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (SeparableConv2D (None, 5, 13, 256)        33920     \n",
      "_________________________________________________________________\n",
      "separable_5_BN (BatchNormali (None, 5, 13, 256)        1024      \n",
      "_________________________________________________________________\n",
      "separable_5_relu (ReLU)      (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (SeparableConv2D (None, 3, 7, 256)         67840     \n",
      "_________________________________________________________________\n",
      "separable_6_BN (BatchNormali (None, 3, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "separable_6_relu (ReLU)      (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (SeparableConv2D (None, 2, 4, 512)         133376    \n",
      "_________________________________________________________________\n",
      "separable_7_BN (BatchNormali (None, 2, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "separable_7_relu (ReLU)      (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (SeparableConv2D (None, 2, 4, 1024)        528896    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_BN (BatchNormali (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "separable_8_relu (ReLU)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 816,348\n",
      "Trainable params: 811,460\n",
      "Non-trainable params: 4,888\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 16:01:46.468926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.530642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.530811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.531185: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-15 16:01:46.531683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.531816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.531930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.852559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.852708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.852811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-15 16:01:46.852905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9505 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# CNN created with the functional API and from akida_models layer_blocks\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Rescaling(1. / 255)(inputs)\n",
    "x = conv_block(x,\n",
    "               filters=32,\n",
    "               kernel_size=(3, 3),\n",
    "               padding='same',\n",
    "               strides=(2, 2),\n",
    "               use_bias=False,\n",
    "               name='conv_0',\n",
    "               add_batchnorm=True)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=32,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_1',\n",
    "                         add_batchnorm=True)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=64,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_2',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=128,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_3',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=128,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_4',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=256,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_5',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=256,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_6',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=512,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         strides=(2,2),\n",
    "                         use_bias=False,\n",
    "                         name='separable_7',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = separable_conv_block(x,\n",
    "                         filters=1024,\n",
    "                         kernel_size=(3, 3),\n",
    "                         padding='same',\n",
    "                         use_bias=False,\n",
    "                         name='separable_8',\n",
    "                         pooling='global_avg',\n",
    "                         add_batchnorm=True)\n",
    "\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "shape = (1, 1, int(1024))\n",
    "x = Reshape(shape, name='reshape_1')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = layers.Dense(units = 12, activation='linear', use_bias = True)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "outputs = layers.Activation('softmax')(x)\n",
    "\n",
    "CNN_model = keras.Model(inputs=inputs, outputs=outputs, name='CNN_model')\n",
    "\n",
    "CNN_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a1e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compatible for Akida conversion: True\n"
     ]
    }
   ],
   "source": [
    "# Check if model is compatible\n",
    "\n",
    "print(\"Model compatible for Akida conversion:\", check_model_compatibility(CNN_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208c5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN model\n",
    "\n",
    "CNN_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25eb38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 16:01:58.621549: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 16:02:00.327624: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8301\n",
      "2022-04-15 16:02:01.189360: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-15 16:02:01.413983: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 10ms/step - loss: 2.1901 - accuracy: 0.2384 - val_loss: 3.2950 - val_accuracy: 0.2359\n",
      "Epoch 2/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 1.2941 - accuracy: 0.5912 - val_loss: 0.8658 - val_accuracy: 0.7323\n",
      "Epoch 3/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.9413 - accuracy: 0.7065 - val_loss: 0.6636 - val_accuracy: 0.7881\n",
      "Epoch 4/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.7947 - accuracy: 0.7530 - val_loss: 0.5080 - val_accuracy: 0.8380\n",
      "Epoch 5/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.7019 - accuracy: 0.7825 - val_loss: 0.7175 - val_accuracy: 0.7655\n",
      "Epoch 6/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.6421 - accuracy: 0.8024 - val_loss: 0.9579 - val_accuracy: 0.7060\n",
      "Epoch 7/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.5988 - accuracy: 0.8162 - val_loss: 0.4652 - val_accuracy: 0.8479\n",
      "Epoch 8/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.5575 - accuracy: 0.8283 - val_loss: 0.4448 - val_accuracy: 0.8623\n",
      "Epoch 9/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.5260 - accuracy: 0.8377 - val_loss: 0.4925 - val_accuracy: 0.8527\n",
      "Epoch 10/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.5025 - accuracy: 0.8453 - val_loss: 0.4152 - val_accuracy: 0.8659\n",
      "Epoch 11/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.4755 - accuracy: 0.8531 - val_loss: 0.3674 - val_accuracy: 0.8815\n",
      "Epoch 12/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.4546 - accuracy: 0.8590 - val_loss: 0.3680 - val_accuracy: 0.8858\n",
      "Epoch 13/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.4418 - accuracy: 0.8637 - val_loss: 0.4007 - val_accuracy: 0.8721\n",
      "Epoch 14/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.4247 - accuracy: 0.8702 - val_loss: 0.3375 - val_accuracy: 0.8909\n",
      "Epoch 15/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.4091 - accuracy: 0.8729 - val_loss: 0.3626 - val_accuracy: 0.8858\n",
      "Epoch 16/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.3980 - accuracy: 0.8779 - val_loss: 0.3209 - val_accuracy: 0.8970\n",
      "Epoch 17/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.3844 - accuracy: 0.8825 - val_loss: 0.3088 - val_accuracy: 0.9025\n",
      "Epoch 18/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.3820 - accuracy: 0.8818 - val_loss: 0.2898 - val_accuracy: 0.9071\n",
      "Epoch 19/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3704 - accuracy: 0.8826 - val_loss: 0.2970 - val_accuracy: 0.9048\n",
      "Epoch 20/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3564 - accuracy: 0.8871 - val_loss: 0.2947 - val_accuracy: 0.9064\n",
      "Epoch 21/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3483 - accuracy: 0.8893 - val_loss: 0.2822 - val_accuracy: 0.9117\n",
      "Epoch 22/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.3426 - accuracy: 0.8927 - val_loss: 0.2825 - val_accuracy: 0.9067\n",
      "Epoch 23/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3316 - accuracy: 0.8933 - val_loss: 0.2634 - val_accuracy: 0.9144\n",
      "Epoch 24/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.3275 - accuracy: 0.8959 - val_loss: 0.2732 - val_accuracy: 0.9131\n",
      "Epoch 25/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3219 - accuracy: 0.8972 - val_loss: 0.2581 - val_accuracy: 0.9220\n",
      "Epoch 26/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.3182 - accuracy: 0.8988 - val_loss: 0.2626 - val_accuracy: 0.9154\n",
      "Epoch 27/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.3071 - accuracy: 0.9039 - val_loss: 0.2605 - val_accuracy: 0.9165\n",
      "Epoch 28/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2996 - accuracy: 0.9049 - val_loss: 0.2524 - val_accuracy: 0.9211\n",
      "Epoch 29/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.3009 - accuracy: 0.9044 - val_loss: 0.2771 - val_accuracy: 0.9083\n",
      "Epoch 30/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2946 - accuracy: 0.9061 - val_loss: 0.2840 - val_accuracy: 0.9158\n",
      "Epoch 31/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2896 - accuracy: 0.9079 - val_loss: 0.2566 - val_accuracy: 0.9197\n",
      "Epoch 32/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2846 - accuracy: 0.9082 - val_loss: 0.2569 - val_accuracy: 0.9158\n",
      "Epoch 33/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2813 - accuracy: 0.9097 - val_loss: 0.2734 - val_accuracy: 0.9131\n",
      "Epoch 34/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2726 - accuracy: 0.9137 - val_loss: 0.2564 - val_accuracy: 0.9181\n",
      "Epoch 35/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2780 - accuracy: 0.9095 - val_loss: 0.2541 - val_accuracy: 0.9174\n",
      "Epoch 36/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2739 - accuracy: 0.9108 - val_loss: 0.2687 - val_accuracy: 0.9160\n",
      "Epoch 37/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2632 - accuracy: 0.9154 - val_loss: 0.2642 - val_accuracy: 0.9160\n",
      "Epoch 38/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2626 - accuracy: 0.9158 - val_loss: 0.2520 - val_accuracy: 0.9222\n",
      "Epoch 39/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2632 - accuracy: 0.9143 - val_loss: 0.2436 - val_accuracy: 0.9224\n",
      "Epoch 40/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2588 - accuracy: 0.9179 - val_loss: 0.2613 - val_accuracy: 0.9149\n",
      "Epoch 41/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2547 - accuracy: 0.9180 - val_loss: 0.2469 - val_accuracy: 0.9206\n",
      "Epoch 42/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2528 - accuracy: 0.9189 - val_loss: 0.2421 - val_accuracy: 0.9234\n",
      "Epoch 43/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2523 - accuracy: 0.9192 - val_loss: 0.2630 - val_accuracy: 0.9140\n",
      "Epoch 44/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2489 - accuracy: 0.9199 - val_loss: 0.2518 - val_accuracy: 0.9163\n",
      "Epoch 45/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2481 - accuracy: 0.9192 - val_loss: 0.2349 - val_accuracy: 0.9240\n",
      "Epoch 46/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2438 - accuracy: 0.9199 - val_loss: 0.2878 - val_accuracy: 0.9158\n",
      "Epoch 47/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2364 - accuracy: 0.9241 - val_loss: 0.2543 - val_accuracy: 0.9247\n",
      "Epoch 48/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2386 - accuracy: 0.9219 - val_loss: 0.2350 - val_accuracy: 0.9263\n",
      "Epoch 49/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2340 - accuracy: 0.9236 - val_loss: 0.2528 - val_accuracy: 0.9188\n",
      "Epoch 50/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2313 - accuracy: 0.9238 - val_loss: 0.2476 - val_accuracy: 0.9204\n",
      "Epoch 51/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2251 - accuracy: 0.9252 - val_loss: 0.2409 - val_accuracy: 0.9261\n",
      "Epoch 52/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2315 - accuracy: 0.9243 - val_loss: 0.2334 - val_accuracy: 0.9234\n",
      "Epoch 53/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2258 - accuracy: 0.9268 - val_loss: 0.2592 - val_accuracy: 0.9231\n",
      "Epoch 54/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2219 - accuracy: 0.9272 - val_loss: 0.2669 - val_accuracy: 0.9190\n",
      "Epoch 55/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2250 - accuracy: 0.9267 - val_loss: 0.2308 - val_accuracy: 0.9272\n",
      "Epoch 56/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2216 - accuracy: 0.9263 - val_loss: 0.2428 - val_accuracy: 0.9231\n",
      "Epoch 57/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2166 - accuracy: 0.9277 - val_loss: 0.2286 - val_accuracy: 0.9268\n",
      "Epoch 58/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2152 - accuracy: 0.9287 - val_loss: 0.2394 - val_accuracy: 0.9279\n",
      "Epoch 59/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2148 - accuracy: 0.9302 - val_loss: 0.2527 - val_accuracy: 0.9224\n",
      "Epoch 60/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2145 - accuracy: 0.9298 - val_loss: 0.2260 - val_accuracy: 0.9270\n",
      "Epoch 61/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2101 - accuracy: 0.9314 - val_loss: 0.2344 - val_accuracy: 0.9277\n",
      "Epoch 62/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2107 - accuracy: 0.9313 - val_loss: 0.2316 - val_accuracy: 0.9284\n",
      "Epoch 63/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2055 - accuracy: 0.9317 - val_loss: 0.2426 - val_accuracy: 0.9263\n",
      "Epoch 64/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2062 - accuracy: 0.9318 - val_loss: 0.2766 - val_accuracy: 0.9167\n",
      "Epoch 65/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2001 - accuracy: 0.9333 - val_loss: 0.2267 - val_accuracy: 0.9293\n",
      "Epoch 66/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2035 - accuracy: 0.9326 - val_loss: 0.2433 - val_accuracy: 0.9245\n",
      "Epoch 67/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.2001 - accuracy: 0.9333 - val_loss: 0.2373 - val_accuracy: 0.9284\n",
      "Epoch 68/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.2011 - accuracy: 0.9315 - val_loss: 0.2323 - val_accuracy: 0.9286\n",
      "Epoch 69/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.2007 - accuracy: 0.9339 - val_loss: 0.2411 - val_accuracy: 0.9288\n",
      "Epoch 70/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1937 - accuracy: 0.9367 - val_loss: 0.2239 - val_accuracy: 0.9327\n",
      "Epoch 71/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1931 - accuracy: 0.9349 - val_loss: 0.2324 - val_accuracy: 0.9250\n",
      "Epoch 72/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1955 - accuracy: 0.9367 - val_loss: 0.2555 - val_accuracy: 0.9192\n",
      "Epoch 73/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1927 - accuracy: 0.9363 - val_loss: 0.2300 - val_accuracy: 0.9311\n",
      "Epoch 74/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1896 - accuracy: 0.9373 - val_loss: 0.2444 - val_accuracy: 0.9256\n",
      "Epoch 75/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1883 - accuracy: 0.9370 - val_loss: 0.2315 - val_accuracy: 0.9318\n",
      "Epoch 76/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1924 - accuracy: 0.9365 - val_loss: 0.2285 - val_accuracy: 0.9305\n",
      "Epoch 77/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1842 - accuracy: 0.9384 - val_loss: 0.2440 - val_accuracy: 0.9284\n",
      "Epoch 78/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1851 - accuracy: 0.9390 - val_loss: 0.2326 - val_accuracy: 0.9302\n",
      "Epoch 79/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1843 - accuracy: 0.9386 - val_loss: 0.2398 - val_accuracy: 0.9279\n",
      "Epoch 80/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1812 - accuracy: 0.9390 - val_loss: 0.2275 - val_accuracy: 0.9302\n",
      "Epoch 81/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1866 - accuracy: 0.9385 - val_loss: 0.2327 - val_accuracy: 0.9268\n",
      "Epoch 82/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1799 - accuracy: 0.9407 - val_loss: 0.2249 - val_accuracy: 0.9337\n",
      "Epoch 83/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1795 - accuracy: 0.9403 - val_loss: 0.2446 - val_accuracy: 0.9279\n",
      "Epoch 84/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1774 - accuracy: 0.9399 - val_loss: 0.2406 - val_accuracy: 0.9270\n",
      "Epoch 85/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1753 - accuracy: 0.9424 - val_loss: 0.2461 - val_accuracy: 0.9286\n",
      "Epoch 86/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1779 - accuracy: 0.9396 - val_loss: 0.2303 - val_accuracy: 0.9314\n",
      "Epoch 87/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1713 - accuracy: 0.9420 - val_loss: 0.2392 - val_accuracy: 0.9291\n",
      "Epoch 88/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1709 - accuracy: 0.9414 - val_loss: 0.2443 - val_accuracy: 0.9266\n",
      "Epoch 89/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1706 - accuracy: 0.9429 - val_loss: 0.2325 - val_accuracy: 0.9307\n",
      "Epoch 90/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1730 - accuracy: 0.9424 - val_loss: 0.2311 - val_accuracy: 0.9327\n",
      "Epoch 91/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1714 - accuracy: 0.9435 - val_loss: 0.2390 - val_accuracy: 0.9309\n",
      "Epoch 92/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1730 - accuracy: 0.9423 - val_loss: 0.2450 - val_accuracy: 0.9231\n",
      "Epoch 93/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1653 - accuracy: 0.9454 - val_loss: 0.2277 - val_accuracy: 0.9357\n",
      "Epoch 94/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1629 - accuracy: 0.9448 - val_loss: 0.2393 - val_accuracy: 0.9266\n",
      "Epoch 95/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1687 - accuracy: 0.9444 - val_loss: 0.2458 - val_accuracy: 0.9318\n",
      "Epoch 96/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1684 - accuracy: 0.9444 - val_loss: 0.2391 - val_accuracy: 0.9330\n",
      "Epoch 97/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1681 - accuracy: 0.9441 - val_loss: 0.2419 - val_accuracy: 0.9300\n",
      "Epoch 98/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1639 - accuracy: 0.9461 - val_loss: 0.2420 - val_accuracy: 0.9307\n",
      "Epoch 99/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1617 - accuracy: 0.9463 - val_loss: 0.2404 - val_accuracy: 0.9323\n",
      "Epoch 100/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1620 - accuracy: 0.9454 - val_loss: 0.2332 - val_accuracy: 0.9316\n",
      "Epoch 101/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1567 - accuracy: 0.9468 - val_loss: 0.2409 - val_accuracy: 0.9316\n",
      "Epoch 102/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1613 - accuracy: 0.9458 - val_loss: 0.2397 - val_accuracy: 0.9302\n",
      "Epoch 103/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1621 - accuracy: 0.9457 - val_loss: 0.2501 - val_accuracy: 0.9300\n",
      "Epoch 104/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1621 - accuracy: 0.9457 - val_loss: 0.2333 - val_accuracy: 0.9332\n",
      "Epoch 105/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1538 - accuracy: 0.9481 - val_loss: 0.2506 - val_accuracy: 0.9305\n",
      "Epoch 106/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1561 - accuracy: 0.9480 - val_loss: 0.2505 - val_accuracy: 0.9268\n",
      "Epoch 107/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1613 - accuracy: 0.9444 - val_loss: 0.2615 - val_accuracy: 0.9222\n",
      "Epoch 108/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1534 - accuracy: 0.9486 - val_loss: 0.2342 - val_accuracy: 0.9307\n",
      "Epoch 109/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1549 - accuracy: 0.9478 - val_loss: 0.2479 - val_accuracy: 0.9293\n",
      "Epoch 110/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1502 - accuracy: 0.9504 - val_loss: 0.2313 - val_accuracy: 0.9346\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1531 - accuracy: 0.9497 - val_loss: 0.2260 - val_accuracy: 0.9311\n",
      "Epoch 112/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1528 - accuracy: 0.9498 - val_loss: 0.2446 - val_accuracy: 0.9279\n",
      "Epoch 113/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1556 - accuracy: 0.9485 - val_loss: 0.2495 - val_accuracy: 0.9284\n",
      "Epoch 114/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1513 - accuracy: 0.9494 - val_loss: 0.2310 - val_accuracy: 0.9348\n",
      "Epoch 115/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1473 - accuracy: 0.9509 - val_loss: 0.2276 - val_accuracy: 0.9314\n",
      "Epoch 116/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1522 - accuracy: 0.9486 - val_loss: 0.2419 - val_accuracy: 0.9307\n",
      "Epoch 117/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1479 - accuracy: 0.9502 - val_loss: 0.2466 - val_accuracy: 0.9309\n",
      "Epoch 118/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1495 - accuracy: 0.9487 - val_loss: 0.2336 - val_accuracy: 0.9346\n",
      "Epoch 119/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1437 - accuracy: 0.9514 - val_loss: 0.2457 - val_accuracy: 0.9316\n",
      "Epoch 120/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1451 - accuracy: 0.9525 - val_loss: 0.2471 - val_accuracy: 0.9302\n",
      "Epoch 121/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1426 - accuracy: 0.9511 - val_loss: 0.2473 - val_accuracy: 0.9302\n",
      "Epoch 122/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1454 - accuracy: 0.9501 - val_loss: 0.2311 - val_accuracy: 0.9364\n",
      "Epoch 123/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1417 - accuracy: 0.9522 - val_loss: 0.2455 - val_accuracy: 0.9332\n",
      "Epoch 124/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1445 - accuracy: 0.9512 - val_loss: 0.2387 - val_accuracy: 0.9330\n",
      "Epoch 125/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1428 - accuracy: 0.9519 - val_loss: 0.2551 - val_accuracy: 0.9307\n",
      "Epoch 126/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1428 - accuracy: 0.9508 - val_loss: 0.2594 - val_accuracy: 0.9272\n",
      "Epoch 127/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1420 - accuracy: 0.9520 - val_loss: 0.2427 - val_accuracy: 0.9302\n",
      "Epoch 128/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1462 - accuracy: 0.9505 - val_loss: 0.2412 - val_accuracy: 0.9300\n",
      "Epoch 129/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1375 - accuracy: 0.9538 - val_loss: 0.2496 - val_accuracy: 0.9341\n",
      "Epoch 130/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1398 - accuracy: 0.9526 - val_loss: 0.2335 - val_accuracy: 0.9343\n",
      "Epoch 131/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1381 - accuracy: 0.9535 - val_loss: 0.2598 - val_accuracy: 0.9234\n",
      "Epoch 132/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1398 - accuracy: 0.9513 - val_loss: 0.2516 - val_accuracy: 0.9302\n",
      "Epoch 133/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1366 - accuracy: 0.9537 - val_loss: 0.2455 - val_accuracy: 0.9307\n",
      "Epoch 134/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1377 - accuracy: 0.9532 - val_loss: 0.2467 - val_accuracy: 0.9307\n",
      "Epoch 135/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1362 - accuracy: 0.9537 - val_loss: 0.2425 - val_accuracy: 0.9325\n",
      "Epoch 136/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1341 - accuracy: 0.9546 - val_loss: 0.2342 - val_accuracy: 0.9330\n",
      "Epoch 137/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1433 - accuracy: 0.9515 - val_loss: 0.2530 - val_accuracy: 0.9323\n",
      "Epoch 138/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1372 - accuracy: 0.9538 - val_loss: 0.2438 - val_accuracy: 0.9298\n",
      "Epoch 139/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1337 - accuracy: 0.9550 - val_loss: 0.2493 - val_accuracy: 0.9311\n",
      "Epoch 140/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1353 - accuracy: 0.9553 - val_loss: 0.2435 - val_accuracy: 0.9295\n",
      "Epoch 141/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1298 - accuracy: 0.9564 - val_loss: 0.2341 - val_accuracy: 0.9382\n",
      "Epoch 142/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1337 - accuracy: 0.9544 - val_loss: 0.2603 - val_accuracy: 0.9272\n",
      "Epoch 143/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1341 - accuracy: 0.9552 - val_loss: 0.2412 - val_accuracy: 0.9350\n",
      "Epoch 144/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1320 - accuracy: 0.9556 - val_loss: 0.2424 - val_accuracy: 0.9339\n",
      "Epoch 145/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1337 - accuracy: 0.9543 - val_loss: 0.2461 - val_accuracy: 0.9318\n",
      "Epoch 146/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1255 - accuracy: 0.9573 - val_loss: 0.2599 - val_accuracy: 0.9302\n",
      "Epoch 147/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1329 - accuracy: 0.9546 - val_loss: 0.2559 - val_accuracy: 0.9314\n",
      "Epoch 148/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1310 - accuracy: 0.9557 - val_loss: 0.2532 - val_accuracy: 0.9325\n",
      "Epoch 149/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1319 - accuracy: 0.9564 - val_loss: 0.2513 - val_accuracy: 0.9284\n",
      "Epoch 150/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1312 - accuracy: 0.9555 - val_loss: 0.2337 - val_accuracy: 0.9302\n",
      "Epoch 151/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1294 - accuracy: 0.9558 - val_loss: 0.2451 - val_accuracy: 0.9318\n",
      "Epoch 152/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1325 - accuracy: 0.9554 - val_loss: 0.2527 - val_accuracy: 0.9291\n",
      "Epoch 153/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1254 - accuracy: 0.9574 - val_loss: 0.2531 - val_accuracy: 0.9327\n",
      "Epoch 154/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1317 - accuracy: 0.9547 - val_loss: 0.2482 - val_accuracy: 0.9327\n",
      "Epoch 155/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1270 - accuracy: 0.9561 - val_loss: 0.2592 - val_accuracy: 0.9311\n",
      "Epoch 156/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1267 - accuracy: 0.9559 - val_loss: 0.2622 - val_accuracy: 0.9298\n",
      "Epoch 157/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1222 - accuracy: 0.9577 - val_loss: 0.2558 - val_accuracy: 0.9309\n",
      "Epoch 158/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1239 - accuracy: 0.9575 - val_loss: 0.2541 - val_accuracy: 0.9353\n",
      "Epoch 159/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1231 - accuracy: 0.9579 - val_loss: 0.2537 - val_accuracy: 0.9316\n",
      "Epoch 160/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1274 - accuracy: 0.9564 - val_loss: 0.2382 - val_accuracy: 0.9323\n",
      "Epoch 161/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1250 - accuracy: 0.9582 - val_loss: 0.2457 - val_accuracy: 0.9321\n",
      "Epoch 162/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1259 - accuracy: 0.9570 - val_loss: 0.2571 - val_accuracy: 0.9327\n",
      "Epoch 163/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1238 - accuracy: 0.9584 - val_loss: 0.2693 - val_accuracy: 0.9300\n",
      "Epoch 164/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1225 - accuracy: 0.9579 - val_loss: 0.2646 - val_accuracy: 0.9298\n",
      "Epoch 165/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1249 - accuracy: 0.9567 - val_loss: 0.2501 - val_accuracy: 0.9341\n",
      "Epoch 166/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1207 - accuracy: 0.9588 - val_loss: 0.2579 - val_accuracy: 0.9300\n",
      "Epoch 167/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1239 - accuracy: 0.9583 - val_loss: 0.2464 - val_accuracy: 0.9355\n",
      "Epoch 168/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1205 - accuracy: 0.9590 - val_loss: 0.2629 - val_accuracy: 0.9288\n",
      "Epoch 169/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1178 - accuracy: 0.9592 - val_loss: 0.2578 - val_accuracy: 0.9330\n",
      "Epoch 170/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1203 - accuracy: 0.9594 - val_loss: 0.2534 - val_accuracy: 0.9341\n",
      "Epoch 171/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1166 - accuracy: 0.9603 - val_loss: 0.2576 - val_accuracy: 0.9314\n",
      "Epoch 172/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1170 - accuracy: 0.9606 - val_loss: 0.2548 - val_accuracy: 0.9341\n",
      "Epoch 173/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1229 - accuracy: 0.9591 - val_loss: 0.2475 - val_accuracy: 0.9334\n",
      "Epoch 174/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1217 - accuracy: 0.9585 - val_loss: 0.2745 - val_accuracy: 0.9309\n",
      "Epoch 175/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1218 - accuracy: 0.9583 - val_loss: 0.2621 - val_accuracy: 0.9327\n",
      "Epoch 176/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1176 - accuracy: 0.9603 - val_loss: 0.2530 - val_accuracy: 0.9309\n",
      "Epoch 177/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1174 - accuracy: 0.9609 - val_loss: 0.2560 - val_accuracy: 0.9327\n",
      "Epoch 178/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1131 - accuracy: 0.9615 - val_loss: 0.2436 - val_accuracy: 0.9327\n",
      "Epoch 179/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1207 - accuracy: 0.9592 - val_loss: 0.2403 - val_accuracy: 0.9371\n",
      "Epoch 180/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1143 - accuracy: 0.9611 - val_loss: 0.2509 - val_accuracy: 0.9330\n",
      "Epoch 181/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1173 - accuracy: 0.9603 - val_loss: 0.2622 - val_accuracy: 0.9305\n",
      "Epoch 182/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1149 - accuracy: 0.9601 - val_loss: 0.2606 - val_accuracy: 0.9318\n",
      "Epoch 183/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1166 - accuracy: 0.9599 - val_loss: 0.2520 - val_accuracy: 0.9311\n",
      "Epoch 184/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1165 - accuracy: 0.9608 - val_loss: 0.2811 - val_accuracy: 0.9288\n",
      "Epoch 185/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1148 - accuracy: 0.9614 - val_loss: 0.2532 - val_accuracy: 0.9300\n",
      "Epoch 186/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1149 - accuracy: 0.9607 - val_loss: 0.2540 - val_accuracy: 0.9334\n",
      "Epoch 187/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1166 - accuracy: 0.9610 - val_loss: 0.2549 - val_accuracy: 0.9311\n",
      "Epoch 188/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.1124 - accuracy: 0.9619 - val_loss: 0.2530 - val_accuracy: 0.9346\n",
      "Epoch 189/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1137 - accuracy: 0.9613 - val_loss: 0.2602 - val_accuracy: 0.9330\n",
      "Epoch 190/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1096 - accuracy: 0.9626 - val_loss: 0.2618 - val_accuracy: 0.9295\n",
      "Epoch 191/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1108 - accuracy: 0.9614 - val_loss: 0.2550 - val_accuracy: 0.9327\n",
      "Epoch 192/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1106 - accuracy: 0.9626 - val_loss: 0.2500 - val_accuracy: 0.9350\n",
      "Epoch 193/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1134 - accuracy: 0.9620 - val_loss: 0.2473 - val_accuracy: 0.9359\n",
      "Epoch 194/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1107 - accuracy: 0.9623 - val_loss: 0.2548 - val_accuracy: 0.9348\n",
      "Epoch 195/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1082 - accuracy: 0.9626 - val_loss: 0.2620 - val_accuracy: 0.9316\n",
      "Epoch 196/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1103 - accuracy: 0.9638 - val_loss: 0.2543 - val_accuracy: 0.9309\n",
      "Epoch 197/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1069 - accuracy: 0.9628 - val_loss: 0.2535 - val_accuracy: 0.9325\n",
      "Epoch 198/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1081 - accuracy: 0.9633 - val_loss: 0.2608 - val_accuracy: 0.9305\n",
      "Epoch 199/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1057 - accuracy: 0.9643 - val_loss: 0.2527 - val_accuracy: 0.9359\n",
      "Epoch 200/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1077 - accuracy: 0.9637 - val_loss: 0.2478 - val_accuracy: 0.9364\n",
      "Epoch 201/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1047 - accuracy: 0.9645 - val_loss: 0.2777 - val_accuracy: 0.9261\n",
      "Epoch 202/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1072 - accuracy: 0.9641 - val_loss: 0.2659 - val_accuracy: 0.9318\n",
      "Epoch 203/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1107 - accuracy: 0.9617 - val_loss: 0.2580 - val_accuracy: 0.9311\n",
      "Epoch 204/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1059 - accuracy: 0.9635 - val_loss: 0.2545 - val_accuracy: 0.9346\n",
      "Epoch 205/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1070 - accuracy: 0.9632 - val_loss: 0.2628 - val_accuracy: 0.9286\n",
      "Epoch 206/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1073 - accuracy: 0.9645 - val_loss: 0.2616 - val_accuracy: 0.9321\n",
      "Epoch 207/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1054 - accuracy: 0.9649 - val_loss: 0.2536 - val_accuracy: 0.9348\n",
      "Epoch 208/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1045 - accuracy: 0.9646 - val_loss: 0.2602 - val_accuracy: 0.9334\n",
      "Epoch 209/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1090 - accuracy: 0.9619 - val_loss: 0.2685 - val_accuracy: 0.9311\n",
      "Epoch 210/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1000 - accuracy: 0.9648 - val_loss: 0.2803 - val_accuracy: 0.9298\n",
      "Epoch 211/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1047 - accuracy: 0.9641 - val_loss: 0.2858 - val_accuracy: 0.9311\n",
      "Epoch 212/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1014 - accuracy: 0.9653 - val_loss: 0.2658 - val_accuracy: 0.9318\n",
      "Epoch 213/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1027 - accuracy: 0.9649 - val_loss: 0.2678 - val_accuracy: 0.9305\n",
      "Epoch 214/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1013 - accuracy: 0.9654 - val_loss: 0.2674 - val_accuracy: 0.9305\n",
      "Epoch 215/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1031 - accuracy: 0.9640 - val_loss: 0.2640 - val_accuracy: 0.9332\n",
      "Epoch 216/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1039 - accuracy: 0.9649 - val_loss: 0.2654 - val_accuracy: 0.9300\n",
      "Epoch 217/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1081 - accuracy: 0.9641 - val_loss: 0.2723 - val_accuracy: 0.9325\n",
      "Epoch 218/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1067 - accuracy: 0.9635 - val_loss: 0.2472 - val_accuracy: 0.9332\n",
      "Epoch 219/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0990 - accuracy: 0.9659 - val_loss: 0.2629 - val_accuracy: 0.9298\n",
      "Epoch 220/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1024 - accuracy: 0.9647 - val_loss: 0.2797 - val_accuracy: 0.9263\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1025 - accuracy: 0.9660 - val_loss: 0.2724 - val_accuracy: 0.9330\n",
      "Epoch 222/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1031 - accuracy: 0.9643 - val_loss: 0.2764 - val_accuracy: 0.9286\n",
      "Epoch 223/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0994 - accuracy: 0.9662 - val_loss: 0.2686 - val_accuracy: 0.9307\n",
      "Epoch 224/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1004 - accuracy: 0.9652 - val_loss: 0.2604 - val_accuracy: 0.9300\n",
      "Epoch 225/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1005 - accuracy: 0.9655 - val_loss: 0.2658 - val_accuracy: 0.9348\n",
      "Epoch 226/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1015 - accuracy: 0.9665 - val_loss: 0.2710 - val_accuracy: 0.9325\n",
      "Epoch 227/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1027 - accuracy: 0.9653 - val_loss: 0.2584 - val_accuracy: 0.9314\n",
      "Epoch 228/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0985 - accuracy: 0.9671 - val_loss: 0.2869 - val_accuracy: 0.9307\n",
      "Epoch 229/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1035 - accuracy: 0.9653 - val_loss: 0.2619 - val_accuracy: 0.9302\n",
      "Epoch 230/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1007 - accuracy: 0.9654 - val_loss: 0.2920 - val_accuracy: 0.9286\n",
      "Epoch 231/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0965 - accuracy: 0.9674 - val_loss: 0.2799 - val_accuracy: 0.9327\n",
      "Epoch 232/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0992 - accuracy: 0.9659 - val_loss: 0.2722 - val_accuracy: 0.9337\n",
      "Epoch 233/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1004 - accuracy: 0.9656 - val_loss: 0.2935 - val_accuracy: 0.9291\n",
      "Epoch 234/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1018 - accuracy: 0.9649 - val_loss: 0.2922 - val_accuracy: 0.9302\n",
      "Epoch 235/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0979 - accuracy: 0.9663 - val_loss: 0.2861 - val_accuracy: 0.9307\n",
      "Epoch 236/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0987 - accuracy: 0.9669 - val_loss: 0.2616 - val_accuracy: 0.9302\n",
      "Epoch 237/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0975 - accuracy: 0.9667 - val_loss: 0.2762 - val_accuracy: 0.9311\n",
      "Epoch 238/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0969 - accuracy: 0.9673 - val_loss: 0.2811 - val_accuracy: 0.9334\n",
      "Epoch 239/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0954 - accuracy: 0.9682 - val_loss: 0.2790 - val_accuracy: 0.9314\n",
      "Epoch 240/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0979 - accuracy: 0.9655 - val_loss: 0.2750 - val_accuracy: 0.9327\n",
      "Epoch 241/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1012 - accuracy: 0.9648 - val_loss: 0.2777 - val_accuracy: 0.9270\n",
      "Epoch 242/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0939 - accuracy: 0.9676 - val_loss: 0.2831 - val_accuracy: 0.9327\n",
      "Epoch 243/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0971 - accuracy: 0.9671 - val_loss: 0.2906 - val_accuracy: 0.9330\n",
      "Epoch 244/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0952 - accuracy: 0.9665 - val_loss: 0.2629 - val_accuracy: 0.9362\n",
      "Epoch 245/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0944 - accuracy: 0.9677 - val_loss: 0.2816 - val_accuracy: 0.9337\n",
      "Epoch 246/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.2881 - val_accuracy: 0.9298\n",
      "Epoch 247/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.1033 - accuracy: 0.9654 - val_loss: 0.2755 - val_accuracy: 0.9307\n",
      "Epoch 248/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0953 - accuracy: 0.9685 - val_loss: 0.2756 - val_accuracy: 0.9314\n",
      "Epoch 249/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0988 - accuracy: 0.9671 - val_loss: 0.2793 - val_accuracy: 0.9337\n",
      "Epoch 250/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0952 - accuracy: 0.9680 - val_loss: 0.2883 - val_accuracy: 0.9288\n",
      "Epoch 251/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0932 - accuracy: 0.9673 - val_loss: 0.3005 - val_accuracy: 0.9311\n",
      "Epoch 252/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.1026 - accuracy: 0.9651 - val_loss: 0.2850 - val_accuracy: 0.9300\n",
      "Epoch 253/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0970 - accuracy: 0.9665 - val_loss: 0.2819 - val_accuracy: 0.9318\n",
      "Epoch 254/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0918 - accuracy: 0.9686 - val_loss: 0.2959 - val_accuracy: 0.9314\n",
      "Epoch 255/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0939 - accuracy: 0.9674 - val_loss: 0.2836 - val_accuracy: 0.9346\n",
      "Epoch 256/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0946 - accuracy: 0.9685 - val_loss: 0.2871 - val_accuracy: 0.9298\n",
      "Epoch 257/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0918 - accuracy: 0.9685 - val_loss: 0.2850 - val_accuracy: 0.9311\n",
      "Epoch 258/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0894 - accuracy: 0.9695 - val_loss: 0.2898 - val_accuracy: 0.9318\n",
      "Epoch 259/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0887 - accuracy: 0.9685 - val_loss: 0.2783 - val_accuracy: 0.9309\n",
      "Epoch 260/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0933 - accuracy: 0.9674 - val_loss: 0.2822 - val_accuracy: 0.9337\n",
      "Epoch 261/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0931 - accuracy: 0.9682 - val_loss: 0.2909 - val_accuracy: 0.9339\n",
      "Epoch 262/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0930 - accuracy: 0.9688 - val_loss: 0.2802 - val_accuracy: 0.9284\n",
      "Epoch 263/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0935 - accuracy: 0.9687 - val_loss: 0.2892 - val_accuracy: 0.9323\n",
      "Epoch 264/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0887 - accuracy: 0.9711 - val_loss: 0.2912 - val_accuracy: 0.9327\n",
      "Epoch 265/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0954 - accuracy: 0.9676 - val_loss: 0.2808 - val_accuracy: 0.9348\n",
      "Epoch 266/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0918 - accuracy: 0.9686 - val_loss: 0.2659 - val_accuracy: 0.9369\n",
      "Epoch 267/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0922 - accuracy: 0.9694 - val_loss: 0.2728 - val_accuracy: 0.9366\n",
      "Epoch 268/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0896 - accuracy: 0.9697 - val_loss: 0.2767 - val_accuracy: 0.9302\n",
      "Epoch 269/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0948 - accuracy: 0.9679 - val_loss: 0.2688 - val_accuracy: 0.9371\n",
      "Epoch 270/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0913 - accuracy: 0.9692 - val_loss: 0.2815 - val_accuracy: 0.9339\n",
      "Epoch 271/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.2841 - val_accuracy: 0.9295\n",
      "Epoch 272/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0898 - accuracy: 0.9700 - val_loss: 0.3000 - val_accuracy: 0.9268\n",
      "Epoch 273/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0901 - accuracy: 0.9684 - val_loss: 0.2841 - val_accuracy: 0.9323\n",
      "Epoch 274/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0903 - accuracy: 0.9693 - val_loss: 0.2786 - val_accuracy: 0.9318\n",
      "Epoch 275/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0877 - accuracy: 0.9693 - val_loss: 0.2929 - val_accuracy: 0.9325\n",
      "Epoch 276/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0927 - accuracy: 0.9685 - val_loss: 0.2874 - val_accuracy: 0.9327\n",
      "Epoch 277/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0902 - accuracy: 0.9694 - val_loss: 0.2766 - val_accuracy: 0.9307\n",
      "Epoch 278/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0883 - accuracy: 0.9697 - val_loss: 0.2748 - val_accuracy: 0.9316\n",
      "Epoch 279/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0885 - accuracy: 0.9701 - val_loss: 0.2913 - val_accuracy: 0.9288\n",
      "Epoch 280/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0894 - accuracy: 0.9698 - val_loss: 0.2996 - val_accuracy: 0.9305\n",
      "Epoch 281/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0895 - accuracy: 0.9691 - val_loss: 0.2897 - val_accuracy: 0.9339\n",
      "Epoch 282/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0877 - accuracy: 0.9702 - val_loss: 0.2832 - val_accuracy: 0.9339\n",
      "Epoch 283/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0908 - accuracy: 0.9695 - val_loss: 0.2870 - val_accuracy: 0.9291\n",
      "Epoch 284/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0823 - accuracy: 0.9713 - val_loss: 0.2958 - val_accuracy: 0.9300\n",
      "Epoch 285/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0863 - accuracy: 0.9710 - val_loss: 0.3050 - val_accuracy: 0.9305\n",
      "Epoch 286/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0869 - accuracy: 0.9704 - val_loss: 0.3011 - val_accuracy: 0.9348\n",
      "Epoch 287/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0860 - accuracy: 0.9705 - val_loss: 0.2960 - val_accuracy: 0.9309\n",
      "Epoch 288/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0907 - accuracy: 0.9675 - val_loss: 0.2908 - val_accuracy: 0.9311\n",
      "Epoch 289/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0882 - accuracy: 0.9699 - val_loss: 0.3042 - val_accuracy: 0.9252\n",
      "Epoch 290/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0875 - accuracy: 0.9708 - val_loss: 0.2885 - val_accuracy: 0.9307\n",
      "Epoch 291/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0910 - accuracy: 0.9681 - val_loss: 0.2996 - val_accuracy: 0.9314\n",
      "Epoch 292/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0891 - accuracy: 0.9702 - val_loss: 0.2968 - val_accuracy: 0.9293\n",
      "Epoch 293/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0891 - accuracy: 0.9698 - val_loss: 0.2880 - val_accuracy: 0.9284\n",
      "Epoch 294/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0837 - accuracy: 0.9725 - val_loss: 0.2826 - val_accuracy: 0.9339\n",
      "Epoch 295/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0867 - accuracy: 0.9705 - val_loss: 0.2766 - val_accuracy: 0.9298\n",
      "Epoch 296/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0872 - accuracy: 0.9704 - val_loss: 0.2841 - val_accuracy: 0.9321\n",
      "Epoch 297/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0849 - accuracy: 0.9705 - val_loss: 0.2807 - val_accuracy: 0.9298\n",
      "Epoch 298/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0883 - accuracy: 0.9697 - val_loss: 0.2844 - val_accuracy: 0.9318\n",
      "Epoch 299/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0855 - accuracy: 0.9709 - val_loss: 0.2823 - val_accuracy: 0.9300\n",
      "Epoch 300/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0834 - accuracy: 0.9710 - val_loss: 0.2742 - val_accuracy: 0.9341\n",
      "Epoch 301/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0839 - accuracy: 0.9706 - val_loss: 0.2845 - val_accuracy: 0.9353\n",
      "Epoch 302/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0876 - accuracy: 0.9703 - val_loss: 0.2771 - val_accuracy: 0.9325\n",
      "Epoch 303/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0846 - accuracy: 0.9706 - val_loss: 0.2792 - val_accuracy: 0.9309\n",
      "Epoch 304/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0821 - accuracy: 0.9721 - val_loss: 0.2832 - val_accuracy: 0.9314\n",
      "Epoch 305/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0838 - accuracy: 0.9711 - val_loss: 0.2762 - val_accuracy: 0.9332\n",
      "Epoch 306/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0841 - accuracy: 0.9712 - val_loss: 0.2929 - val_accuracy: 0.9318\n",
      "Epoch 307/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0847 - accuracy: 0.9714 - val_loss: 0.2810 - val_accuracy: 0.9343\n",
      "Epoch 308/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0837 - accuracy: 0.9721 - val_loss: 0.2878 - val_accuracy: 0.9323\n",
      "Epoch 309/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0844 - accuracy: 0.9717 - val_loss: 0.2792 - val_accuracy: 0.9309\n",
      "Epoch 310/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0836 - accuracy: 0.9719 - val_loss: 0.2936 - val_accuracy: 0.9279\n",
      "Epoch 311/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0833 - accuracy: 0.9714 - val_loss: 0.2948 - val_accuracy: 0.9284\n",
      "Epoch 312/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0867 - accuracy: 0.9696 - val_loss: 0.2893 - val_accuracy: 0.9325\n",
      "Epoch 313/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0831 - accuracy: 0.9714 - val_loss: 0.2831 - val_accuracy: 0.9323\n",
      "Epoch 314/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0814 - accuracy: 0.9726 - val_loss: 0.2979 - val_accuracy: 0.9309\n",
      "Epoch 315/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0808 - accuracy: 0.9717 - val_loss: 0.3074 - val_accuracy: 0.9300\n",
      "Epoch 316/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0784 - accuracy: 0.9727 - val_loss: 0.2933 - val_accuracy: 0.9332\n",
      "Epoch 317/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0805 - accuracy: 0.9735 - val_loss: 0.2886 - val_accuracy: 0.9325\n",
      "Epoch 318/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0829 - accuracy: 0.9714 - val_loss: 0.2868 - val_accuracy: 0.9321\n",
      "Epoch 319/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0803 - accuracy: 0.9729 - val_loss: 0.2956 - val_accuracy: 0.9327\n",
      "Epoch 320/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0826 - accuracy: 0.9726 - val_loss: 0.2937 - val_accuracy: 0.9314\n",
      "Epoch 321/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0806 - accuracy: 0.9724 - val_loss: 0.2994 - val_accuracy: 0.9332\n",
      "Epoch 322/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0846 - accuracy: 0.9710 - val_loss: 0.2829 - val_accuracy: 0.9332\n",
      "Epoch 323/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0826 - accuracy: 0.9725 - val_loss: 0.2992 - val_accuracy: 0.9311\n",
      "Epoch 324/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0817 - accuracy: 0.9714 - val_loss: 0.2877 - val_accuracy: 0.9339\n",
      "Epoch 325/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0816 - accuracy: 0.9712 - val_loss: 0.2960 - val_accuracy: 0.9325\n",
      "Epoch 326/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0816 - accuracy: 0.9719 - val_loss: 0.3000 - val_accuracy: 0.9325\n",
      "Epoch 327/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0807 - accuracy: 0.9728 - val_loss: 0.2954 - val_accuracy: 0.9305\n",
      "Epoch 328/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0791 - accuracy: 0.9734 - val_loss: 0.2810 - val_accuracy: 0.9302\n",
      "Epoch 329/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0803 - accuracy: 0.9732 - val_loss: 0.2861 - val_accuracy: 0.9314\n",
      "Epoch 330/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0785 - accuracy: 0.9733 - val_loss: 0.3070 - val_accuracy: 0.9291\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0808 - accuracy: 0.9725 - val_loss: 0.2861 - val_accuracy: 0.9307\n",
      "Epoch 332/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0803 - accuracy: 0.9726 - val_loss: 0.2796 - val_accuracy: 0.9321\n",
      "Epoch 333/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0804 - accuracy: 0.9726 - val_loss: 0.2862 - val_accuracy: 0.9330\n",
      "Epoch 334/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0760 - accuracy: 0.9740 - val_loss: 0.2945 - val_accuracy: 0.9323\n",
      "Epoch 335/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0778 - accuracy: 0.9732 - val_loss: 0.2973 - val_accuracy: 0.9284\n",
      "Epoch 336/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.2935 - val_accuracy: 0.9275\n",
      "Epoch 337/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0786 - accuracy: 0.9740 - val_loss: 0.2895 - val_accuracy: 0.9334\n",
      "Epoch 338/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0785 - accuracy: 0.9736 - val_loss: 0.3033 - val_accuracy: 0.9302\n",
      "Epoch 339/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0766 - accuracy: 0.9738 - val_loss: 0.3277 - val_accuracy: 0.9272\n",
      "Epoch 340/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0797 - accuracy: 0.9728 - val_loss: 0.2951 - val_accuracy: 0.9321\n",
      "Epoch 341/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0795 - accuracy: 0.9731 - val_loss: 0.2866 - val_accuracy: 0.9334\n",
      "Epoch 342/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0831 - accuracy: 0.9712 - val_loss: 0.2973 - val_accuracy: 0.9291\n",
      "Epoch 343/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0763 - accuracy: 0.9739 - val_loss: 0.3144 - val_accuracy: 0.9275\n",
      "Epoch 344/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0765 - accuracy: 0.9734 - val_loss: 0.3080 - val_accuracy: 0.9300\n",
      "Epoch 345/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0777 - accuracy: 0.9737 - val_loss: 0.2909 - val_accuracy: 0.9307\n",
      "Epoch 346/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0785 - accuracy: 0.9730 - val_loss: 0.3157 - val_accuracy: 0.9334\n",
      "Epoch 347/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0755 - accuracy: 0.9751 - val_loss: 0.3037 - val_accuracy: 0.9314\n",
      "Epoch 348/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0776 - accuracy: 0.9744 - val_loss: 0.2930 - val_accuracy: 0.9321\n",
      "Epoch 349/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0791 - accuracy: 0.9726 - val_loss: 0.2855 - val_accuracy: 0.9309\n",
      "Epoch 350/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0756 - accuracy: 0.9746 - val_loss: 0.2845 - val_accuracy: 0.9321\n",
      "Epoch 351/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0795 - accuracy: 0.9730 - val_loss: 0.3021 - val_accuracy: 0.9293\n",
      "Epoch 352/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0805 - accuracy: 0.9728 - val_loss: 0.2786 - val_accuracy: 0.9309\n",
      "Epoch 353/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0726 - accuracy: 0.9752 - val_loss: 0.2999 - val_accuracy: 0.9327\n",
      "Epoch 354/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0779 - accuracy: 0.9729 - val_loss: 0.2871 - val_accuracy: 0.9318\n",
      "Epoch 355/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0773 - accuracy: 0.9736 - val_loss: 0.2874 - val_accuracy: 0.9323\n",
      "Epoch 356/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0756 - accuracy: 0.9745 - val_loss: 0.2765 - val_accuracy: 0.9341\n",
      "Epoch 357/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0792 - accuracy: 0.9734 - val_loss: 0.2780 - val_accuracy: 0.9355\n",
      "Epoch 358/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0769 - accuracy: 0.9744 - val_loss: 0.3002 - val_accuracy: 0.9275\n",
      "Epoch 359/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0762 - accuracy: 0.9736 - val_loss: 0.2890 - val_accuracy: 0.9332\n",
      "Epoch 360/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0719 - accuracy: 0.9756 - val_loss: 0.3090 - val_accuracy: 0.9307\n",
      "Epoch 361/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0775 - accuracy: 0.9739 - val_loss: 0.2811 - val_accuracy: 0.9323\n",
      "Epoch 362/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0738 - accuracy: 0.9760 - val_loss: 0.2952 - val_accuracy: 0.9272\n",
      "Epoch 363/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0763 - accuracy: 0.9743 - val_loss: 0.2868 - val_accuracy: 0.9330\n",
      "Epoch 364/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0786 - accuracy: 0.9732 - val_loss: 0.2744 - val_accuracy: 0.9314\n",
      "Epoch 365/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0775 - accuracy: 0.9739 - val_loss: 0.2947 - val_accuracy: 0.9337\n",
      "Epoch 366/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0773 - accuracy: 0.9744 - val_loss: 0.2827 - val_accuracy: 0.9318\n",
      "Epoch 367/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0754 - accuracy: 0.9744 - val_loss: 0.2954 - val_accuracy: 0.9334\n",
      "Epoch 368/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0728 - accuracy: 0.9754 - val_loss: 0.2803 - val_accuracy: 0.9327\n",
      "Epoch 369/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0759 - accuracy: 0.9750 - val_loss: 0.2865 - val_accuracy: 0.9323\n",
      "Epoch 370/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0751 - accuracy: 0.9742 - val_loss: 0.3043 - val_accuracy: 0.9332\n",
      "Epoch 371/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0746 - accuracy: 0.9743 - val_loss: 0.2861 - val_accuracy: 0.9339\n",
      "Epoch 372/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0726 - accuracy: 0.9754 - val_loss: 0.3002 - val_accuracy: 0.9291\n",
      "Epoch 373/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0753 - accuracy: 0.9751 - val_loss: 0.2912 - val_accuracy: 0.9305\n",
      "Epoch 374/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0751 - accuracy: 0.9740 - val_loss: 0.3084 - val_accuracy: 0.9309\n",
      "Epoch 375/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0751 - accuracy: 0.9744 - val_loss: 0.2898 - val_accuracy: 0.9343\n",
      "Epoch 376/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0729 - accuracy: 0.9746 - val_loss: 0.2974 - val_accuracy: 0.9316\n",
      "Epoch 377/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0696 - accuracy: 0.9765 - val_loss: 0.2965 - val_accuracy: 0.9309\n",
      "Epoch 378/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0736 - accuracy: 0.9747 - val_loss: 0.3042 - val_accuracy: 0.9325\n",
      "Epoch 379/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0740 - accuracy: 0.9751 - val_loss: 0.3031 - val_accuracy: 0.9323\n",
      "Epoch 380/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0765 - accuracy: 0.9748 - val_loss: 0.3071 - val_accuracy: 0.9295\n",
      "Epoch 381/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0744 - accuracy: 0.9753 - val_loss: 0.2817 - val_accuracy: 0.9327\n",
      "Epoch 382/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.2887 - val_accuracy: 0.9348\n",
      "Epoch 383/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0755 - accuracy: 0.9748 - val_loss: 0.3178 - val_accuracy: 0.9266\n",
      "Epoch 384/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0702 - accuracy: 0.9759 - val_loss: 0.3150 - val_accuracy: 0.9300\n",
      "Epoch 385/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0747 - accuracy: 0.9750 - val_loss: 0.3003 - val_accuracy: 0.9318\n",
      "Epoch 386/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0712 - accuracy: 0.9759 - val_loss: 0.2863 - val_accuracy: 0.9355\n",
      "Epoch 387/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0725 - accuracy: 0.9762 - val_loss: 0.3119 - val_accuracy: 0.9275\n",
      "Epoch 388/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0734 - accuracy: 0.9752 - val_loss: 0.2869 - val_accuracy: 0.9332\n",
      "Epoch 389/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0746 - accuracy: 0.9748 - val_loss: 0.2933 - val_accuracy: 0.9350\n",
      "Epoch 390/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0744 - accuracy: 0.9748 - val_loss: 0.2917 - val_accuracy: 0.9321\n",
      "Epoch 391/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0703 - accuracy: 0.9755 - val_loss: 0.3127 - val_accuracy: 0.9327\n",
      "Epoch 392/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0720 - accuracy: 0.9755 - val_loss: 0.3019 - val_accuracy: 0.9298\n",
      "Epoch 393/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0721 - accuracy: 0.9755 - val_loss: 0.2936 - val_accuracy: 0.9357\n",
      "Epoch 394/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0735 - accuracy: 0.9744 - val_loss: 0.3007 - val_accuracy: 0.9327\n",
      "Epoch 395/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0741 - accuracy: 0.9742 - val_loss: 0.3048 - val_accuracy: 0.9305\n",
      "Epoch 396/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0707 - accuracy: 0.9762 - val_loss: 0.2930 - val_accuracy: 0.9337\n",
      "Epoch 397/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0766 - accuracy: 0.9733 - val_loss: 0.3041 - val_accuracy: 0.9311\n",
      "Epoch 398/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0692 - accuracy: 0.9773 - val_loss: 0.3094 - val_accuracy: 0.9327\n",
      "Epoch 399/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0702 - accuracy: 0.9758 - val_loss: 0.3164 - val_accuracy: 0.9318\n",
      "Epoch 400/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0698 - accuracy: 0.9754 - val_loss: 0.3064 - val_accuracy: 0.9318\n",
      "Epoch 401/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0707 - accuracy: 0.9757 - val_loss: 0.2957 - val_accuracy: 0.9323\n",
      "Epoch 402/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0682 - accuracy: 0.9771 - val_loss: 0.3119 - val_accuracy: 0.9302\n",
      "Epoch 403/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0702 - accuracy: 0.9761 - val_loss: 0.3071 - val_accuracy: 0.9291\n",
      "Epoch 404/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0696 - accuracy: 0.9754 - val_loss: 0.3066 - val_accuracy: 0.9339\n",
      "Epoch 405/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0735 - accuracy: 0.9749 - val_loss: 0.2983 - val_accuracy: 0.9323\n",
      "Epoch 406/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0709 - accuracy: 0.9761 - val_loss: 0.2973 - val_accuracy: 0.9339\n",
      "Epoch 407/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0721 - accuracy: 0.9762 - val_loss: 0.3016 - val_accuracy: 0.9286\n",
      "Epoch 408/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0734 - accuracy: 0.9744 - val_loss: 0.3012 - val_accuracy: 0.9325\n",
      "Epoch 409/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0739 - accuracy: 0.9753 - val_loss: 0.3038 - val_accuracy: 0.9323\n",
      "Epoch 410/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0728 - accuracy: 0.9746 - val_loss: 0.2830 - val_accuracy: 0.9305\n",
      "Epoch 411/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0700 - accuracy: 0.9754 - val_loss: 0.3100 - val_accuracy: 0.9316\n",
      "Epoch 412/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0691 - accuracy: 0.9755 - val_loss: 0.3066 - val_accuracy: 0.9311\n",
      "Epoch 413/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0740 - accuracy: 0.9760 - val_loss: 0.3096 - val_accuracy: 0.9307\n",
      "Epoch 414/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0698 - accuracy: 0.9757 - val_loss: 0.3136 - val_accuracy: 0.9305\n",
      "Epoch 415/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0716 - accuracy: 0.9754 - val_loss: 0.2840 - val_accuracy: 0.9314\n",
      "Epoch 416/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0654 - accuracy: 0.9782 - val_loss: 0.3242 - val_accuracy: 0.9316\n",
      "Epoch 417/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0716 - accuracy: 0.9756 - val_loss: 0.3067 - val_accuracy: 0.9316\n",
      "Epoch 418/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0693 - accuracy: 0.9769 - val_loss: 0.3200 - val_accuracy: 0.9321\n",
      "Epoch 419/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0710 - accuracy: 0.9766 - val_loss: 0.2927 - val_accuracy: 0.9318\n",
      "Epoch 420/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0694 - accuracy: 0.9774 - val_loss: 0.3013 - val_accuracy: 0.9291\n",
      "Epoch 421/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0698 - accuracy: 0.9771 - val_loss: 0.2957 - val_accuracy: 0.9323\n",
      "Epoch 422/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0665 - accuracy: 0.9778 - val_loss: 0.3090 - val_accuracy: 0.9305\n",
      "Epoch 423/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0670 - accuracy: 0.9774 - val_loss: 0.3118 - val_accuracy: 0.9330\n",
      "Epoch 424/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0716 - accuracy: 0.9756 - val_loss: 0.3048 - val_accuracy: 0.9293\n",
      "Epoch 425/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0693 - accuracy: 0.9766 - val_loss: 0.3011 - val_accuracy: 0.9325\n",
      "Epoch 426/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0688 - accuracy: 0.9764 - val_loss: 0.3057 - val_accuracy: 0.9332\n",
      "Epoch 427/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0672 - accuracy: 0.9768 - val_loss: 0.3084 - val_accuracy: 0.9311\n",
      "Epoch 428/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0681 - accuracy: 0.9775 - val_loss: 0.3018 - val_accuracy: 0.9337\n",
      "Epoch 429/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0694 - accuracy: 0.9764 - val_loss: 0.2975 - val_accuracy: 0.9332\n",
      "Epoch 430/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0671 - accuracy: 0.9772 - val_loss: 0.2973 - val_accuracy: 0.9330\n",
      "Epoch 431/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0667 - accuracy: 0.9767 - val_loss: 0.3091 - val_accuracy: 0.9325\n",
      "Epoch 432/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0655 - accuracy: 0.9779 - val_loss: 0.2954 - val_accuracy: 0.9343\n",
      "Epoch 433/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0669 - accuracy: 0.9774 - val_loss: 0.2987 - val_accuracy: 0.9307\n",
      "Epoch 434/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0709 - accuracy: 0.9757 - val_loss: 0.3064 - val_accuracy: 0.9300\n",
      "Epoch 435/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0683 - accuracy: 0.9770 - val_loss: 0.2962 - val_accuracy: 0.9323\n",
      "Epoch 436/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0697 - accuracy: 0.9766 - val_loss: 0.2880 - val_accuracy: 0.9373\n",
      "Epoch 437/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0661 - accuracy: 0.9773 - val_loss: 0.3021 - val_accuracy: 0.9334\n",
      "Epoch 438/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0690 - accuracy: 0.9761 - val_loss: 0.3003 - val_accuracy: 0.9302\n",
      "Epoch 439/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0644 - accuracy: 0.9783 - val_loss: 0.2957 - val_accuracy: 0.9330\n",
      "Epoch 440/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0678 - accuracy: 0.9774 - val_loss: 0.2931 - val_accuracy: 0.9325\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0657 - accuracy: 0.9785 - val_loss: 0.3004 - val_accuracy: 0.9334\n",
      "Epoch 442/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0706 - accuracy: 0.9770 - val_loss: 0.3099 - val_accuracy: 0.9314\n",
      "Epoch 443/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.3107 - val_accuracy: 0.9330\n",
      "Epoch 444/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0675 - accuracy: 0.9774 - val_loss: 0.3144 - val_accuracy: 0.9311\n",
      "Epoch 445/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0669 - accuracy: 0.9769 - val_loss: 0.3130 - val_accuracy: 0.9327\n",
      "Epoch 446/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0673 - accuracy: 0.9769 - val_loss: 0.3021 - val_accuracy: 0.9314\n",
      "Epoch 447/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0653 - accuracy: 0.9778 - val_loss: 0.3098 - val_accuracy: 0.9339\n",
      "Epoch 448/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0676 - accuracy: 0.9769 - val_loss: 0.3008 - val_accuracy: 0.9350\n",
      "Epoch 449/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0663 - accuracy: 0.9776 - val_loss: 0.3116 - val_accuracy: 0.9314\n",
      "Epoch 450/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0657 - accuracy: 0.9784 - val_loss: 0.3138 - val_accuracy: 0.9298\n",
      "Epoch 451/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0682 - accuracy: 0.9770 - val_loss: 0.3045 - val_accuracy: 0.9291\n",
      "Epoch 452/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0637 - accuracy: 0.9786 - val_loss: 0.3025 - val_accuracy: 0.9343\n",
      "Epoch 453/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0650 - accuracy: 0.9781 - val_loss: 0.3067 - val_accuracy: 0.9325\n",
      "Epoch 454/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0649 - accuracy: 0.9769 - val_loss: 0.3042 - val_accuracy: 0.9316\n",
      "Epoch 455/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0645 - accuracy: 0.9790 - val_loss: 0.3054 - val_accuracy: 0.9293\n",
      "Epoch 456/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0651 - accuracy: 0.9782 - val_loss: 0.3053 - val_accuracy: 0.9327\n",
      "Epoch 457/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0647 - accuracy: 0.9775 - val_loss: 0.3092 - val_accuracy: 0.9305\n",
      "Epoch 458/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0636 - accuracy: 0.9781 - val_loss: 0.3058 - val_accuracy: 0.9359\n",
      "Epoch 459/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0656 - accuracy: 0.9780 - val_loss: 0.3200 - val_accuracy: 0.9314\n",
      "Epoch 460/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0637 - accuracy: 0.9791 - val_loss: 0.3093 - val_accuracy: 0.9309\n",
      "Epoch 461/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0661 - accuracy: 0.9772 - val_loss: 0.3000 - val_accuracy: 0.9321\n",
      "Epoch 462/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0668 - accuracy: 0.9783 - val_loss: 0.2974 - val_accuracy: 0.9327\n",
      "Epoch 463/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0635 - accuracy: 0.9784 - val_loss: 0.2942 - val_accuracy: 0.9343\n",
      "Epoch 464/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0637 - accuracy: 0.9787 - val_loss: 0.3152 - val_accuracy: 0.9318\n",
      "Epoch 465/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0634 - accuracy: 0.9787 - val_loss: 0.3085 - val_accuracy: 0.9339\n",
      "Epoch 466/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0667 - accuracy: 0.9774 - val_loss: 0.3049 - val_accuracy: 0.9357\n",
      "Epoch 467/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0672 - accuracy: 0.9775 - val_loss: 0.3037 - val_accuracy: 0.9334\n",
      "Epoch 468/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0633 - accuracy: 0.9782 - val_loss: 0.3286 - val_accuracy: 0.9295\n",
      "Epoch 469/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0673 - accuracy: 0.9772 - val_loss: 0.2974 - val_accuracy: 0.9362\n",
      "Epoch 470/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 0.3050 - val_accuracy: 0.9291\n",
      "Epoch 471/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0643 - accuracy: 0.9778 - val_loss: 0.3072 - val_accuracy: 0.9362\n",
      "Epoch 472/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.3065 - val_accuracy: 0.9305\n",
      "Epoch 473/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0634 - accuracy: 0.9778 - val_loss: 0.3112 - val_accuracy: 0.9334\n",
      "Epoch 474/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0694 - accuracy: 0.9771 - val_loss: 0.3305 - val_accuracy: 0.9311\n",
      "Epoch 475/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0635 - accuracy: 0.9779 - val_loss: 0.3025 - val_accuracy: 0.9337\n",
      "Epoch 476/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0650 - accuracy: 0.9775 - val_loss: 0.3043 - val_accuracy: 0.9362\n",
      "Epoch 477/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0663 - accuracy: 0.9774 - val_loss: 0.3052 - val_accuracy: 0.9318\n",
      "Epoch 478/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0662 - accuracy: 0.9780 - val_loss: 0.3039 - val_accuracy: 0.9302\n",
      "Epoch 479/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0620 - accuracy: 0.9792 - val_loss: 0.3227 - val_accuracy: 0.9332\n",
      "Epoch 480/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0641 - accuracy: 0.9778 - val_loss: 0.3136 - val_accuracy: 0.9316\n",
      "Epoch 481/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0644 - accuracy: 0.9782 - val_loss: 0.3055 - val_accuracy: 0.9337\n",
      "Epoch 482/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0655 - accuracy: 0.9786 - val_loss: 0.2975 - val_accuracy: 0.9327\n",
      "Epoch 483/500\n",
      "1093/1093 [==============================] - 11s 10ms/step - loss: 0.0650 - accuracy: 0.9778 - val_loss: 0.3098 - val_accuracy: 0.9311\n",
      "Epoch 484/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0640 - accuracy: 0.9783 - val_loss: 0.3179 - val_accuracy: 0.9277\n",
      "Epoch 485/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0635 - accuracy: 0.9781 - val_loss: 0.3121 - val_accuracy: 0.9291\n",
      "Epoch 486/500\n",
      "1093/1093 [==============================] - 10s 10ms/step - loss: 0.0614 - accuracy: 0.9790 - val_loss: 0.3360 - val_accuracy: 0.9321\n",
      "Epoch 487/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0652 - accuracy: 0.9778 - val_loss: 0.3174 - val_accuracy: 0.9325\n",
      "Epoch 488/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0625 - accuracy: 0.9783 - val_loss: 0.3231 - val_accuracy: 0.9309\n",
      "Epoch 489/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0649 - accuracy: 0.9778 - val_loss: 0.3078 - val_accuracy: 0.9337\n",
      "Epoch 490/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0657 - accuracy: 0.9776 - val_loss: 0.2999 - val_accuracy: 0.9321\n",
      "Epoch 491/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0611 - accuracy: 0.9801 - val_loss: 0.3112 - val_accuracy: 0.9346\n",
      "Epoch 492/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0606 - accuracy: 0.9792 - val_loss: 0.3182 - val_accuracy: 0.9295\n",
      "Epoch 493/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0624 - accuracy: 0.9795 - val_loss: 0.3068 - val_accuracy: 0.9302\n",
      "Epoch 494/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0626 - accuracy: 0.9784 - val_loss: 0.3171 - val_accuracy: 0.9318\n",
      "Epoch 495/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.3084 - val_accuracy: 0.9355\n",
      "Epoch 496/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0600 - accuracy: 0.9801 - val_loss: 0.3258 - val_accuracy: 0.9341\n",
      "Epoch 497/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0627 - accuracy: 0.9784 - val_loss: 0.3145 - val_accuracy: 0.9316\n",
      "Epoch 498/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0607 - accuracy: 0.9792 - val_loss: 0.3026 - val_accuracy: 0.9330\n",
      "Epoch 499/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0626 - accuracy: 0.9787 - val_loss: 0.3191 - val_accuracy: 0.9323\n",
      "Epoch 500/500\n",
      "1093/1093 [==============================] - 10s 9ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 0.2928 - val_accuracy: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3a20017e50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model for 500 epochs and keep the best model measured on the validation accuracy. \n",
    "\n",
    "EPOCHS = 500\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = CNN_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),  \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "CNN_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5747703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18141/897927363.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
      "/tmp/ipykernel_18141/897927363.py:11: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
      "/tmp/ipykernel_18141/897927363.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
      "/tmp/ipykernel_18141/897927363.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzuElEQVR4nO3deXxU1fn48c+TQAgQRAmgrAkouAFhiVixVqxagfqFLwgCxQWpIrEUcaMsFlHMF7efCkKhsSoIsSwqCBaLuOBG1YRNBAQRAwQRIhAIa7bn98fcTGeSGTIJk4SZPO/Xa17MPffMvc+5zDy5c+6Zc0VVMcYYE/oiqjoAY4wxwWEJ3RhjwoQldGOMCROW0I0xJkxYQjfGmDBhCd0YY8KEJfQwJSLvicidwa5blUQkQ0RuqIDtrhKRu53nQ0Tk/UDqlmM/LUXkqIhEljdWY07HEvpZxPmwFz0KReSEx/KQsmxLVXuq6pxg1z0bichYEfnUR3lDEckVkXaBbktVU1X1d0GKy+sPkKruUtUYVS0IxvaNKc4S+lnE+bDHqGoMsAv4H4+y1KJ6IlKj6qI8K80DuolIq2Llg4CNqvptFcRUbdj78exhCT0EiEh3EckUkb+IyM/AayJynoi8KyJZInLIed7c4zWe3QhDReRzEXnOqfujiPQsZ91WIvKpiOSIyAciMkNE5vmJO5AYJ4vIF8723heRhh7rbxeRnSJyQEQm+Ds+qpoJfATcXmzVHcDrpcVRLOahIvK5x/KNIvKdiBwWkemAeKy7UEQ+cuL7RURSReRcZ91coCWwzPmGNUZE4kVEixKgiDQVkaUiclBEtovIPR7bniQiC0XkdefYbBKRRH/HQESmishuETkiImtE5BqPdZEiMl5EfnC2tUZEWjjrLheRlU4M+0RkvFM+W0Se9NhGdxHJ9FjOcN6P3wDHRKSG802paB+bRaRvsRjvEZEtHus7i8gjIvJWsXrTRGSqv7Ya/yyhh44LgAZAHDAc1//da85yS+AEMP00r78S2Ao0BJ4BXhERKUfdN4CvgVhgEiWTqKdAYvwDcBfQGIgCHgYQkcuAmc72mzr785mEHXM8YxGRi4GOTrxlPVZF22gIvA08iutY/ABc7VkFmOLEdynQAtcxQVVvx/tb1jM+djEfyHRe3x/4PxH5rcf63k6dc4GlpcSc5rS3gdPmRSIS7ax7EBgM9ALOAYYBx0WkHvAB8G8nhouAD0+zj+IGA78HzlXVfFzH5xqgPvA4ME9EmgCIyABcx+YOJ4bewAFc3656ePwhrIHrm9XrZYjDFFFVe5yFDyADuMF53h3IBaJPU78jcMhjeRVwt/N8KLDdY10dQIELylIXVzLMB+p4rJ8HzAuwTb5ifNRj+T7g387zicB8j3V1nWNwg59t1wGOAN2c5WTgnXIeq8+d53cAX3rUE1wJ+G4/2/1fYJ2v/0NnOd45ljVwJf8CoJ7H+inAbOf5JOADj3WXASfK8P45BCQ4z7cCfXzUGewZb7F1s4EnPZa7A5nF2jaslBjWF+0XWAHc76fee8A9zvObgc1n+vmprg87Qw8dWap6smhBROqIyN+dLokjwKfAueJ/BMXPRU9U9bjzNKaMdZsCBz3KAHb7CzjAGH/2eH7cI6amnttW1WO4zuh8cmJaBNzhfJsYgnOWV45jVaR4DOq5LCLni8h8EdnjbHcerjP5QBQdyxyPsp1AM4/l4scmWvz0V4vIw053xmERycZ1llwUSwtcZ8/F+SsPlNf/vYjcISLrRSTbiaFdADGA69vVbc7z24C5ZxBTtWYJPXQUnxbzIeBi4EpVPQf4jVPurxslGPYCDUSkjkdZi9PUP5MY93pu29lnbCmvmQPcCtwI1AOWnWEcxWMQvNv7f7j+X9o7272t2DZPN5XpT7iOZT2PspbAnlJiKsHpLx+Dq+3nqeq5wGGPWHYDF/p46W6gtZ/NHsP1rafIBT7quNsnInHAy8BIINaJ4dsAYgBYAnQQ12ikm4FUP/VMKSyhh656uPqCs0WkAfBYRe9QVXcC6cAkEYkSkauA/6mgGN8EbhaRX4tIFPAEpb9fPwOygRRc3TW5ZxjHv4DLRaSfc2Y8Cu/EVg84ChwWkWbAI8Vevw8/CVNVdwOrgSkiEi0iHYA/4jrLL6t6uLrCsoAaIjIRVz91kX8Ak0Wkjbh0EJFY4F2giYiMFpFaIlJPRK50XrMe6CUiDUTkAmB0KTHUxZXgswBE5C5cZ+ieMTwsIl2cGC5y/gjgfPN8E+f6jKruKscxMFhCD2UvArWBX4AvcV3YqgxDgKtwdX88CSwATvmp+yLljFFVNwF/wvUh34urTzizlNcorm6WOLwvqpUrDlX9BRgAPIWrvW2ALzyqPA50xnU2/C9cF1A9TQEedbogHvaxi8G4+tV/AhYDj6nqB4HEVswKXG3ahqvb5iTe3SHPAwuB93FdZ3gFqO1099yI64/yz8D3wHXOa+YCG3D1lb+P6//ZL1XdDPw/4D+4/pC1x+NYqeoiXNc13gBycJ2VN/DYxBznNdbdcgbEuRBhTLmIyALgO1Wt8G8IJnyJSEvgO1wX6o9UdTyhys7QTZmIyBXiGn8dISI9gD64zraMKRcRicA1tHK+JfMzY7/wMmV1Aa6uhVhcXSBJqrquakMyoUpE6uLqotkJ9KjicEKedbkYY0yYsC4XY4wJE1XW5dKwYUONj4+vqt0bY0xIWrNmzS+q2sjXuipL6PHx8aSnp1fV7o0xJiSJyE5/60rtchGRV0Vkv4j4nILU+ZHANHHNFveNiHQ+k2CNMcaUTyB96LM5/dXnnrh+cNEG1yyAM888LGOMMWVVakJX1U+Bg6ep0gd4XV2+xDXpUZNgBWiMMSYwwRjl0gzvnxln4j1jnJuIDBeRdBFJz8rKCsKujTHGFKnUYYuqmqKqiaqa2KiRz4u0xhhjyikYCX0P3lOKNqccU4AaY0woSU1NJT4+noiICOLj40lNTfVaFxMTg4iUeNSrV8+rblAFchcMXDPCfetn3e9x3XFEgF/hmv6y1G126dJFjTFnp3nz5mlsbKzimhJXY2NjNSkpSePi4lRENDY2VmNjY0s8j4uL06SkJK/XludRt25djYqKOqNtnO2PmJgYnTdvXpn/b4B09Zer/a3Q/ybsf+KavjQPV//4H4ERwAhnvQAzcN2NZCOQWNo21RK6qebmzZvnTo5xcXHuD7Zned26das86dijYh9RUVFlTuqcSUKvqIcldFMVTpdIPc8qq8MZoj3OjkdcXFyZ3sOcJqFX2eRciYmJar8UNcWlpqZy//33c+CA39uHGhNWRITCwsKy1F+jqom+1tnkXCaoPC8U+bsodLrHbbfdZsncVCstW7YM2rYsoRsvxa/c33fffcTHxyMiREREBJSQd+7ciapy7Nixqm6OMWe1qKgokpOTg7dBf30xFf2wPvTKU9RvzFnQX2gPe1S3R0REhAIqIl7lsbGxQR/lYncsClH33Xcfs2bNKhqJZExIioiIoLCwEBHx+V4WEUaMGMHf/va3Kogu9FiXy1nEs7ujYcOGp+2DnjlzpiXzaqpu3brExsYCroTnKTY2lnnz5vk8e5s3bx5xcXGICHFxcX7rVeajoKAAVaWwsNDn+sLCQkvmZVFV/5HW5VJyqJw9zs5H3bp1ff6IJjY21mus+Om+QvsbLmlMWWHDFqvefffdx8yZNrNwsNStWxfA68JrbGwsU6dOZciQIVUVljEV7nTDFq0PvQLYWGpvxftHIyMjGT58uH2VNibILKGfgdTUVO69995qNzyvKEHHxcWRnJxc6hlxQUEBkZGRlRRd5Sj6A1XUtuJ92aZqnTx5kujo6KoOo9LZRdEyKD6D2m233RayybzowpqI0LRpUwCaNGnCO++84/cClaryySefsHjxYlSVjIwMBg8ezDfffMMjjzzC7t27Wb9+Penp6WRnZwNw6tQpunTpwqhRo9z7VlUOHTrEsmXLKCgo4KWXXqJv376sWrUKgNmzZ3P55ZezatUqduzYQVpaGp9++imfffaZVxuKkmrxbsPVq1ezceNG9/KpU6fc8RQtF71m69at9OzZk7Vr1wJw5MgRd71ffvmFr776yr2PjRs3cvToUTIzM+natSu1a9emZs2aPPTQQz6P8cmTJ/n666/Jy8vjxx9/LBF/dnY2hw4dci+///77PPvssxQUFFBYWMh3333Hrl27SmzX81eFp06dIi8vj4yMDJ8xFMnLy3PX93ytL+vWrWP8+PGcOHHCXaaqHDx4kJMnT6Kq7N27l8OHD5Ofn8+XX37pPp6FhYUsWrSII0eO8P777zNr1iyWLFnC559/zs6dOxk1ahSHDh3yOs7g6jrbu3cve/aUbaJWVeXIkSMcOXKE/fv3s3HjRrZs2cJ5553Hiy++6N52kfz8fF5//XVWr15Nfn4+X3zxhTv2WbNmMWXKFAC+//57NmzYwMSJE3n55ZcZOHAg3bp147nnnuPUqVOMHz+exx9/HFXlxIkTXu8vgKNHj7rfu8ePH2fMmDHu//8dO3Zw8uTJMrWzTAekKh6hcFE0HMZvx8bG6ldffaWDBg1SQK+66ip96623dPDgwVq/fn1NTEzUCy+80Os1/fv31969e+u4ceP0kUce0fbt22uTJk00KSnJXefSSy/VNm3alHit56P4XChXX321Tp06VQcOHFiirohorVq1NCEh4bTtufvuu3X06NE6ZswYbd26tXs/o0eP1hYtWujkyZPddceMGaMLFy7U888/X8877zxdsGCBvvrqq9qkSRMF9Nxzz3XXveCCC3TcuHEKaN++ffW+++5zr+vXr59ecMEF7uVzzjlHa9as6RXX+PHj9ZprrtHWrVtrYmKi/vWvf9XExEQF9J577nHXmzx5sqampurs2bPd8f/617/WSy65xF3nt7/9rcbExCigtWrV0jfffFMfeugh7dy5s957771as2ZNbdu2rVf8gF522WX6/PPP65QpU/Tpp5/Wli1bardu3XTs2LHu9tWsWVOnT5+u77//vtavX1/btGmjffr00T/84Q/6v//7v5qQkODVtnPPPbfEZ6Bx48YK6IUXXqj9+vVTQK+88kpt3769RkZGKqB9+vQp9b3ZpEkT7dWrlw4YMEA7derktc/u3btrUlKSPv/88/rkk0/qHXfcoTfddJP26tVL27VrpzVq1PC73bZt2/os92xXTEyMDhs2zP2ZOP/8893rrr/++jJ/zqKionTSpEn6+uuva7t27bzW3XzzzV7vc0BfeumlcuclbHKuspk3b95ZNTFT8R8kFH1oSnvcfvvt7uTla5v9+vUrse2uXbuqiJTYR9GHuCjJXHPNNT6327hxY/3Vr36lTZs2VUBbt26tf/3rX7VDhw4l6p533nkKrj8gu3bt8vtBBNcfph49egR8zNq0aRPwcZoxY0apdYp+HALoRRddpBs2bNBu3bopoPXr1z+jZFD0aNSokY4ePVojIyO1QYMGevHFF2uzZs1KvA/atWunPXv21LZt2+pNN92kzZs314suukjj4+O9tnfFFVeUus/ifxTat2+vw4cP91m3bt26OmjQIL3tttv0lltu8VpXs2ZNr+NQ/NG1a9cSZfHx8XrppZcGdMxbtmypl19+eYk6TZs21U6dOmlycrIOGDDAXT5ixAitVauWxsTEaPfu3bV27doaGRmp9evX12HDhmm9evX87rdOnTp611136W9+8xt9+eWXfda59957tU2bNu735lVXXeVeV/THuE6dOu6ye+65R3v27Kk33nijPvLII7pnz55y5ycsof9XYWFhibKzZfig5xsgIiJCN2/erNu2bVNV1R9//FFXr16tjz32mLvOggULdPTo0Xrttdfqjh079KefftL8/Hz98ccf9euvv1ZV1c8++0zPP/98feyxx3T69OkKrqSblZWlqqppaWn6zjvv6KhRo1RENCcnR7dt26a7du3Su+66SxcuXKjTp0/X3NxcTUtL0+3bt7uPW1ZWli5YsEDXrVunixcv1lmzZrnX5efna0FBgebn56uq6rFjx/TgwYM6c+ZMTUlJca9btmyZHj9+3P1/U1BQoL/88ov+8Y9/VEC///57feKJJ3TNmjVaWFioq1ev1j179ugPP/yg+/bt07Vr1+quXbv0nHPO0dq1a+vYsWM1LS1NVVX379+vTz/9tP7zn//UOXPm6JIlSzQtLU1PnDihe/fuVXAlc1XVTz/9VLdu3appaWk6ZcoU/eKLL7SwsFDXrl2rGRkZmpeXp3v37tUhQ4boTz/9pKqqOTk5umfPHl20aJECunDhQlVVzc7O1unTp+vbb7+tGRkZ+tRTT+n69es1Ozvb/X83Y8YMveOOO/S9997TVatW6Zo1a3Tnzp2qqpqXl+c+jjk5OXrTTTfpgAEDNCcnR9euXauHDh3y+Z4+efKkfvnllzp37lx98803tbCwUKdNm6ZNmzbV+++/X5s2bapvvfWWdurUSW+//XbNzs52b2PBggW6adMm9/KDDz6ogwYN0pUrV2r9+vV1/fr1XvvMzc3VF154QdetW+f+fzt+/LguWbJEJ02apID+5z//0YSEBJ0zZ46qqq5Zs0aPHDmi+/fv99rWd999p88884weO3ZMZ82apYsWLdKff/5ZT506pfv37/dKfm+88YZ+8cUXunXrVp0/f74WFhZ6faazsrLcMe3du1dPnDhR4jipqmZkZOiUKVN0y5Ytum3bNl28eLEeOHBACwsLvY6/quoPP/ygb7/9tk6bNk0PHjzo3s7x48c1IyPD/X7v27evDhgwQLOzs93v+/fff18///xzDSZL6I4rrrhC+/Tpo4MHD9b33ntPR48erQ0aNKjUpB0TE6Ovvfaa5uTkaF5envsN+dNPP2lubq4COnTo0BIf2iJHjx5VQBs0aBBwu4vegBkZGQro4sWLg3A0K1ZOTo6uWbMm4Po//vijHjx4sEz7OHnypM8/8OWRk5MTUL0lS5boypUrg7LPsgpWW0uTm5urmZmZlbKv6uh0Cb3ajEM/dOgQDRo0qLT9eRo5ciQvvfRSQHVPnDhBrVq1iIjwf716y5Yt1K5dm/j4+DLHoqo2IsOYEFatp89VVVasWFHhybxu3bpceeWVrFq1yusv5oEDB5g2bVrA26ldu/ZpkznApZdeWq5kDiV/Km6MCR8BJXQR6SEiW0Vku4iM9bE+TkQ+FJFvRGSViDQPfqhll5ubyz/+8Q969OgR9G0XDV8smhPj6NGjfPnll1x77bVe9Ro0aGBJ1BhTKUr9YZGIROK6Z+iNuO4pmiYiS1V1s0e154DXVXWOiPwWmALcXhEBB2rnzp20a9eOo0ePBm2b9tNyY8zZLJAz9K7AdlXdoaq5wHygT7E6lwEfOc8/9rG+0r344oscPXoUESn3rxRFhKSkJHf3yS+//GLJ3Bhz1gokoTcDdnssZzplnjYA/ZznfYF6IhJ75uGVz6FDh3j55Zdp27Ytqq4pOssqKSnJpu40xoSUYF0UfRi4VkTWAdcCe4ASWVREhotIuoikZ2VlBWnXJb377rscO3aMbdu2lfm1RfNJWyI3xoSaQCbn2gO08Fhu7pS5qepPOGfoIhID3KKq2cU3pKopQAq4hi2WL+TTW7lyJXfccUfA9UWEuXPnWleKMSbkBXKGnga0EZFWIhIFDAKWelYQkYYiUrStccCrwQ0zMGvWrOF3v/tdwPWjoqIsmRtjwkapCV1V84GRwApgC7BQVTeJyBMi0tup1h3YKiLbgPOBIN7GOjA5OTkkJvoca+9TdHQ0r776qiVzY0zYCGg+dFVdDiwvVjbR4/mbwJvBDa1sFi9eHHDdpKQk6yM3xoSdsLnBxcKFCwOqN2/ePDsrN8aEpbD56f9HH31Uap3rr7/ekrkxJmyFTUL3vLuKL0lJSXzwwQeVFI0xxlS+sEjoRbea8icuLs76zI0xYS/kE/ratWt54IEHTlsnObnSB90YY0ylC/mEPmvWrNOuj42NtX5zY0y1EPIJ/XSjW0SEqVOnVmI0xhhTdUI+oR8+fNjvuhEjRtjZuTGm2gj5hO6PiNiFUGNMtRLSCT01NdXvuqq6V6oxxlSVkE3oy5YtY+TIkX7Xx8XFVWI0xhhT9UI2ob/xxhtkZ2f7XW9DFY0x1U3IJvRjx475vfly3bp17WKoMabaCemE7q+fPDo6upKjMcaYqhfSCd2fgwcPVmIkxhhzdgjZhL5nzx6/61q2bFmJkRhjzNkhZBP63r17fZaLiF0QNcZUSyGb0AsKCnyWq6pdEDXGVEsBJXQR6SEiW0Vku4iM9bG+pYh8LCLrROQbEekV/FD/63Q/KLLx58aY6qrUhC4ikcAMoCdwGTBYRC4rVu1RXDeP7gQMAir0N/fjx4/3WW7dLcaY6iyQM/SuwHZV3aGqucB8oE+xOgqc4zyvD/wUvBBL2rVrl89y624xxlRngST0ZsBuj+VMp8zTJOA2EckElgN/9rUhERkuIukikp6VlVWOcF2aN2/us9y6W4wx1VmwLooOBmaranOgFzBXREpsW1VTVDVRVRMbNWpU7p09+OCDJcrq1Klj3S3GmGotkIS+B2jhsdzcKfP0R2AhgKr+B4gGGgYjQF9uuOEGr2UR4c4777TuFmNMtRZIQk8D2ohIKxGJwnXRc2mxOruA6wFE5FJcCb38fSqlePvtt72WVZU5c+acdvSLMcaEu1ITuqrmAyOBFcAWXKNZNonIEyLS26n2EHCPiGwA/gkM1QqckNzXjSuOHz/OhAkTKmqXxhhz1pOquhFEYmKipqenl+u1/mZZFBEKCwvPJCxjjDmricgaVU30tS4kfynasKHv7nmbw8UYU52FZELv06f4MHgb5WKMMSGZ0Nu1a+e1HBsbS0pKio1yMcZUayGZ0IvmQo+KigJg+vTplsyNMdVeSCb0r776CoDc3FwA/vOf/1RlOMYYc1YIuYSemprKe++951U2a9YsG4NujKn2Qi6hT5gwgfz8fK+y3NxcG4NujKn2Qi6h+5tp0V+5McZUFyGX0P2NNbcx6MaY6i7kEnpycjIREd5h16pVy8agG2OqvZBL6EOGDKFVq1ZER0e7y/7yl7/YsEVjTLUXcgkdIDo6ml69etGvXz8AevWq0FuYGmNMSKhR1QGUR25uLlFRUURGRgJQo0ZINsMYY4IqJM/QCwsLiYiIoHbt2oAldGOMgRBN6KqKiLgTes2aNas4ImOMqXphkdDtDN0YY0K0D/3o0aMsXrzYPUnXv/71L9q2bVvFURljTNUK6AxdRHqIyFYR2S4iY32sf0FE1juPbSKSHfRIHampqfzyyy/uZA4wfvx4m8vFGFPtlXoLOhGJBLYBNwKZuG4aPVhVN/up/2egk6oOO912y3sLuvj4eHbu3FmiPC4ujoyMjDJvzxhjQsmZ3oKuK7BdVXeoai4wHyh5y6D/GozrRtEVwuZyMcYY3wJJ6M2A3R7LmU5ZCSISB7QCPjrz0HyzuVyMMca3YI9yGQS8qaoFvlaKyHARSReR9KysrHLtIDk5GRHxKrP7iRpjTGAJfQ/QwmO5uVPmyyBO092iqimqmqiqiY0aNQo8Sg9Dhgyhfv36xMTEICLExcXZ/USNMYbAhi2mAW1EpBWuRD4I+EPxSiJyCXAeUOH3g4uOjqZ37978/e9/r+hdGWNMyCj1DF1V84GRwApgC7BQVTeJyBMi0tuj6iBgvpY2bCYICgsLS3S7GGNMdRfQD4tUdTmwvFjZxGLLk4IXVqnxWEI3xphiQvqn/8YYY/7LEroxxoSJkE3oxW9DZ4wx1V1IZkW7KGqMMSWFZEK3LhdjjCnJEroxxoQJS+jGGBMmLKEbY0yYCNmEbqNcjDHGW0hmRRvlYowxJYVkQrcuF2OMKckSujHGhAlL6MYYEyZCNqHbRVFjjPEWklnRLooaY0xJIZnQrcvFGGNKsoRujDFhwhK6McaEiYASuoj0EJGtIrJdRMb6qXOriGwWkU0i8kZww/yvoluWWkI3xhhvpd5TVEQigRnAjUAmkCYiS1V1s0edNsA44GpVPSQijSsq4KKEbqNcjDHGWyBZsSuwXVV3qGouMB/oU6zOPcAMVT0EoKr7gxvmf9kZujHG+BZIQm8G7PZYznTKPLUF2orIFyLypYj08LUhERkuIukikp6VlVWugFNTUwF47LHHiI+Pdy8bY0x1F6x+ixpAG6A7MBh4WUTOLV5JVVNUNVFVExs1alTmnaSmpjJixAj38s6dOxk+fLgldWOMIbCEvgdo4bHc3CnzlAksVdU8Vf0R2IYrwQfVhAkTOHHihFfZ8ePHmTBhQrB3ZYwxISeQhJ4GtBGRViISBQwClharswTX2Tki0hBXF8yO4IXpsmvXrjKVG2NMdVJqQlfVfGAksALYAixU1U0i8oSI9HaqrQAOiMhm4GPgEVU9EOxgW7ZsWaZyY4ypTgLqQ1fV5araVlUvVNVkp2yiqi51nquqPqiql6lqe1WdXxHBJicnU7t2ba+yOnXqkJycXBG7M8aYkBJSg7mHDBnCSy+95F6Oi4sjJSWFIUOGVGFUxhhzdgiphA4wcOBAAJ555hkyMjIsmRtjjCPkErr9UtQYY3wLuaxYWFgI2C9FjTGmuJBL6PbTf2OM8c0SujHGhAlL6MYYEyYsoRtjTJgI2YRuo1yMMcZbyGVFG+VijDG+hVxCty4XY4zxzRK6McaECUvoxhgTJkI2odtFUWOM8RZyWdEuihpjjG8hl9Cty8UYY3yzhG6MMWHCEroxxoSJgBK6iPQQka0isl1ExvpYP1REskRkvfO4O/ihulhCN8YY32qUVkFEIoEZwI1AJpAmIktVdXOxqgtUdWQFxOjFRrkYY4xvgWTFrsB2Vd2hqrnAfKBPxYbln41yMcYY3wJJ6M2A3R7LmU5ZcbeIyDci8qaItPC1IREZLiLpIpKelZVVjnCty8UYY/wJVr/FMiBeVTsAK4E5viqpaoqqJqpqYqNGjcq1I0voxhjjWyAJfQ/gecbd3ClzU9UDqnrKWfwH0CU44ZVkCd0YY3wLJKGnAW1EpJWIRAGDgKWeFUSkicdib2BL8EL0ZhdFjTHGt1JHuahqvoiMBFYAkcCrqrpJRJ4A0lV1KTBKRHoD+cBBYGhFBWwXRY0xxrdSEzqAqi4Hlhcrm+jxfBwwLrih+Y0FsIRujDHFhVy/hSV0Y4zxzRK6McaECUvoxhgTJkIuoRddFLVRLsYY4y3ksqKdoRtjjG+W0I0xJkxYQjfGmDBhCd0YY8JEyCZ0uyhqjDHeQi4r2k//jTHGt5BL6NblYowxvllCN8aYMGEJ3RhjwkTIJnS7KGqMMd5CLivaRVFjjPEt5BK6dbkYY4xvltCNMSZMBJTQRaSHiGwVke0iMvY09W4RERWRxOCF6M0SujHG+FZqQheRSGAG0BO4DBgsIpf5qFcPuB/4KthBerKEbowxvgVyht4V2K6qO1Q1F5gP9PFRbzLwNHAyiPGVYKNcjDHGt0CyYjNgt8dyplPmJiKdgRaq+q/TbUhEhotIuoikZ2VllTlYsFEuxhjjzxmf5opIBPA88FBpdVU1RVUTVTWxUaNG5dqfdbkYY4xvgST0PUALj+XmTlmRekA7YJWIZAC/ApZW1IVRS+jGGONbIAk9DWgjIq1EJAoYBCwtWqmqh1W1oarGq2o88CXQW1XTKyJgS+jGGONbqQldVfOBkcAKYAuwUFU3icgTItK7ogP0EQ9gF0WNMaa4GoFUUtXlwPJiZRP91O1+5mH5ZxdFjTHGt5A7zbUuF2OM8c0SujHGhAlL6MYYEyYsoRtjTJgI2YRuo1yMMcZbyGVFG+VijDG+hVxCty4XY4zxzRK6McaECUvoxhgTJkI2odtFUWOM8RbQT//PJnZR1ISjvLw8MjMzOXmyQu8PY0JIdHQ0zZs3p2bNmgG/JuQSunW5mHCUmZlJvXr1iI+Pt/e2QVU5cOAAmZmZtGrVKuDXhVy/hSV0E45OnjxJbGysva8N4MpvsbGxZf7GZgndmLOEvaeNp/K8HyyhG2NMmAjZhG6jXEx1lpqaSnx8PBEREcTHx5OamnpG2ztw4AAdO3akY8eOXHDBBTRr1sy9nJube9rXpqenM2rUqFL30a1btzOK0ZQu5C6K2igXU92lpqYyfPhwjh8/DsDOnTsZPnw4AEOGDCnXNmNjY1m/fj0AkyZNIiYmhocffti9Pj8/nxo1fKeLxMREEhNLv4Xw6tWryxVbVSooKCAyMrKqwwhYyJ3mWpeLqe4mTJjgTuZFjh8/zoQJE4K6n6FDhzJixAiuvPJKxowZw9dff81VV11Fp06d6NatG1u3bgVg1apV3HzzzYDrj8GwYcPo3r07rVu3Ztq0ae7txcTEuOt3796d/v37c8kllzBkyBD353r58uVccskldOnShVGjRrm36ykjI4NrrrmGzp0707lzZ68/FE8//TTt27cnISGBsWPHArB9+3ZuuOEGEhIS6Ny5Mz/88INXzAAjR45k9uzZAMTHx/OXv/yFzp07s2jRIl5++WWuuOIKEhISuOWWW9zHft++ffTt25eEhAQSEhJYvXo1EydO5MUXX3Rvd8KECUydOvVM/ysCFtAZuoj0AKYCkcA/VPWpYutHAH8CCoCjwHBV3RzkWAFL6Mbs2rWrTOVnIjMzk9WrVxMZGcmRI0f47LPPqFGjBh988AHjx4/nrbfeKvGa7777jo8//picnBwuvvhikpKSSoylXrduHZs2baJp06ZcffXVfPHFFyQmJnLvvffy6aef0qpVKwYPHuwzpsaNG7Ny5Uqio6P5/vvvGTx4MOnp6bz33nu88847fPXVV9SpU4eDBw8Crm8tY8eOpW/fvpw8eZLCwkJ279592nbHxsaydu1awNUddc899wDw6KOP8sorr/DnP/+ZUaNGce2117J48WIKCgo4evQoTZs2pV+/fowePZrCwkLmz5/P119/XebjXl6lJnQRiQRmADcCmUCaiCwtlrDfUNVZTv3ewPNAjwqI1xK6qfZatmzJzp07fZYH24ABA9xdDocPH+bOO+/k+++/R0TIy8vz+Zrf//731KpVi1q1atG4cWP27dtH8+bNvep07drVXdaxY0cyMjKIiYmhdevW7nHXgwcPJiUlpcT28/LyGDlyJOvXrycyMpJt27YB8MEHH3DXXXdRp04dABo0aEBOTg579uyhb9++gOvHOoEYOHCg+/m3337Lo48+SnZ2NkePHuWmm24C4KOPPuL1118HIDIykvr161O/fn1iY2NZt24d+/bto1OnTsTGxga0z2AIpMulK7BdVXeoai4wH+jjWUFVj3gs1gU0eCF6s4uiprpLTk52J60iderUITk5Oej7qlu3rvv5X//6V6677jq+/fZbli1b5neMdK1atdzPIyMjyc/PL1cdf1544QXOP/98NmzYQHp6eqkXbX2pUaOG+3ocUKItnu0eOnQo06dPZ+PGjTz22GOljg2/++67mT17Nq+99hrDhg0rc2xnIpCs2Azw/H6S6ZR5EZE/icgPwDOAz0veIjJcRNJFJD0rK6s88dpFUVPtDRkyhJSUFOLi4hAR4uLiSElJKfcF0UAdPnyYZs1cH/2i/uZguvjii9mxYwcZGRkALFiwwG8cTZo0ISIigrlz51JQUADAjTfeyGuvvebu4z548CD16tWjefPmLFmyBIBTp05x/Phx4uLi2Lx5M6dOnSI7O5sPP/zQb1w5OTk0adKEvLw8r9FE119/PTNnzgRcF08PHz4MQN++ffn3v/9NWlqa+2y+sgTtNFdVZ6jqhcBfgEf91ElR1URVTWzUqFF59wNYQjfV25AhQ8jIyKCwsJCMjIwKT+YAY8aMYdy4cXTq1KlMZ9SBql27Nn/729/o0aMHXbp0oV69etSvX79Evfvuu485c+aQkJDAd9995z6b7tGjB7179yYxMZGOHTvy3HPPATB37lymTZtGhw4d6NatGz///DMtWrTg1ltvpV27dtx666106tTJb1yTJ0/myiuv5Oqrr+aSSy5xl0+dOpWPP/6Y9u3b06VLFzZvdvVCR0VFcd1113HrrbdW/ggZVT3tA7gKWOGxPA4Yd5r6EcDh0rbbpUsXLY+UlBQFdPfu3eV6vTFno82bN1d1CGeFnJwcVVUtLCzUpKQkff7556s4orIrKCjQhIQE3bZt2xlvy9f7AkhXP3k1kDP0NKCNiLQSkShgELDUs4KItPFY/D3w/Rn+nfFL7QzdmLD18ssv07FjRy6//HIOHz7MvffeW9UhlcnmzZu56KKLuP7662nTpk3pLwiyUke5qGq+iIwEVuAatviqqm4SkSdw/aVYCowUkRuAPOAQcGdFBWwJ3Zjw9cADD/DAAw9UdRjldtlll7Fjx44q239A49BVdTmwvFjZRI/n9wc5Lr+KLoraKBdjjPEWclnRztCNMcY3S+jGGBMmLKEbY0yYsIRujOG6665jxYoVXmUvvvgiSUlJfl/TvXt30tPTAejVqxfZ2dkl6kyaNMk9HtyfJUuWuMdwA0ycOJEPPvigDNGbIiGb0O2iqDHBM3jwYObPn+9VNn/+fL8TZBW3fPlyzj333HLtu3hCf+KJJ7jhhhvKta2qUvRr1apm86Ebc5YZPXq0e27yYOnYsaPXtK7F9e/fn0cffZTc3FyioqLIyMjgp59+4pprriEpKYm0tDROnDhB//79efzxx0u8Pj4+nvT0dBo2bEhycjJz5syhcePGtGjRgi5dugCuMeYpKSnk5uZy0UUXMXfuXNavX8/SpUv55JNPePLJJ3nrrbeYPHkyN998M/379+fDDz/k4YcfJj8/nyuuuIKZM2dSq1Yt4uPjufPOO1m2bBl5eXksWrTI61ec4Jpm9/bbb+fYsWMATJ8+3X2Tjaeffpp58+YRERFBz549eeqpp9i+fTsjRowgKyuLyMhIFi1axO7du3nuued49913Adc0u4mJiQwdOpT4+HgGDhzIypUrGTNmDDk5OSXaV6dOHfbt28eIESPcwxlnzpzJv//9bxo0aMDo0aMB1zS7jRs35v77z2zAYMid5lqXizHB16BBA7p27cp7770HuM7Ob731VkSE5ORk0tPT+eabb/jkk0/45ptv/G5nzZo1zJ8/n/Xr17N8+XLS0tLc6/r160daWhobNmzg0ksv5ZVXXqFbt2707t2bZ599lvXr13PhhRe66588eZKhQ4eyYMECNm7cSH5+vnvuFICGDRuydu1akpKSfHbrFE2zu3btWhYsWOC+q5LnNLsbNmxgzJgxgGs6hT/96U9s2LCB1atX06RJk1KPW9E0u4MGDfLZPsA9ze6GDRtYu3Ytl19+OcOGDXPP1Fg0ze5tt91W6v5KE1Jn6KmpqUyePBmADh06MGXKlEqZw8KYynS6M+mKVNTt0qdPH+bPn+9OSAsXLiQlJYX8/Hz27t3L5s2b6dChg89tfPbZZ/Tt29c9G2Tv3r3d6/xNQ+vP1q1badWqFW3btgXgzjvvZMaMGe6z2n79+gHQpUsX3n777RKvr47T7IZMQi9+263du3ef8W23jDH/1adPHx544AHWrl3L8ePH6dKlCz/++CPPPfccaWlpnHfeeQwdOrTU6WP9GTp0KEuWLCEhIYHZs2ezatWqM4q3aApef9Pvek6zW1hYGHCS9lTWaXbL0r6iaXZ//vnnoE2zGzJdLpV12y1jqquYmBiuu+46hg0b5r4YeuTIEerWrUv9+vXZt2+fu0vGn9/85jcsWbKEEydOkJOTw7Jly9zr/E1DW69ePXJyckps6+KLLyYjI4Pt27cDrlkTr7322oDbUx2n2Q2ZhF6Zt90yproaPHgwGzZscCf0hIQEOnXqxCWXXMIf/vAHrr766tO+vnPnzgwcOJCEhAR69uzJFVdc4V7nbxraQYMG8eyzz9KpUyd++OEHd3l0dDSvvfYaAwYMoH379kRERDBixIiA21Idp9mVoouMlS0xMVGLxrAGIj4+3udtt+Li4twT4hsTqrZs2cKll15a1WGYSlRYWOi+EbW/mRl9vS9EZI2qJvqqHzJn6JV52y1jjKlIFTXNbshcFC268DlhwgR27dpFy5YtSU5OtguixpiQU1HT7IZMQgdXUrcEbsKVqtrvK4xbebrDQ6bLxZhwFh0dzYEDB8r1ITbhR1U5cOBAmYdahtQZujHhqnnz5mRmZpKVlVXVoZizRHR0NM2bNy/TawJK6CLSA5iK6xZ0/1DVp4qtfxC4G8gHsoBhqlpySIoxxqeaNWvSqlWrqg7DhLhSu1xEJBKYAfQELgMGi8hlxaqtAxJVtQPwJvBMsAM1xhhzeoH0oXcFtqvqDlXNBeYDfTwrqOrHqlr0M84vgbJ9TzDGGHPGAknozYDdHsuZTpk/fwR8/j5YRIaLSLqIpFtfoTHGBFdQL4qKyG1AIuBzwgVVTQFSnLpZIlLefvaGwC/lfG2osjZXD9bm6uFM2hznb0UgCX0P0MJjublT5kVEbgAmANeq6qnSNqqqjQLYt08iku7vp6/hytpcPVibq4eKanMgXS5pQBsRaSUiUcAgYGmx4DoBfwd6q+r+YAdpjDGmdKUmdFXNB0YCK4AtwEJV3SQiT4hI0ez1zwIxwCIRWS8iS/1szhhjTAUJqA9dVZcDy4uVTfR4Xtl3dE2p5P2dDazN1YO1uXqokDZX2fS5xhhjgsvmcjHGmDBhCd0YY8JESCV0EekhIltFZLuIjK3qeIJFRF4Vkf0i8q1HWQMRWSki3zv/nueUi4hMc47BNyLSueoiLz8RaSEiH4vIZhHZJCL3O+Vh224RiRaRr0Vkg9Pmx53yViLyldO2Bc5oMkSklrO83VkfX6UNOAMiEiki60TkXWc5rNssIhkistEZJJLulFX4eztkEnqAc8qEqtlAj2JlY4EPVbUN8KGzDK72t3Eew4GZlRRjsOUDD6nqZcCvgD85/5/h3O5TwG9VNQHoCPQQkV8BTwMvqOpFwCFcv7bG+feQU/6CUy9U3Y9rlFyR6tDm61S1o8d484p/b6tqSDyAq4AVHsvjgHFVHVcQ2xcPfOuxvBVo4jxvAmx1nv8dGOyrXig/gHeAG6tLu4E6wFrgSly/GKzhlLvf57iGCl/lPK/h1JOqjr0cbW3uJLDfAu8CUg3anAE0LFZW4e/tkDlDp+xzyoS681V1r/P8Z+B853nYHQfna3Un4CvCvN1O18N6YD+wEvgByFbX7z3Au13uNjvrDwOxlRpwcLwIjAEKneVYwr/NCrwvImtEZLhTVuHvbbvBRQhQVRWRsBxfKiIxwFvAaFU94nkLtnBst6oWAB1F5FxgMXBJ1UZUsUTkZmC/qq4Rke5VHE5l+rWq7hGRxsBKEfnOc2VFvbdD6Qw9oDllwsg+EWkC4PxbNKVC2BwHEamJK5mnqurbTnHYtxtAVbOBj3F1N5wrIkUnV57tcrfZWV8fOFC5kZ6xq4HeIpKBa+rt3+K6WU44txlV3eP8ux/XH+6uVMJ7O5QSeqlzyoSZpcCdzvM7cfUxF5Xf4VwZ/xVw2ONrXMgQ16n4K8AWVX3eY1XYtltEGjln5ohIbVzXDLbgSuz9nWrF21x0LPoDH6nTyRoqVHWcqjZX1Xhcn9mPVHUIYdxmEakrIvWKngO/A76lMt7bVX3xoIwXGnoB23D1O06o6niC2K5/AnuBPFz9Z3/E1W/4IfA98AHQwKkruEb7/ABsxHWnqCpvQzna/Gtc/YzfAOudR69wbjfQAdfdvb5xPuATnfLWwNfAdmARUMspj3aWtzvrW1d1G86w/d2Bd8O9zU7bNjiPTUW5qjLe2/bTf2OMCROh1OVijDHmNCyhG2NMmLCEbowxYcISujHGhAlL6MYYEyYsoRtjTJiwhG6MMWHi/wMguJfZtXPM+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "172d89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNN-Model\n",
    "\n",
    "models.save_model(CNN_model, CNN_model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8dd616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of CNN: 99.31381344795227 %\n",
      "Accuracy on validation set of CNN: 93.82292628288269 %\n",
      "Accuracy on test set of CNN: 94.62365508079529 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the CNN model \n",
    "\n",
    "score = CNN_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of CNN:', score[1] * 100,'%')\n",
    "score = CNN_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy on test set of CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016efe63",
   "metadata": {},
   "source": [
    "<font size=\"5\">3. Quantize the CNN-Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf0883cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 101, 1)]      0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 40, 101, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (QuantizedConv2D)     (None, 20, 51, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ActivationDiscr (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_1 (QuantizedSepara (None, 20, 51, 32)        1344      \n",
      "_________________________________________________________________\n",
      "separable_1_relu (Activation (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_2 (QuantizedSepara (None, 10, 26, 64)        2400      \n",
      "_________________________________________________________________\n",
      "separable_2_relu (Activation (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_3 (QuantizedSepara (None, 10, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "separable_3_relu (Activation (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_4 (QuantizedSepara (None, 5, 13, 128)        17664     \n",
      "_________________________________________________________________\n",
      "separable_4_relu (Activation (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "separable_5 (QuantizedSepara (None, 5, 13, 256)        34176     \n",
      "_________________________________________________________________\n",
      "separable_5_relu (Activation (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 13, 256)        0         \n",
      "_________________________________________________________________\n",
      "separable_6 (QuantizedSepara (None, 3, 7, 256)         68096     \n",
      "_________________________________________________________________\n",
      "separable_6_relu (Activation (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "separable_7 (QuantizedSepara (None, 2, 4, 512)         133888    \n",
      "_________________________________________________________________\n",
      "separable_7_relu (Activation (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_8 (QuantizedSepara (None, 2, 4, 1024)        529920    \n",
      "_________________________________________________________________\n",
      "separable_8_global_avg (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "separable_8_relu (Activation (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (QuantizedDense)       (None, 12)                12300     \n",
      "_________________________________________________________________\n",
      "re_lu (ActivationDiscreteRel (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 809,004\n",
      "Trainable params: 809,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Quantize the CNN-model with 4-Bit activations\n",
    "\n",
    "quantized_model = quantize(CNN_model,\n",
    "                           input_weight_quantization=8,\n",
    "                           weight_quantization=4,\n",
    "                           activ_quantization=4)\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0300370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy after quantization\n",
    "\n",
    "quantized_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab6dfa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of quantized CNN: 73.29025864601135 %\n",
      "Accuracy on validation set of quantized CNN: 68.67993474006653 %\n",
      "Accuracy on test set of quantized CNN: 69.18325424194336 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the quantized CNN model before training\n",
    "\n",
    "score = quantized_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy on test set of quantized CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "043b41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1093/1093 [==============================] - 17s 13ms/step - loss: 0.4334 - accuracy: 0.8611 - val_loss: 0.3125 - val_accuracy: 0.9160\n",
      "Epoch 2/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.2227 - accuracy: 0.9386 - val_loss: 0.2687 - val_accuracy: 0.9277\n",
      "Epoch 3/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1940 - accuracy: 0.9463 - val_loss: 0.2584 - val_accuracy: 0.9291\n",
      "Epoch 4/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1766 - accuracy: 0.9523 - val_loss: 0.2541 - val_accuracy: 0.9357\n",
      "Epoch 5/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1706 - accuracy: 0.9523 - val_loss: 0.2541 - val_accuracy: 0.9330\n",
      "Epoch 6/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1631 - accuracy: 0.9537 - val_loss: 0.2586 - val_accuracy: 0.9318\n",
      "Epoch 7/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1677 - accuracy: 0.9515 - val_loss: 0.2530 - val_accuracy: 0.9325\n",
      "Epoch 8/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1630 - accuracy: 0.9549 - val_loss: 0.2560 - val_accuracy: 0.9302\n",
      "Epoch 9/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1567 - accuracy: 0.9560 - val_loss: 0.2565 - val_accuracy: 0.9318\n",
      "Epoch 10/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1592 - accuracy: 0.9561 - val_loss: 0.2606 - val_accuracy: 0.9314\n",
      "Epoch 11/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1568 - accuracy: 0.9567 - val_loss: 0.2578 - val_accuracy: 0.9321\n",
      "Epoch 12/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1495 - accuracy: 0.9583 - val_loss: 0.2547 - val_accuracy: 0.9332\n",
      "Epoch 13/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1512 - accuracy: 0.9581 - val_loss: 0.2575 - val_accuracy: 0.9318\n",
      "Epoch 14/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1501 - accuracy: 0.9575 - val_loss: 0.2521 - val_accuracy: 0.9323\n",
      "Epoch 15/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1513 - accuracy: 0.9580 - val_loss: 0.2552 - val_accuracy: 0.9327\n",
      "Epoch 16/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1476 - accuracy: 0.9592 - val_loss: 0.2511 - val_accuracy: 0.9346\n",
      "Epoch 17/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1477 - accuracy: 0.9591 - val_loss: 0.2527 - val_accuracy: 0.9332\n",
      "Epoch 18/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1494 - accuracy: 0.9577 - val_loss: 0.2606 - val_accuracy: 0.9282\n",
      "Epoch 19/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1467 - accuracy: 0.9585 - val_loss: 0.2567 - val_accuracy: 0.9300\n",
      "Epoch 20/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1438 - accuracy: 0.9592 - val_loss: 0.2571 - val_accuracy: 0.9309\n",
      "Epoch 21/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1454 - accuracy: 0.9593 - val_loss: 0.2554 - val_accuracy: 0.9307\n",
      "Epoch 22/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1437 - accuracy: 0.9599 - val_loss: 0.2577 - val_accuracy: 0.9311\n",
      "Epoch 23/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1383 - accuracy: 0.9619 - val_loss: 0.2609 - val_accuracy: 0.9316\n",
      "Epoch 24/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1416 - accuracy: 0.9602 - val_loss: 0.2576 - val_accuracy: 0.9327\n",
      "Epoch 25/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1397 - accuracy: 0.9612 - val_loss: 0.2589 - val_accuracy: 0.9327\n",
      "Epoch 26/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1368 - accuracy: 0.9627 - val_loss: 0.2596 - val_accuracy: 0.9327\n",
      "Epoch 27/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1365 - accuracy: 0.9621 - val_loss: 0.2626 - val_accuracy: 0.9300\n",
      "Epoch 28/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1400 - accuracy: 0.9615 - val_loss: 0.2576 - val_accuracy: 0.9316\n",
      "Epoch 29/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1393 - accuracy: 0.9609 - val_loss: 0.2531 - val_accuracy: 0.9334\n",
      "Epoch 30/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1388 - accuracy: 0.9619 - val_loss: 0.2562 - val_accuracy: 0.9348\n",
      "Epoch 31/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1339 - accuracy: 0.9638 - val_loss: 0.2664 - val_accuracy: 0.9286\n",
      "Epoch 32/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1372 - accuracy: 0.9614 - val_loss: 0.2588 - val_accuracy: 0.9314\n",
      "Epoch 33/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1399 - accuracy: 0.9614 - val_loss: 0.2585 - val_accuracy: 0.9339\n",
      "Epoch 34/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1357 - accuracy: 0.9619 - val_loss: 0.2618 - val_accuracy: 0.9295\n",
      "Epoch 35/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1345 - accuracy: 0.9629 - val_loss: 0.2527 - val_accuracy: 0.9321\n",
      "Epoch 36/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1379 - accuracy: 0.9621 - val_loss: 0.2547 - val_accuracy: 0.9323\n",
      "Epoch 37/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1315 - accuracy: 0.9643 - val_loss: 0.2543 - val_accuracy: 0.9311\n",
      "Epoch 38/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1334 - accuracy: 0.9637 - val_loss: 0.2577 - val_accuracy: 0.9318\n",
      "Epoch 39/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1352 - accuracy: 0.9628 - val_loss: 0.2557 - val_accuracy: 0.9327\n",
      "Epoch 40/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1363 - accuracy: 0.9613 - val_loss: 0.2567 - val_accuracy: 0.9343\n",
      "Epoch 41/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1340 - accuracy: 0.9631 - val_loss: 0.2582 - val_accuracy: 0.9309\n",
      "Epoch 42/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1310 - accuracy: 0.9641 - val_loss: 0.2572 - val_accuracy: 0.9311\n",
      "Epoch 43/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1352 - accuracy: 0.9625 - val_loss: 0.2600 - val_accuracy: 0.9300\n",
      "Epoch 44/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1351 - accuracy: 0.9629 - val_loss: 0.2606 - val_accuracy: 0.9282\n",
      "Epoch 45/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1335 - accuracy: 0.9623 - val_loss: 0.2525 - val_accuracy: 0.9307\n",
      "Epoch 46/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1374 - accuracy: 0.9602 - val_loss: 0.2596 - val_accuracy: 0.9279\n",
      "Epoch 47/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1293 - accuracy: 0.9645 - val_loss: 0.2561 - val_accuracy: 0.9302\n",
      "Epoch 48/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1330 - accuracy: 0.9637 - val_loss: 0.2536 - val_accuracy: 0.9305\n",
      "Epoch 49/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1306 - accuracy: 0.9638 - val_loss: 0.2649 - val_accuracy: 0.9293\n",
      "Epoch 50/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1318 - accuracy: 0.9644 - val_loss: 0.2576 - val_accuracy: 0.9314\n",
      "Epoch 51/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1319 - accuracy: 0.9633 - val_loss: 0.2625 - val_accuracy: 0.9316\n",
      "Epoch 52/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1331 - accuracy: 0.9638 - val_loss: 0.2539 - val_accuracy: 0.9323\n",
      "Epoch 53/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1314 - accuracy: 0.9637 - val_loss: 0.2582 - val_accuracy: 0.9309\n",
      "Epoch 54/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1295 - accuracy: 0.9644 - val_loss: 0.2576 - val_accuracy: 0.9325\n",
      "Epoch 55/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1301 - accuracy: 0.9643 - val_loss: 0.2548 - val_accuracy: 0.9323\n",
      "Epoch 56/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1312 - accuracy: 0.9641 - val_loss: 0.2627 - val_accuracy: 0.9293\n",
      "Epoch 57/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1307 - accuracy: 0.9639 - val_loss: 0.2541 - val_accuracy: 0.9339\n",
      "Epoch 58/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1292 - accuracy: 0.9648 - val_loss: 0.2579 - val_accuracy: 0.9309\n",
      "Epoch 59/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1278 - accuracy: 0.9648 - val_loss: 0.2542 - val_accuracy: 0.9359\n",
      "Epoch 60/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1289 - accuracy: 0.9643 - val_loss: 0.2591 - val_accuracy: 0.9309\n",
      "Epoch 61/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1251 - accuracy: 0.9670 - val_loss: 0.2566 - val_accuracy: 0.9330\n",
      "Epoch 62/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1292 - accuracy: 0.9649 - val_loss: 0.2641 - val_accuracy: 0.9288\n",
      "Epoch 63/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1269 - accuracy: 0.9649 - val_loss: 0.2546 - val_accuracy: 0.9321\n",
      "Epoch 64/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1291 - accuracy: 0.9640 - val_loss: 0.2617 - val_accuracy: 0.9307\n",
      "Epoch 65/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1261 - accuracy: 0.9657 - val_loss: 0.2655 - val_accuracy: 0.9327\n",
      "Epoch 66/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1275 - accuracy: 0.9651 - val_loss: 0.2550 - val_accuracy: 0.9318\n",
      "Epoch 67/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1290 - accuracy: 0.9642 - val_loss: 0.2626 - val_accuracy: 0.9307\n",
      "Epoch 68/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1269 - accuracy: 0.9655 - val_loss: 0.2594 - val_accuracy: 0.9314\n",
      "Epoch 69/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1296 - accuracy: 0.9650 - val_loss: 0.2600 - val_accuracy: 0.9293\n",
      "Epoch 70/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1243 - accuracy: 0.9662 - val_loss: 0.2623 - val_accuracy: 0.9334\n",
      "Epoch 71/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1259 - accuracy: 0.9658 - val_loss: 0.2570 - val_accuracy: 0.9318\n",
      "Epoch 72/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1263 - accuracy: 0.9651 - val_loss: 0.2598 - val_accuracy: 0.9327\n",
      "Epoch 73/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1274 - accuracy: 0.9667 - val_loss: 0.2613 - val_accuracy: 0.9300\n",
      "Epoch 74/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1256 - accuracy: 0.9657 - val_loss: 0.2574 - val_accuracy: 0.9316\n",
      "Epoch 75/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1251 - accuracy: 0.9654 - val_loss: 0.2496 - val_accuracy: 0.9348\n",
      "Epoch 76/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1263 - accuracy: 0.9659 - val_loss: 0.2614 - val_accuracy: 0.9330\n",
      "Epoch 77/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1226 - accuracy: 0.9668 - val_loss: 0.2715 - val_accuracy: 0.9291\n",
      "Epoch 78/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1267 - accuracy: 0.9660 - val_loss: 0.2588 - val_accuracy: 0.9330\n",
      "Epoch 79/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1233 - accuracy: 0.9662 - val_loss: 0.2580 - val_accuracy: 0.9337\n",
      "Epoch 80/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1222 - accuracy: 0.9659 - val_loss: 0.2601 - val_accuracy: 0.9307\n",
      "Epoch 81/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1251 - accuracy: 0.9655 - val_loss: 0.2626 - val_accuracy: 0.9325\n",
      "Epoch 82/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1233 - accuracy: 0.9670 - val_loss: 0.2628 - val_accuracy: 0.9314\n",
      "Epoch 83/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1260 - accuracy: 0.9652 - val_loss: 0.2640 - val_accuracy: 0.9316\n",
      "Epoch 84/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1226 - accuracy: 0.9668 - val_loss: 0.2590 - val_accuracy: 0.9325\n",
      "Epoch 85/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1201 - accuracy: 0.9679 - val_loss: 0.2593 - val_accuracy: 0.9330\n",
      "Epoch 86/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1220 - accuracy: 0.9659 - val_loss: 0.2555 - val_accuracy: 0.9302\n",
      "Epoch 87/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1221 - accuracy: 0.9671 - val_loss: 0.2622 - val_accuracy: 0.9298\n",
      "Epoch 88/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1183 - accuracy: 0.9683 - val_loss: 0.2606 - val_accuracy: 0.9325\n",
      "Epoch 89/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1218 - accuracy: 0.9672 - val_loss: 0.2605 - val_accuracy: 0.9346\n",
      "Epoch 90/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1230 - accuracy: 0.9664 - val_loss: 0.2534 - val_accuracy: 0.9330\n",
      "Epoch 91/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1218 - accuracy: 0.9678 - val_loss: 0.2544 - val_accuracy: 0.9348\n",
      "Epoch 92/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1211 - accuracy: 0.9672 - val_loss: 0.2634 - val_accuracy: 0.9330\n",
      "Epoch 93/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1217 - accuracy: 0.9668 - val_loss: 0.2587 - val_accuracy: 0.9341\n",
      "Epoch 94/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1190 - accuracy: 0.9678 - val_loss: 0.2627 - val_accuracy: 0.9307\n",
      "Epoch 95/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1185 - accuracy: 0.9685 - val_loss: 0.2584 - val_accuracy: 0.9332\n",
      "Epoch 96/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1212 - accuracy: 0.9679 - val_loss: 0.2659 - val_accuracy: 0.9300\n",
      "Epoch 97/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1196 - accuracy: 0.9683 - val_loss: 0.2604 - val_accuracy: 0.9332\n",
      "Epoch 98/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1203 - accuracy: 0.9667 - val_loss: 0.2550 - val_accuracy: 0.9309\n",
      "Epoch 99/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1163 - accuracy: 0.9692 - val_loss: 0.2680 - val_accuracy: 0.9288\n",
      "Epoch 100/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1171 - accuracy: 0.9679 - val_loss: 0.2671 - val_accuracy: 0.9318\n",
      "Epoch 101/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1161 - accuracy: 0.9688 - val_loss: 0.2570 - val_accuracy: 0.9371\n",
      "Epoch 102/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1187 - accuracy: 0.9667 - val_loss: 0.2551 - val_accuracy: 0.9348\n",
      "Epoch 103/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1150 - accuracy: 0.9690 - val_loss: 0.2658 - val_accuracy: 0.9321\n",
      "Epoch 104/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1161 - accuracy: 0.9677 - val_loss: 0.2662 - val_accuracy: 0.9323\n",
      "Epoch 105/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1131 - accuracy: 0.9710 - val_loss: 0.2659 - val_accuracy: 0.9305\n",
      "Epoch 106/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1149 - accuracy: 0.9692 - val_loss: 0.2591 - val_accuracy: 0.9359\n",
      "Epoch 107/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1135 - accuracy: 0.9697 - val_loss: 0.2661 - val_accuracy: 0.9302\n",
      "Epoch 108/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1130 - accuracy: 0.9702 - val_loss: 0.2665 - val_accuracy: 0.9300\n",
      "Epoch 109/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1135 - accuracy: 0.9706 - val_loss: 0.2614 - val_accuracy: 0.9332\n",
      "Epoch 110/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1125 - accuracy: 0.9708 - val_loss: 0.2559 - val_accuracy: 0.9323\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1155 - accuracy: 0.9689 - val_loss: 0.2581 - val_accuracy: 0.9321\n",
      "Epoch 112/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1131 - accuracy: 0.9693 - val_loss: 0.2669 - val_accuracy: 0.9318\n",
      "Epoch 113/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1167 - accuracy: 0.9682 - val_loss: 0.2656 - val_accuracy: 0.9332\n",
      "Epoch 114/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1143 - accuracy: 0.9699 - val_loss: 0.2616 - val_accuracy: 0.9350\n",
      "Epoch 115/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1142 - accuracy: 0.9696 - val_loss: 0.2608 - val_accuracy: 0.9327\n",
      "Epoch 116/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1112 - accuracy: 0.9706 - val_loss: 0.2640 - val_accuracy: 0.9321\n",
      "Epoch 117/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1133 - accuracy: 0.9697 - val_loss: 0.2644 - val_accuracy: 0.9337\n",
      "Epoch 118/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1119 - accuracy: 0.9704 - val_loss: 0.2645 - val_accuracy: 0.9353\n",
      "Epoch 119/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1092 - accuracy: 0.9714 - val_loss: 0.2633 - val_accuracy: 0.9325\n",
      "Epoch 120/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1103 - accuracy: 0.9711 - val_loss: 0.2657 - val_accuracy: 0.9305\n",
      "Epoch 121/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1089 - accuracy: 0.9719 - val_loss: 0.2691 - val_accuracy: 0.9318\n",
      "Epoch 122/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1079 - accuracy: 0.9721 - val_loss: 0.2619 - val_accuracy: 0.9348\n",
      "Epoch 123/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1074 - accuracy: 0.9717 - val_loss: 0.2602 - val_accuracy: 0.9337\n",
      "Epoch 124/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1063 - accuracy: 0.9717 - val_loss: 0.2659 - val_accuracy: 0.9327\n",
      "Epoch 125/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1093 - accuracy: 0.9713 - val_loss: 0.2680 - val_accuracy: 0.9341\n",
      "Epoch 126/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1037 - accuracy: 0.9730 - val_loss: 0.2685 - val_accuracy: 0.9316\n",
      "Epoch 127/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1051 - accuracy: 0.9730 - val_loss: 0.2667 - val_accuracy: 0.9314\n",
      "Epoch 128/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1041 - accuracy: 0.9726 - val_loss: 0.2620 - val_accuracy: 0.9373\n",
      "Epoch 129/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 0.2670 - val_accuracy: 0.9334\n",
      "Epoch 130/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1021 - accuracy: 0.9746 - val_loss: 0.2625 - val_accuracy: 0.9321\n",
      "Epoch 131/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1011 - accuracy: 0.9745 - val_loss: 0.2599 - val_accuracy: 0.9332\n",
      "Epoch 132/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1008 - accuracy: 0.9741 - val_loss: 0.2650 - val_accuracy: 0.9334\n",
      "Epoch 133/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1007 - accuracy: 0.9751 - val_loss: 0.2633 - val_accuracy: 0.9323\n",
      "Epoch 134/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1007 - accuracy: 0.9738 - val_loss: 0.2662 - val_accuracy: 0.9321\n",
      "Epoch 135/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.0965 - accuracy: 0.9769 - val_loss: 0.2634 - val_accuracy: 0.9327\n",
      "Epoch 136/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0958 - accuracy: 0.9764 - val_loss: 0.2636 - val_accuracy: 0.9346\n",
      "Epoch 137/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0979 - accuracy: 0.9761 - val_loss: 0.2720 - val_accuracy: 0.9327\n",
      "Epoch 138/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0948 - accuracy: 0.9766 - val_loss: 0.2693 - val_accuracy: 0.9309\n",
      "Epoch 139/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0910 - accuracy: 0.9790 - val_loss: 0.2784 - val_accuracy: 0.9298\n",
      "Epoch 140/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0880 - accuracy: 0.9795 - val_loss: 0.2666 - val_accuracy: 0.9350\n",
      "Epoch 141/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.0839 - accuracy: 0.9813 - val_loss: 0.2671 - val_accuracy: 0.9339\n",
      "Epoch 142/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1312 - accuracy: 0.9643 - val_loss: 0.2665 - val_accuracy: 0.9334\n",
      "Epoch 143/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1294 - accuracy: 0.9643 - val_loss: 0.2584 - val_accuracy: 0.9346\n",
      "Epoch 144/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1275 - accuracy: 0.9655 - val_loss: 0.2642 - val_accuracy: 0.9337\n",
      "Epoch 145/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1278 - accuracy: 0.9654 - val_loss: 0.2614 - val_accuracy: 0.9362\n",
      "Epoch 146/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1242 - accuracy: 0.9663 - val_loss: 0.2693 - val_accuracy: 0.9316\n",
      "Epoch 147/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1266 - accuracy: 0.9661 - val_loss: 0.2615 - val_accuracy: 0.9334\n",
      "Epoch 148/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1276 - accuracy: 0.9650 - val_loss: 0.2580 - val_accuracy: 0.9373\n",
      "Epoch 149/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1261 - accuracy: 0.9641 - val_loss: 0.2643 - val_accuracy: 0.9314\n",
      "Epoch 150/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1265 - accuracy: 0.9653 - val_loss: 0.2700 - val_accuracy: 0.9272\n",
      "Epoch 151/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1283 - accuracy: 0.9639 - val_loss: 0.2660 - val_accuracy: 0.9300\n",
      "Epoch 152/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1294 - accuracy: 0.9641 - val_loss: 0.2635 - val_accuracy: 0.9318\n",
      "Epoch 153/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1240 - accuracy: 0.9661 - val_loss: 0.2579 - val_accuracy: 0.9325\n",
      "Epoch 154/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1264 - accuracy: 0.9649 - val_loss: 0.2720 - val_accuracy: 0.9302\n",
      "Epoch 155/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1249 - accuracy: 0.9654 - val_loss: 0.2568 - val_accuracy: 0.9346\n",
      "Epoch 156/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1266 - accuracy: 0.9656 - val_loss: 0.2658 - val_accuracy: 0.9298\n",
      "Epoch 157/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1237 - accuracy: 0.9666 - val_loss: 0.2585 - val_accuracy: 0.9318\n",
      "Epoch 158/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1279 - accuracy: 0.9644 - val_loss: 0.2648 - val_accuracy: 0.9323\n",
      "Epoch 159/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1231 - accuracy: 0.9666 - val_loss: 0.2694 - val_accuracy: 0.9327\n",
      "Epoch 160/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1263 - accuracy: 0.9652 - val_loss: 0.2571 - val_accuracy: 0.9330\n",
      "Epoch 161/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1247 - accuracy: 0.9661 - val_loss: 0.2668 - val_accuracy: 0.9314\n",
      "Epoch 162/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1257 - accuracy: 0.9662 - val_loss: 0.2656 - val_accuracy: 0.9323\n",
      "Epoch 163/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1258 - accuracy: 0.9657 - val_loss: 0.2692 - val_accuracy: 0.9337\n",
      "Epoch 164/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1237 - accuracy: 0.9651 - val_loss: 0.2680 - val_accuracy: 0.9330\n",
      "Epoch 165/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1262 - accuracy: 0.9653 - val_loss: 0.2622 - val_accuracy: 0.9348\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1229 - accuracy: 0.9670 - val_loss: 0.2679 - val_accuracy: 0.9334\n",
      "Epoch 167/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1246 - accuracy: 0.9667 - val_loss: 0.2566 - val_accuracy: 0.9348\n",
      "Epoch 168/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1209 - accuracy: 0.9672 - val_loss: 0.2587 - val_accuracy: 0.9337\n",
      "Epoch 169/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1245 - accuracy: 0.9657 - val_loss: 0.2644 - val_accuracy: 0.9330\n",
      "Epoch 170/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1218 - accuracy: 0.9676 - val_loss: 0.2575 - val_accuracy: 0.9341\n",
      "Epoch 171/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1240 - accuracy: 0.9663 - val_loss: 0.2560 - val_accuracy: 0.9339\n",
      "Epoch 172/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1238 - accuracy: 0.9669 - val_loss: 0.2668 - val_accuracy: 0.9337\n",
      "Epoch 173/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1254 - accuracy: 0.9658 - val_loss: 0.2579 - val_accuracy: 0.9332\n",
      "Epoch 174/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1245 - accuracy: 0.9653 - val_loss: 0.2628 - val_accuracy: 0.9316\n",
      "Epoch 175/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1258 - accuracy: 0.9663 - val_loss: 0.2542 - val_accuracy: 0.9332\n",
      "Epoch 176/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1224 - accuracy: 0.9668 - val_loss: 0.2605 - val_accuracy: 0.9330\n",
      "Epoch 177/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1254 - accuracy: 0.9653 - val_loss: 0.2618 - val_accuracy: 0.9343\n",
      "Epoch 178/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1199 - accuracy: 0.9672 - val_loss: 0.2583 - val_accuracy: 0.9325\n",
      "Epoch 179/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1264 - accuracy: 0.9643 - val_loss: 0.2574 - val_accuracy: 0.9362\n",
      "Epoch 180/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1233 - accuracy: 0.9664 - val_loss: 0.2571 - val_accuracy: 0.9337\n",
      "Epoch 181/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1212 - accuracy: 0.9678 - val_loss: 0.2638 - val_accuracy: 0.9316\n",
      "Epoch 182/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1253 - accuracy: 0.9655 - val_loss: 0.2608 - val_accuracy: 0.9353\n",
      "Epoch 183/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1250 - accuracy: 0.9658 - val_loss: 0.2652 - val_accuracy: 0.9311\n",
      "Epoch 184/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1219 - accuracy: 0.9663 - val_loss: 0.2618 - val_accuracy: 0.9330\n",
      "Epoch 185/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1242 - accuracy: 0.9663 - val_loss: 0.2625 - val_accuracy: 0.9323\n",
      "Epoch 186/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1204 - accuracy: 0.9673 - val_loss: 0.2627 - val_accuracy: 0.9348\n",
      "Epoch 187/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1253 - accuracy: 0.9641 - val_loss: 0.2627 - val_accuracy: 0.9339\n",
      "Epoch 188/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1221 - accuracy: 0.9655 - val_loss: 0.2591 - val_accuracy: 0.9357\n",
      "Epoch 189/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1244 - accuracy: 0.9658 - val_loss: 0.2674 - val_accuracy: 0.9337\n",
      "Epoch 190/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1223 - accuracy: 0.9663 - val_loss: 0.2684 - val_accuracy: 0.9330\n",
      "Epoch 191/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1229 - accuracy: 0.9656 - val_loss: 0.2644 - val_accuracy: 0.9311\n",
      "Epoch 192/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1225 - accuracy: 0.9668 - val_loss: 0.2616 - val_accuracy: 0.9334\n",
      "Epoch 193/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1234 - accuracy: 0.9655 - val_loss: 0.2652 - val_accuracy: 0.9337\n",
      "Epoch 194/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1202 - accuracy: 0.9668 - val_loss: 0.2557 - val_accuracy: 0.9332\n",
      "Epoch 195/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1209 - accuracy: 0.9668 - val_loss: 0.2580 - val_accuracy: 0.9350\n",
      "Epoch 196/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1211 - accuracy: 0.9664 - val_loss: 0.2647 - val_accuracy: 0.9330\n",
      "Epoch 197/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1198 - accuracy: 0.9669 - val_loss: 0.2698 - val_accuracy: 0.9337\n",
      "Epoch 198/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1231 - accuracy: 0.9652 - val_loss: 0.2727 - val_accuracy: 0.9302\n",
      "Epoch 199/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1195 - accuracy: 0.9671 - val_loss: 0.2639 - val_accuracy: 0.9327\n",
      "Epoch 200/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1227 - accuracy: 0.9662 - val_loss: 0.2647 - val_accuracy: 0.9314\n",
      "Epoch 201/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1210 - accuracy: 0.9673 - val_loss: 0.2668 - val_accuracy: 0.9330\n",
      "Epoch 202/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1197 - accuracy: 0.9677 - val_loss: 0.2717 - val_accuracy: 0.9321\n",
      "Epoch 203/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1203 - accuracy: 0.9669 - val_loss: 0.2669 - val_accuracy: 0.9309\n",
      "Epoch 204/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1201 - accuracy: 0.9675 - val_loss: 0.2645 - val_accuracy: 0.9341\n",
      "Epoch 205/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1221 - accuracy: 0.9674 - val_loss: 0.2639 - val_accuracy: 0.9330\n",
      "Epoch 206/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1214 - accuracy: 0.9668 - val_loss: 0.2650 - val_accuracy: 0.9337\n",
      "Epoch 207/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1216 - accuracy: 0.9664 - val_loss: 0.2622 - val_accuracy: 0.9343\n",
      "Epoch 208/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1181 - accuracy: 0.9679 - val_loss: 0.2662 - val_accuracy: 0.9330\n",
      "Epoch 209/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1189 - accuracy: 0.9678 - val_loss: 0.2650 - val_accuracy: 0.9327\n",
      "Epoch 210/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1161 - accuracy: 0.9684 - val_loss: 0.2670 - val_accuracy: 0.9314\n",
      "Epoch 211/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1227 - accuracy: 0.9655 - val_loss: 0.2658 - val_accuracy: 0.9316\n",
      "Epoch 212/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1190 - accuracy: 0.9674 - val_loss: 0.2565 - val_accuracy: 0.9366\n",
      "Epoch 213/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1196 - accuracy: 0.9668 - val_loss: 0.2650 - val_accuracy: 0.9339\n",
      "Epoch 214/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1146 - accuracy: 0.9702 - val_loss: 0.2625 - val_accuracy: 0.9334\n",
      "Epoch 215/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1209 - accuracy: 0.9673 - val_loss: 0.2527 - val_accuracy: 0.9346\n",
      "Epoch 216/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1201 - accuracy: 0.9674 - val_loss: 0.2611 - val_accuracy: 0.9355\n",
      "Epoch 217/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1246 - accuracy: 0.9658 - val_loss: 0.2601 - val_accuracy: 0.9332\n",
      "Epoch 218/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1234 - accuracy: 0.9666 - val_loss: 0.2555 - val_accuracy: 0.9346\n",
      "Epoch 219/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1209 - accuracy: 0.9672 - val_loss: 0.2587 - val_accuracy: 0.9343\n",
      "Epoch 220/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1223 - accuracy: 0.9661 - val_loss: 0.2574 - val_accuracy: 0.9350\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1184 - accuracy: 0.9681 - val_loss: 0.2661 - val_accuracy: 0.9346\n",
      "Epoch 222/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1253 - accuracy: 0.9651 - val_loss: 0.2650 - val_accuracy: 0.9323\n",
      "Epoch 223/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1177 - accuracy: 0.9669 - val_loss: 0.2582 - val_accuracy: 0.9332\n",
      "Epoch 224/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1196 - accuracy: 0.9670 - val_loss: 0.2620 - val_accuracy: 0.9337\n",
      "Epoch 225/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1199 - accuracy: 0.9671 - val_loss: 0.2627 - val_accuracy: 0.9330\n",
      "Epoch 226/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1178 - accuracy: 0.9681 - val_loss: 0.2567 - val_accuracy: 0.9332\n",
      "Epoch 227/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1235 - accuracy: 0.9666 - val_loss: 0.2546 - val_accuracy: 0.9343\n",
      "Epoch 228/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1176 - accuracy: 0.9680 - val_loss: 0.2531 - val_accuracy: 0.9359\n",
      "Epoch 229/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1177 - accuracy: 0.9676 - val_loss: 0.2649 - val_accuracy: 0.9314\n",
      "Epoch 230/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1224 - accuracy: 0.9662 - val_loss: 0.2581 - val_accuracy: 0.9362\n",
      "Epoch 231/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1169 - accuracy: 0.9687 - val_loss: 0.2618 - val_accuracy: 0.9337\n",
      "Epoch 232/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1156 - accuracy: 0.9683 - val_loss: 0.2556 - val_accuracy: 0.9343\n",
      "Epoch 233/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1205 - accuracy: 0.9677 - val_loss: 0.2648 - val_accuracy: 0.9346\n",
      "Epoch 234/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1178 - accuracy: 0.9680 - val_loss: 0.2634 - val_accuracy: 0.9348\n",
      "Epoch 235/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1196 - accuracy: 0.9682 - val_loss: 0.2610 - val_accuracy: 0.9346\n",
      "Epoch 236/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1179 - accuracy: 0.9677 - val_loss: 0.2523 - val_accuracy: 0.9341\n",
      "Epoch 237/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1185 - accuracy: 0.9682 - val_loss: 0.2580 - val_accuracy: 0.9330\n",
      "Epoch 238/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1190 - accuracy: 0.9688 - val_loss: 0.2597 - val_accuracy: 0.9355\n",
      "Epoch 239/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1180 - accuracy: 0.9676 - val_loss: 0.2650 - val_accuracy: 0.9318\n",
      "Epoch 240/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1204 - accuracy: 0.9659 - val_loss: 0.2626 - val_accuracy: 0.9330\n",
      "Epoch 241/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1202 - accuracy: 0.9668 - val_loss: 0.2619 - val_accuracy: 0.9327\n",
      "Epoch 242/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1181 - accuracy: 0.9679 - val_loss: 0.2652 - val_accuracy: 0.9298\n",
      "Epoch 243/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1190 - accuracy: 0.9673 - val_loss: 0.2680 - val_accuracy: 0.9321\n",
      "Epoch 244/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1199 - accuracy: 0.9682 - val_loss: 0.2614 - val_accuracy: 0.9318\n",
      "Epoch 245/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1154 - accuracy: 0.9695 - val_loss: 0.2673 - val_accuracy: 0.9307\n",
      "Epoch 246/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1183 - accuracy: 0.9681 - val_loss: 0.2659 - val_accuracy: 0.9339\n",
      "Epoch 247/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1201 - accuracy: 0.9674 - val_loss: 0.2634 - val_accuracy: 0.9330\n",
      "Epoch 248/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1165 - accuracy: 0.9688 - val_loss: 0.2656 - val_accuracy: 0.9311\n",
      "Epoch 249/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1201 - accuracy: 0.9674 - val_loss: 0.2623 - val_accuracy: 0.9321\n",
      "Epoch 250/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1169 - accuracy: 0.9681 - val_loss: 0.2633 - val_accuracy: 0.9314\n",
      "Epoch 251/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1173 - accuracy: 0.9684 - val_loss: 0.2648 - val_accuracy: 0.9327\n",
      "Epoch 252/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1240 - accuracy: 0.9657 - val_loss: 0.2643 - val_accuracy: 0.9353\n",
      "Epoch 253/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1189 - accuracy: 0.9675 - val_loss: 0.2636 - val_accuracy: 0.9330\n",
      "Epoch 254/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1166 - accuracy: 0.9678 - val_loss: 0.2628 - val_accuracy: 0.9337\n",
      "Epoch 255/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1170 - accuracy: 0.9675 - val_loss: 0.2573 - val_accuracy: 0.9362\n",
      "Epoch 256/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1157 - accuracy: 0.9689 - val_loss: 0.2647 - val_accuracy: 0.9341\n",
      "Epoch 257/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1156 - accuracy: 0.9682 - val_loss: 0.2659 - val_accuracy: 0.9321\n",
      "Epoch 258/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1198 - accuracy: 0.9671 - val_loss: 0.2634 - val_accuracy: 0.9334\n",
      "Epoch 259/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1143 - accuracy: 0.9688 - val_loss: 0.2651 - val_accuracy: 0.9339\n",
      "Epoch 260/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1178 - accuracy: 0.9675 - val_loss: 0.2596 - val_accuracy: 0.9359\n",
      "Epoch 261/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1197 - accuracy: 0.9668 - val_loss: 0.2586 - val_accuracy: 0.9353\n",
      "Epoch 262/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1150 - accuracy: 0.9699 - val_loss: 0.2591 - val_accuracy: 0.9359\n",
      "Epoch 263/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1191 - accuracy: 0.9677 - val_loss: 0.2600 - val_accuracy: 0.9350\n",
      "Epoch 264/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1162 - accuracy: 0.9692 - val_loss: 0.2623 - val_accuracy: 0.9318\n",
      "Epoch 265/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1178 - accuracy: 0.9683 - val_loss: 0.2590 - val_accuracy: 0.9341\n",
      "Epoch 266/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1160 - accuracy: 0.9687 - val_loss: 0.2683 - val_accuracy: 0.9337\n",
      "Epoch 267/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1177 - accuracy: 0.9674 - val_loss: 0.2599 - val_accuracy: 0.9355\n",
      "Epoch 268/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1143 - accuracy: 0.9692 - val_loss: 0.2670 - val_accuracy: 0.9337\n",
      "Epoch 269/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1164 - accuracy: 0.9688 - val_loss: 0.2658 - val_accuracy: 0.9332\n",
      "Epoch 270/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1169 - accuracy: 0.9684 - val_loss: 0.2587 - val_accuracy: 0.9346\n",
      "Epoch 271/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1165 - accuracy: 0.9685 - val_loss: 0.2625 - val_accuracy: 0.9337\n",
      "Epoch 272/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1163 - accuracy: 0.9685 - val_loss: 0.2760 - val_accuracy: 0.9302\n",
      "Epoch 273/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1158 - accuracy: 0.9688 - val_loss: 0.2633 - val_accuracy: 0.9353\n",
      "Epoch 274/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1152 - accuracy: 0.9682 - val_loss: 0.2651 - val_accuracy: 0.9362\n",
      "Epoch 275/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1170 - accuracy: 0.9680 - val_loss: 0.2742 - val_accuracy: 0.9321\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1202 - accuracy: 0.9675 - val_loss: 0.2710 - val_accuracy: 0.9321\n",
      "Epoch 277/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1156 - accuracy: 0.9687 - val_loss: 0.2664 - val_accuracy: 0.9307\n",
      "Epoch 278/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1169 - accuracy: 0.9684 - val_loss: 0.2644 - val_accuracy: 0.9316\n",
      "Epoch 279/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1183 - accuracy: 0.9676 - val_loss: 0.2633 - val_accuracy: 0.9341\n",
      "Epoch 280/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1181 - accuracy: 0.9677 - val_loss: 0.2683 - val_accuracy: 0.9325\n",
      "Epoch 281/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1177 - accuracy: 0.9684 - val_loss: 0.2555 - val_accuracy: 0.9362\n",
      "Epoch 282/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1149 - accuracy: 0.9688 - val_loss: 0.2637 - val_accuracy: 0.9339\n",
      "Epoch 283/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1197 - accuracy: 0.9683 - val_loss: 0.2597 - val_accuracy: 0.9348\n",
      "Epoch 284/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1160 - accuracy: 0.9690 - val_loss: 0.2687 - val_accuracy: 0.9307\n",
      "Epoch 285/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1156 - accuracy: 0.9689 - val_loss: 0.2636 - val_accuracy: 0.9330\n",
      "Epoch 286/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1153 - accuracy: 0.9691 - val_loss: 0.2664 - val_accuracy: 0.9334\n",
      "Epoch 287/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1141 - accuracy: 0.9701 - val_loss: 0.2666 - val_accuracy: 0.9355\n",
      "Epoch 288/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1150 - accuracy: 0.9693 - val_loss: 0.2591 - val_accuracy: 0.9341\n",
      "Epoch 289/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1178 - accuracy: 0.9688 - val_loss: 0.2671 - val_accuracy: 0.9311\n",
      "Epoch 290/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1194 - accuracy: 0.9661 - val_loss: 0.2526 - val_accuracy: 0.9378\n",
      "Epoch 291/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1201 - accuracy: 0.9673 - val_loss: 0.2680 - val_accuracy: 0.9339\n",
      "Epoch 292/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1198 - accuracy: 0.9667 - val_loss: 0.2628 - val_accuracy: 0.9343\n",
      "Epoch 293/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1166 - accuracy: 0.9682 - val_loss: 0.2575 - val_accuracy: 0.9337\n",
      "Epoch 294/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1194 - accuracy: 0.9685 - val_loss: 0.2610 - val_accuracy: 0.9346\n",
      "Epoch 295/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1177 - accuracy: 0.9679 - val_loss: 0.2602 - val_accuracy: 0.9350\n",
      "Epoch 296/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1153 - accuracy: 0.9691 - val_loss: 0.2657 - val_accuracy: 0.9332\n",
      "Epoch 297/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1149 - accuracy: 0.9695 - val_loss: 0.2702 - val_accuracy: 0.9298\n",
      "Epoch 298/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1229 - accuracy: 0.9669 - val_loss: 0.2627 - val_accuracy: 0.9353\n",
      "Epoch 299/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1128 - accuracy: 0.9704 - val_loss: 0.2664 - val_accuracy: 0.9298\n",
      "Epoch 300/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1147 - accuracy: 0.9690 - val_loss: 0.2660 - val_accuracy: 0.9321\n",
      "Epoch 301/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1171 - accuracy: 0.9677 - val_loss: 0.2611 - val_accuracy: 0.9337\n",
      "Epoch 302/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1181 - accuracy: 0.9680 - val_loss: 0.2635 - val_accuracy: 0.9341\n",
      "Epoch 303/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1187 - accuracy: 0.9678 - val_loss: 0.2636 - val_accuracy: 0.9316\n",
      "Epoch 304/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1169 - accuracy: 0.9689 - val_loss: 0.2711 - val_accuracy: 0.9323\n",
      "Epoch 305/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1143 - accuracy: 0.9697 - val_loss: 0.2653 - val_accuracy: 0.9330\n",
      "Epoch 306/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1154 - accuracy: 0.9682 - val_loss: 0.2700 - val_accuracy: 0.9334\n",
      "Epoch 307/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1175 - accuracy: 0.9680 - val_loss: 0.2597 - val_accuracy: 0.9364\n",
      "Epoch 308/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1171 - accuracy: 0.9682 - val_loss: 0.2742 - val_accuracy: 0.9300\n",
      "Epoch 309/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1129 - accuracy: 0.9696 - val_loss: 0.2696 - val_accuracy: 0.9332\n",
      "Epoch 310/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1139 - accuracy: 0.9697 - val_loss: 0.2796 - val_accuracy: 0.9284\n",
      "Epoch 311/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1137 - accuracy: 0.9689 - val_loss: 0.2723 - val_accuracy: 0.9325\n",
      "Epoch 312/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1197 - accuracy: 0.9664 - val_loss: 0.2652 - val_accuracy: 0.9316\n",
      "Epoch 313/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1147 - accuracy: 0.9690 - val_loss: 0.2664 - val_accuracy: 0.9321\n",
      "Epoch 314/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1139 - accuracy: 0.9694 - val_loss: 0.2637 - val_accuracy: 0.9341\n",
      "Epoch 315/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1132 - accuracy: 0.9690 - val_loss: 0.2715 - val_accuracy: 0.9346\n",
      "Epoch 316/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1155 - accuracy: 0.9685 - val_loss: 0.2547 - val_accuracy: 0.9369\n",
      "Epoch 317/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1147 - accuracy: 0.9702 - val_loss: 0.2589 - val_accuracy: 0.9337\n",
      "Epoch 318/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1153 - accuracy: 0.9684 - val_loss: 0.2564 - val_accuracy: 0.9346\n",
      "Epoch 319/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1116 - accuracy: 0.9701 - val_loss: 0.2596 - val_accuracy: 0.9350\n",
      "Epoch 320/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1141 - accuracy: 0.9693 - val_loss: 0.2574 - val_accuracy: 0.9353\n",
      "Epoch 321/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1155 - accuracy: 0.9690 - val_loss: 0.2656 - val_accuracy: 0.9332\n",
      "Epoch 322/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1171 - accuracy: 0.9689 - val_loss: 0.2601 - val_accuracy: 0.9311\n",
      "Epoch 323/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1135 - accuracy: 0.9692 - val_loss: 0.2668 - val_accuracy: 0.9343\n",
      "Epoch 324/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1142 - accuracy: 0.9693 - val_loss: 0.2628 - val_accuracy: 0.9355\n",
      "Epoch 325/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1137 - accuracy: 0.9693 - val_loss: 0.2636 - val_accuracy: 0.9353\n",
      "Epoch 326/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1153 - accuracy: 0.9682 - val_loss: 0.2689 - val_accuracy: 0.9332\n",
      "Epoch 327/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1151 - accuracy: 0.9676 - val_loss: 0.2694 - val_accuracy: 0.9318\n",
      "Epoch 328/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1136 - accuracy: 0.9698 - val_loss: 0.2599 - val_accuracy: 0.9339\n",
      "Epoch 329/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1117 - accuracy: 0.9720 - val_loss: 0.2565 - val_accuracy: 0.9350\n",
      "Epoch 330/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1143 - accuracy: 0.9697 - val_loss: 0.2672 - val_accuracy: 0.9309\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1157 - accuracy: 0.9686 - val_loss: 0.2620 - val_accuracy: 0.9307\n",
      "Epoch 332/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1140 - accuracy: 0.9692 - val_loss: 0.2685 - val_accuracy: 0.9348\n",
      "Epoch 333/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1135 - accuracy: 0.9686 - val_loss: 0.2663 - val_accuracy: 0.9343\n",
      "Epoch 334/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1122 - accuracy: 0.9700 - val_loss: 0.2704 - val_accuracy: 0.9355\n",
      "Epoch 335/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1134 - accuracy: 0.9693 - val_loss: 0.2588 - val_accuracy: 0.9357\n",
      "Epoch 336/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1171 - accuracy: 0.9688 - val_loss: 0.2570 - val_accuracy: 0.9334\n",
      "Epoch 337/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1152 - accuracy: 0.9694 - val_loss: 0.2597 - val_accuracy: 0.9371\n",
      "Epoch 338/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1134 - accuracy: 0.9694 - val_loss: 0.2544 - val_accuracy: 0.9346\n",
      "Epoch 339/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1110 - accuracy: 0.9703 - val_loss: 0.2672 - val_accuracy: 0.9330\n",
      "Epoch 340/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1124 - accuracy: 0.9693 - val_loss: 0.2619 - val_accuracy: 0.9327\n",
      "Epoch 341/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1136 - accuracy: 0.9692 - val_loss: 0.2615 - val_accuracy: 0.9339\n",
      "Epoch 342/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1144 - accuracy: 0.9688 - val_loss: 0.2650 - val_accuracy: 0.9350\n",
      "Epoch 343/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1162 - accuracy: 0.9681 - val_loss: 0.2639 - val_accuracy: 0.9346\n",
      "Epoch 344/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1140 - accuracy: 0.9700 - val_loss: 0.2635 - val_accuracy: 0.9334\n",
      "Epoch 345/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1139 - accuracy: 0.9685 - val_loss: 0.2611 - val_accuracy: 0.9348\n",
      "Epoch 346/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1186 - accuracy: 0.9671 - val_loss: 0.2674 - val_accuracy: 0.9311\n",
      "Epoch 347/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1169 - accuracy: 0.9685 - val_loss: 0.2594 - val_accuracy: 0.9350\n",
      "Epoch 348/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1150 - accuracy: 0.9678 - val_loss: 0.2633 - val_accuracy: 0.9355\n",
      "Epoch 349/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1108 - accuracy: 0.9706 - val_loss: 0.2669 - val_accuracy: 0.9330\n",
      "Epoch 350/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1112 - accuracy: 0.9697 - val_loss: 0.2592 - val_accuracy: 0.9346\n",
      "Epoch 351/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1109 - accuracy: 0.9698 - val_loss: 0.2671 - val_accuracy: 0.9334\n",
      "Epoch 352/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1172 - accuracy: 0.9683 - val_loss: 0.2644 - val_accuracy: 0.9332\n",
      "Epoch 353/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1125 - accuracy: 0.9694 - val_loss: 0.2649 - val_accuracy: 0.9325\n",
      "Epoch 354/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1140 - accuracy: 0.9698 - val_loss: 0.2654 - val_accuracy: 0.9364\n",
      "Epoch 355/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1121 - accuracy: 0.9696 - val_loss: 0.2688 - val_accuracy: 0.9311\n",
      "Epoch 356/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1124 - accuracy: 0.9703 - val_loss: 0.2673 - val_accuracy: 0.9325\n",
      "Epoch 357/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1145 - accuracy: 0.9697 - val_loss: 0.2665 - val_accuracy: 0.9318\n",
      "Epoch 358/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1153 - accuracy: 0.9684 - val_loss: 0.2646 - val_accuracy: 0.9327\n",
      "Epoch 359/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1101 - accuracy: 0.9710 - val_loss: 0.2680 - val_accuracy: 0.9359\n",
      "Epoch 360/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1110 - accuracy: 0.9710 - val_loss: 0.2621 - val_accuracy: 0.9327\n",
      "Epoch 361/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1129 - accuracy: 0.9695 - val_loss: 0.2725 - val_accuracy: 0.9327\n",
      "Epoch 362/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1143 - accuracy: 0.9688 - val_loss: 0.2716 - val_accuracy: 0.9311\n",
      "Epoch 363/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1121 - accuracy: 0.9700 - val_loss: 0.2615 - val_accuracy: 0.9350\n",
      "Epoch 364/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1133 - accuracy: 0.9691 - val_loss: 0.2672 - val_accuracy: 0.9323\n",
      "Epoch 365/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1123 - accuracy: 0.9706 - val_loss: 0.2681 - val_accuracy: 0.9343\n",
      "Epoch 366/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1130 - accuracy: 0.9690 - val_loss: 0.2650 - val_accuracy: 0.9325\n",
      "Epoch 367/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1082 - accuracy: 0.9722 - val_loss: 0.2637 - val_accuracy: 0.9327\n",
      "Epoch 368/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1126 - accuracy: 0.9704 - val_loss: 0.2651 - val_accuracy: 0.9343\n",
      "Epoch 369/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1161 - accuracy: 0.9676 - val_loss: 0.2660 - val_accuracy: 0.9307\n",
      "Epoch 370/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1147 - accuracy: 0.9694 - val_loss: 0.2643 - val_accuracy: 0.9332\n",
      "Epoch 371/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1117 - accuracy: 0.9714 - val_loss: 0.2580 - val_accuracy: 0.9362\n",
      "Epoch 372/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1113 - accuracy: 0.9694 - val_loss: 0.2627 - val_accuracy: 0.9321\n",
      "Epoch 373/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1119 - accuracy: 0.9700 - val_loss: 0.2623 - val_accuracy: 0.9318\n",
      "Epoch 374/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1131 - accuracy: 0.9690 - val_loss: 0.2651 - val_accuracy: 0.9325\n",
      "Epoch 375/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1137 - accuracy: 0.9690 - val_loss: 0.2666 - val_accuracy: 0.9309\n",
      "Epoch 376/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1113 - accuracy: 0.9704 - val_loss: 0.2643 - val_accuracy: 0.9339\n",
      "Epoch 377/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1123 - accuracy: 0.9702 - val_loss: 0.2611 - val_accuracy: 0.9339\n",
      "Epoch 378/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1098 - accuracy: 0.9713 - val_loss: 0.2686 - val_accuracy: 0.9339\n",
      "Epoch 379/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1113 - accuracy: 0.9693 - val_loss: 0.2625 - val_accuracy: 0.9343\n",
      "Epoch 380/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1174 - accuracy: 0.9679 - val_loss: 0.2646 - val_accuracy: 0.9334\n",
      "Epoch 381/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1144 - accuracy: 0.9689 - val_loss: 0.2597 - val_accuracy: 0.9346\n",
      "Epoch 382/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1114 - accuracy: 0.9700 - val_loss: 0.2626 - val_accuracy: 0.9348\n",
      "Epoch 383/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1137 - accuracy: 0.9691 - val_loss: 0.2615 - val_accuracy: 0.9362\n",
      "Epoch 384/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1107 - accuracy: 0.9707 - val_loss: 0.2631 - val_accuracy: 0.9327\n",
      "Epoch 385/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1131 - accuracy: 0.9692 - val_loss: 0.2687 - val_accuracy: 0.9327\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1143 - accuracy: 0.9691 - val_loss: 0.2631 - val_accuracy: 0.9321\n",
      "Epoch 387/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1115 - accuracy: 0.9701 - val_loss: 0.2579 - val_accuracy: 0.9357\n",
      "Epoch 388/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1130 - accuracy: 0.9692 - val_loss: 0.2685 - val_accuracy: 0.9300\n",
      "Epoch 389/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1112 - accuracy: 0.9698 - val_loss: 0.2682 - val_accuracy: 0.9323\n",
      "Epoch 390/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1125 - accuracy: 0.9692 - val_loss: 0.2627 - val_accuracy: 0.9327\n",
      "Epoch 391/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1124 - accuracy: 0.9700 - val_loss: 0.2705 - val_accuracy: 0.9341\n",
      "Epoch 392/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1138 - accuracy: 0.9687 - val_loss: 0.2594 - val_accuracy: 0.9339\n",
      "Epoch 393/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1086 - accuracy: 0.9706 - val_loss: 0.2670 - val_accuracy: 0.9330\n",
      "Epoch 394/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1101 - accuracy: 0.9698 - val_loss: 0.2608 - val_accuracy: 0.9346\n",
      "Epoch 395/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1115 - accuracy: 0.9708 - val_loss: 0.2632 - val_accuracy: 0.9353\n",
      "Epoch 396/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1122 - accuracy: 0.9701 - val_loss: 0.2648 - val_accuracy: 0.9355\n",
      "Epoch 397/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1129 - accuracy: 0.9696 - val_loss: 0.2672 - val_accuracy: 0.9337\n",
      "Epoch 398/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1107 - accuracy: 0.9705 - val_loss: 0.2600 - val_accuracy: 0.9366\n",
      "Epoch 399/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1113 - accuracy: 0.9696 - val_loss: 0.2627 - val_accuracy: 0.9346\n",
      "Epoch 400/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1053 - accuracy: 0.9731 - val_loss: 0.2661 - val_accuracy: 0.9343\n",
      "Epoch 401/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1087 - accuracy: 0.9708 - val_loss: 0.2572 - val_accuracy: 0.9327\n",
      "Epoch 402/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1112 - accuracy: 0.9701 - val_loss: 0.2643 - val_accuracy: 0.9341\n",
      "Epoch 403/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1132 - accuracy: 0.9698 - val_loss: 0.2618 - val_accuracy: 0.9357\n",
      "Epoch 404/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1087 - accuracy: 0.9709 - val_loss: 0.2678 - val_accuracy: 0.9325\n",
      "Epoch 405/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1124 - accuracy: 0.9696 - val_loss: 0.2558 - val_accuracy: 0.9373\n",
      "Epoch 406/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1102 - accuracy: 0.9710 - val_loss: 0.2681 - val_accuracy: 0.9341\n",
      "Epoch 407/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1121 - accuracy: 0.9699 - val_loss: 0.2658 - val_accuracy: 0.9346\n",
      "Epoch 408/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1103 - accuracy: 0.9704 - val_loss: 0.2742 - val_accuracy: 0.9332\n",
      "Epoch 409/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1113 - accuracy: 0.9700 - val_loss: 0.2564 - val_accuracy: 0.9357\n",
      "Epoch 410/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1134 - accuracy: 0.9691 - val_loss: 0.2559 - val_accuracy: 0.9350\n",
      "Epoch 411/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1124 - accuracy: 0.9707 - val_loss: 0.2554 - val_accuracy: 0.9353\n",
      "Epoch 412/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1163 - accuracy: 0.9690 - val_loss: 0.2557 - val_accuracy: 0.9369\n",
      "Epoch 413/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1112 - accuracy: 0.9707 - val_loss: 0.2566 - val_accuracy: 0.9362\n",
      "Epoch 414/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1130 - accuracy: 0.9697 - val_loss: 0.2607 - val_accuracy: 0.9339\n",
      "Epoch 415/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1128 - accuracy: 0.9687 - val_loss: 0.2567 - val_accuracy: 0.9325\n",
      "Epoch 416/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1115 - accuracy: 0.9700 - val_loss: 0.2611 - val_accuracy: 0.9332\n",
      "Epoch 417/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1088 - accuracy: 0.9722 - val_loss: 0.2685 - val_accuracy: 0.9323\n",
      "Epoch 418/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1099 - accuracy: 0.9702 - val_loss: 0.2663 - val_accuracy: 0.9339\n",
      "Epoch 419/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1108 - accuracy: 0.9702 - val_loss: 0.2639 - val_accuracy: 0.9332\n",
      "Epoch 420/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1108 - accuracy: 0.9705 - val_loss: 0.2738 - val_accuracy: 0.9337\n",
      "Epoch 421/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1082 - accuracy: 0.9708 - val_loss: 0.2648 - val_accuracy: 0.9325\n",
      "Epoch 422/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1144 - accuracy: 0.9692 - val_loss: 0.2633 - val_accuracy: 0.9343\n",
      "Epoch 423/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1093 - accuracy: 0.9712 - val_loss: 0.2681 - val_accuracy: 0.9318\n",
      "Epoch 424/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1136 - accuracy: 0.9690 - val_loss: 0.2621 - val_accuracy: 0.9334\n",
      "Epoch 425/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1113 - accuracy: 0.9710 - val_loss: 0.2588 - val_accuracy: 0.9334\n",
      "Epoch 426/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1094 - accuracy: 0.9709 - val_loss: 0.2541 - val_accuracy: 0.9339\n",
      "Epoch 427/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1112 - accuracy: 0.9705 - val_loss: 0.2686 - val_accuracy: 0.9359\n",
      "Epoch 428/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1083 - accuracy: 0.9712 - val_loss: 0.2641 - val_accuracy: 0.9348\n",
      "Epoch 429/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1080 - accuracy: 0.9720 - val_loss: 0.2637 - val_accuracy: 0.9346\n",
      "Epoch 430/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1100 - accuracy: 0.9704 - val_loss: 0.2681 - val_accuracy: 0.9334\n",
      "Epoch 431/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1103 - accuracy: 0.9700 - val_loss: 0.2721 - val_accuracy: 0.9332\n",
      "Epoch 432/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1099 - accuracy: 0.9701 - val_loss: 0.2679 - val_accuracy: 0.9327\n",
      "Epoch 433/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1067 - accuracy: 0.9720 - val_loss: 0.2627 - val_accuracy: 0.9364\n",
      "Epoch 434/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1109 - accuracy: 0.9696 - val_loss: 0.2586 - val_accuracy: 0.9343\n",
      "Epoch 435/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1090 - accuracy: 0.9716 - val_loss: 0.2656 - val_accuracy: 0.9341\n",
      "Epoch 436/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1110 - accuracy: 0.9708 - val_loss: 0.2650 - val_accuracy: 0.9337\n",
      "Epoch 437/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1089 - accuracy: 0.9703 - val_loss: 0.2656 - val_accuracy: 0.9355\n",
      "Epoch 438/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1079 - accuracy: 0.9715 - val_loss: 0.2555 - val_accuracy: 0.9375\n",
      "Epoch 439/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1076 - accuracy: 0.9715 - val_loss: 0.2598 - val_accuracy: 0.9327\n",
      "Epoch 440/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1117 - accuracy: 0.9704 - val_loss: 0.2696 - val_accuracy: 0.9309\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1073 - accuracy: 0.9715 - val_loss: 0.2642 - val_accuracy: 0.9359\n",
      "Epoch 442/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1141 - accuracy: 0.9696 - val_loss: 0.2616 - val_accuracy: 0.9337\n",
      "Epoch 443/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1117 - accuracy: 0.9705 - val_loss: 0.2615 - val_accuracy: 0.9373\n",
      "Epoch 444/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1080 - accuracy: 0.9712 - val_loss: 0.2683 - val_accuracy: 0.9341\n",
      "Epoch 445/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1102 - accuracy: 0.9702 - val_loss: 0.2668 - val_accuracy: 0.9330\n",
      "Epoch 446/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1088 - accuracy: 0.9711 - val_loss: 0.2552 - val_accuracy: 0.9346\n",
      "Epoch 447/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1056 - accuracy: 0.9729 - val_loss: 0.2628 - val_accuracy: 0.9337\n",
      "Epoch 448/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1101 - accuracy: 0.9710 - val_loss: 0.2606 - val_accuracy: 0.9339\n",
      "Epoch 449/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1090 - accuracy: 0.9721 - val_loss: 0.2558 - val_accuracy: 0.9339\n",
      "Epoch 450/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1115 - accuracy: 0.9697 - val_loss: 0.2625 - val_accuracy: 0.9330\n",
      "Epoch 451/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1076 - accuracy: 0.9721 - val_loss: 0.2697 - val_accuracy: 0.9314\n",
      "Epoch 452/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1079 - accuracy: 0.9712 - val_loss: 0.2584 - val_accuracy: 0.9359\n",
      "Epoch 453/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1127 - accuracy: 0.9699 - val_loss: 0.2641 - val_accuracy: 0.9337\n",
      "Epoch 454/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1062 - accuracy: 0.9710 - val_loss: 0.2655 - val_accuracy: 0.9350\n",
      "Epoch 455/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1087 - accuracy: 0.9712 - val_loss: 0.2681 - val_accuracy: 0.9332\n",
      "Epoch 456/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1094 - accuracy: 0.9697 - val_loss: 0.2623 - val_accuracy: 0.9375\n",
      "Epoch 457/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1086 - accuracy: 0.9709 - val_loss: 0.2637 - val_accuracy: 0.9353\n",
      "Epoch 458/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1071 - accuracy: 0.9719 - val_loss: 0.2726 - val_accuracy: 0.9318\n",
      "Epoch 459/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1084 - accuracy: 0.9716 - val_loss: 0.2630 - val_accuracy: 0.9366\n",
      "Epoch 460/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1116 - accuracy: 0.9703 - val_loss: 0.2691 - val_accuracy: 0.9341\n",
      "Epoch 461/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1108 - accuracy: 0.9701 - val_loss: 0.2674 - val_accuracy: 0.9314\n",
      "Epoch 462/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1145 - accuracy: 0.9691 - val_loss: 0.2626 - val_accuracy: 0.9337\n",
      "Epoch 463/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1057 - accuracy: 0.9727 - val_loss: 0.2577 - val_accuracy: 0.9357\n",
      "Epoch 464/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1098 - accuracy: 0.9717 - val_loss: 0.2646 - val_accuracy: 0.9314\n",
      "Epoch 465/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1087 - accuracy: 0.9714 - val_loss: 0.2676 - val_accuracy: 0.9330\n",
      "Epoch 466/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1080 - accuracy: 0.9718 - val_loss: 0.2670 - val_accuracy: 0.9337\n",
      "Epoch 467/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1130 - accuracy: 0.9708 - val_loss: 0.2731 - val_accuracy: 0.9311\n",
      "Epoch 468/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1098 - accuracy: 0.9703 - val_loss: 0.2696 - val_accuracy: 0.9314\n",
      "Epoch 469/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1088 - accuracy: 0.9721 - val_loss: 0.2720 - val_accuracy: 0.9332\n",
      "Epoch 470/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1137 - accuracy: 0.9700 - val_loss: 0.2639 - val_accuracy: 0.9330\n",
      "Epoch 471/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1123 - accuracy: 0.9696 - val_loss: 0.2652 - val_accuracy: 0.9353\n",
      "Epoch 472/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1094 - accuracy: 0.9716 - val_loss: 0.2625 - val_accuracy: 0.9348\n",
      "Epoch 473/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1081 - accuracy: 0.9723 - val_loss: 0.2685 - val_accuracy: 0.9323\n",
      "Epoch 474/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1071 - accuracy: 0.9714 - val_loss: 0.2633 - val_accuracy: 0.9327\n",
      "Epoch 475/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1072 - accuracy: 0.9713 - val_loss: 0.2658 - val_accuracy: 0.9339\n",
      "Epoch 476/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1120 - accuracy: 0.9694 - val_loss: 0.2646 - val_accuracy: 0.9321\n",
      "Epoch 477/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1100 - accuracy: 0.9700 - val_loss: 0.2632 - val_accuracy: 0.9337\n",
      "Epoch 478/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1080 - accuracy: 0.9725 - val_loss: 0.2686 - val_accuracy: 0.9316\n",
      "Epoch 479/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1104 - accuracy: 0.9706 - val_loss: 0.2624 - val_accuracy: 0.9346\n",
      "Epoch 480/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1092 - accuracy: 0.9713 - val_loss: 0.2667 - val_accuracy: 0.9314\n",
      "Epoch 481/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1070 - accuracy: 0.9716 - val_loss: 0.2694 - val_accuracy: 0.9332\n",
      "Epoch 482/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1107 - accuracy: 0.9698 - val_loss: 0.2599 - val_accuracy: 0.9371\n",
      "Epoch 483/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1089 - accuracy: 0.9707 - val_loss: 0.2768 - val_accuracy: 0.9314\n",
      "Epoch 484/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1074 - accuracy: 0.9725 - val_loss: 0.2689 - val_accuracy: 0.9350\n",
      "Epoch 485/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1079 - accuracy: 0.9707 - val_loss: 0.2646 - val_accuracy: 0.9343\n",
      "Epoch 486/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1093 - accuracy: 0.9710 - val_loss: 0.2677 - val_accuracy: 0.9323\n",
      "Epoch 487/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1087 - accuracy: 0.9708 - val_loss: 0.2646 - val_accuracy: 0.9316\n",
      "Epoch 488/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1090 - accuracy: 0.9713 - val_loss: 0.2587 - val_accuracy: 0.9371\n",
      "Epoch 489/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1099 - accuracy: 0.9702 - val_loss: 0.2661 - val_accuracy: 0.9334\n",
      "Epoch 490/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1091 - accuracy: 0.9706 - val_loss: 0.2636 - val_accuracy: 0.9355\n",
      "Epoch 491/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1083 - accuracy: 0.9710 - val_loss: 0.2616 - val_accuracy: 0.9366\n",
      "Epoch 492/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1093 - accuracy: 0.9706 - val_loss: 0.2646 - val_accuracy: 0.9350\n",
      "Epoch 493/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1044 - accuracy: 0.9724 - val_loss: 0.2706 - val_accuracy: 0.9302\n",
      "Epoch 494/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1089 - accuracy: 0.9714 - val_loss: 0.2627 - val_accuracy: 0.9343\n",
      "Epoch 495/500\n",
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1113 - accuracy: 0.9706 - val_loss: 0.2655 - val_accuracy: 0.9325\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 14s 13ms/step - loss: 0.1033 - accuracy: 0.9717 - val_loss: 0.2624 - val_accuracy: 0.9337\n",
      "Epoch 497/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1075 - accuracy: 0.9711 - val_loss: 0.2652 - val_accuracy: 0.9343\n",
      "Epoch 498/500\n",
      "1093/1093 [==============================] - 15s 14ms/step - loss: 0.1060 - accuracy: 0.9729 - val_loss: 0.2694 - val_accuracy: 0.9359\n",
      "Epoch 499/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1090 - accuracy: 0.9713 - val_loss: 0.2582 - val_accuracy: 0.9366\n",
      "Epoch 500/500\n",
      "1093/1093 [==============================] - 15s 13ms/step - loss: 0.1092 - accuracy: 0.9713 - val_loss: 0.2611 - val_accuracy: 0.9341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f39600fcf10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantization aware training, in which the best model is saved\n",
    "\n",
    "EPOCHS = 500\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "history = quantized_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),  \n",
    "    epochs=EPOCHS,\n",
    "    batch_size = 32,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "quantized_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38d549d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18141/897927363.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
      "/tmp/ipykernel_18141/897927363.py:11: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
      "/tmp/ipykernel_18141/897927363.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
      "/tmp/ipykernel_18141/897927363.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy',color='k')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy',color='k')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss',color='k')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color='k')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d116b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save_model(quantized_model, Quantized_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4037feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 15:16:37.228328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:37.431443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:37.432007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:37.434074: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-23 15:16:37.436447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:37.437001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:37.437468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:38.901995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:38.902597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:38.903072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 15:16:38.904099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9750 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "##### Optional if pretrained ##########\n",
    "\n",
    "quantized_model = cnn2snn.load_quantized_model(Quantized_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63d68f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set of quantized CNN: 99.75983500480652 %\n",
      "Accuracy on validation set of quantized CNN: 93.77716779708862 %\n",
      "Accuracy on test set of quantized CNN: 94.46350932121277 %\n"
     ]
    }
   ],
   "source": [
    "# Print peformance of the quantized CNN after quantization aware training\n",
    "\n",
    "score = quantized_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on train set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Accuracy on validation set of quantized CNN:', score[1] * 100,'%')\n",
    "score = quantized_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy on test set of quantized CNN:', score[1] * 100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a493e2",
   "metadata": {},
   "source": [
    "<font size=\"5\">4. Akida Model Conversion</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4efc22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Summary                 \n",
      "_______________________________________________\n",
      "Input shape   Output shape  Sequences  Layers\n",
      "===============================================\n",
      "[40, 101, 1]  [1, 1, 12]    1          10    \n",
      "_______________________________________________\n",
      "\n",
      "                SW/conv_0-dense (Software)                 \n",
      "___________________________________________________________\n",
      "Layer (type)             Output shape   Kernel shape     \n",
      "===========================================================\n",
      "conv_0 (InputConv.)      [51, 20, 32]   (3, 3, 1, 32)    \n",
      "___________________________________________________________\n",
      "separable_1 (Sep.Conv.)  [51, 20, 32]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 32)   \n",
      "___________________________________________________________\n",
      "separable_2 (Sep.Conv.)  [26, 10, 64]   (3, 3, 32, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 32, 64)   \n",
      "___________________________________________________________\n",
      "separable_3 (Sep.Conv.)  [26, 10, 128]  (3, 3, 64, 1)    \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 64, 128)  \n",
      "___________________________________________________________\n",
      "separable_4 (Sep.Conv.)  [13, 5, 128]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 128) \n",
      "___________________________________________________________\n",
      "separable_5 (Sep.Conv.)  [13, 5, 256]   (3, 3, 128, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 128, 256) \n",
      "___________________________________________________________\n",
      "separable_6 (Sep.Conv.)  [7, 3, 256]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 256) \n",
      "___________________________________________________________\n",
      "separable_7 (Sep.Conv.)  [4, 2, 512]    (3, 3, 256, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 256, 512) \n",
      "___________________________________________________________\n",
      "separable_8 (Sep.Conv.)  [1, 1, 1024]   (3, 3, 512, 1)   \n",
      "___________________________________________________________\n",
      "                                        (1, 1, 512, 1024)\n",
      "___________________________________________________________\n",
      "dense (Fully.)           [1, 1, 12]     (1, 1, 1024, 12) \n",
      "___________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Convert to an Akida model\n",
    "\n",
    "akida_model = convert(quantized_model)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6c944ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN accuracy on training set after conversion: 99.7341033851784 %\n",
      "SNN accuracy on validation set after conversion: 93.4339967970716 %\n",
      "SNN accuracy on test set after conversion: 94.37199725463282 %\n"
     ]
    }
   ],
   "source": [
    "# Print performance of the final Akida model\n",
    "\n",
    "results = akida_model.predict(x_train)\n",
    "accuracy = (y_train == results).mean()\n",
    "\n",
    "print('SNN accuracy on training set after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_val)\n",
    "accuracy = (y_val == results).mean()\n",
    "\n",
    "print('SNN accuracy on validation set after conversion:', accuracy * 100,'%')\n",
    "\n",
    "results = akida_model.predict(x_test)\n",
    "accuracy = (y_test == results).mean()\n",
    "\n",
    "\n",
    "print('SNN accuracy on test set after conversion:', accuracy * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb59492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
