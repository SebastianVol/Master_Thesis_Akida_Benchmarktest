{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e2ede1",
   "metadata": {},
   "source": [
    "<font size=\"5\">Create edge data set</font>\n",
    "\n",
    "Create a balanced data set for edge learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e44ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and dependencies\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "from tensorflow.python.ops import gen_audio_ops as audio_ops\n",
    "\n",
    "\n",
    "import akida\n",
    "import akida_models\n",
    "from akida_models import kws\n",
    "from akida_models.kws import preprocessing\n",
    "import cnn2snn\n",
    "from cnn2snn import check_model_compatibility\n",
    "from cnn2snn import quantize\n",
    "from cnn2snn import quantize_layer\n",
    "from cnn2snn import convert\n",
    "\n",
    "import librosa\n",
    "import scipy\n",
    "from scipy import io\n",
    "from scipy.io import wavfile\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9507066",
   "metadata": {},
   "source": [
    "<font size=\"5\">1. Load the data set</font>\n",
    "\n",
    "The Google Speech Command data set is loaded in this section of the code as a randomly ordered list of directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e46cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories of the data\n",
    "# Folder Just_Edge only includes the keywords, backword follow and forward\n",
    "# Folder Silence only includes the silence category\n",
    "\n",
    "data_dir = pathlib.Path('data/Modded_Google_Edge')\n",
    "silence_dir = pathlib.Path('data/Modded_Google_Edge/silence')\n",
    "edge_dir = pathlib.Path('data/Edge_Categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c21492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known and unknown commands: ['off' 'up' 'down' 'on' 'stop' 'yes' 'right' 'unknown' 'left' 'go' 'no'\n",
      " 'silence' 'forward' 'follow' 'backward']\n",
      "Newly added commands for edge learning: ['forward' 'follow' 'backward']\n"
     ]
    }
   ],
   "source": [
    "# Check if the keywords are the desired ones\n",
    "\n",
    "targets = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "\n",
    "targets = targets[targets != 'README.md']\n",
    "\n",
    "targets = targets[targets != 'follow']\n",
    "targets = targets[targets != 'forward']\n",
    "targets = targets[targets != 'backward']\n",
    "\n",
    "targets_edge = np.array(tf.io.gfile.listdir(str(edge_dir)))\n",
    "\n",
    "targets = np.append(targets, targets_edge)\n",
    "\n",
    "print('Known and unknown commands:', targets)\n",
    "print('Newly added commands for edge learning:', targets_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce610cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Modded_Google_Edge/off\n",
      "data/Modded_Google_Edge/up\n",
      "data/Modded_Google_Edge/down\n",
      "data/Modded_Google_Edge/on\n",
      "data/Modded_Google_Edge/stop\n",
      "data/Modded_Google_Edge/yes\n",
      "data/Modded_Google_Edge/right\n",
      "data/Modded_Google_Edge/unknown\n",
      "data/Modded_Google_Edge/left\n",
      "data/Modded_Google_Edge/go\n",
      "data/Modded_Google_Edge/no\n",
      "data/Modded_Google_Edge/silence\n",
      "data/Modded_Google_Edge/forward\n",
      "data/Modded_Google_Edge/follow\n",
      "data/Modded_Google_Edge/backward\n"
     ]
    }
   ],
   "source": [
    "# Create list of file names, along with its target \n",
    "\n",
    "filenames = []\n",
    "y = []\n",
    "for i, target in enumerate(targets):\n",
    "    print(join(data_dir, target))\n",
    "    filenames.append(listdir(join(data_dir, target)))\n",
    "    y.append(np.ones(len(filenames[i])) * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbc3210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 402)\n"
     ]
    }
   ],
   "source": [
    "# Create list with all the silence file names\n",
    "# The targets in this case are note neccessary because these files are used later as added noise\n",
    "\n",
    "silence_filenames = []\n",
    "silence_filenames.append(listdir(silence_dir))\n",
    "print(np.shape(silence_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b49297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filenames:  101462\n",
      "y:  101462\n"
     ]
    }
   ],
   "source": [
    "# Flatten the array to make it a list instead of a list of arrays\n",
    "\n",
    "filenames = [item for sublist in filenames for item in sublist]\n",
    "y = [item for sublist in y for item in sublist]\n",
    "\n",
    "# Check if targets and file names have the same size\n",
    "\n",
    "print('Filenames: ', len(filenames))\n",
    "print('y: ', len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef755f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 15:26:11.512568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.576585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.576763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.577380: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-17 15:26:11.577912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.578052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.578176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.909849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.910031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.910150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 15:26:11.910252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9439 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filenames:  91359\n",
      "y:  91359\n"
     ]
    }
   ],
   "source": [
    "# Check if the file names are one second in length.\n",
    "\n",
    "filenames_temp = []\n",
    "y_temp=[]\n",
    "\n",
    "\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "\n",
    "    path = join(data_dir, targets[int(y[index])], filename)\n",
    "    wav_loader = tf.io.read_file(path)\n",
    "    wav_decoder = tf.audio.decode_wav(wav_loader,desired_channels=1, desired_samples=-1)\n",
    "    \n",
    "    if wav_decoder[0].shape == (16000,1):\n",
    "        filenames_temp.append(filename)\n",
    "        y_temp.append(y[index])\n",
    "\n",
    "filenames = filenames_temp\n",
    "y = y_temp\n",
    "\n",
    "print('Filenames: ', len(filenames))\n",
    "print('y: ', len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07764487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 3427,\n",
       " 1.0: 3269,\n",
       " 2.0: 3580,\n",
       " 3.0: 3471,\n",
       " 4.0: 3563,\n",
       " 5.0: 3692,\n",
       " 6.0: 3448,\n",
       " 7.0: 55955,\n",
       " 8.0: 3502,\n",
       " 9.0: 3478,\n",
       " 10.0: 3545,\n",
       " 11.0: 398,\n",
       " 12.0: 10,\n",
       " 13.0: 11,\n",
       " 14.0: 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of all labels\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674434d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "# 10% should be unknown and silence\n",
    "# 80 is here hardcoded because it can be easily seen in the distribution of the final data set\n",
    "# Every keyword should have 50 utterances and the 40 from the new keywords\n",
    "\n",
    "amount_sil_un = 80\n",
    "print(int(amount_sil_un))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac07514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    }
   ],
   "source": [
    "# Make file names of silence to one long list \n",
    "\n",
    "silence_filenames = np.squeeze(silence_filenames)\n",
    "\n",
    "# Print the length in order to check if something has changed\n",
    "\n",
    "print(len(silence_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d33ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silence Filenames:  398\n"
     ]
    }
   ],
   "source": [
    "# Include only the silence files which have a total of one second in length\n",
    "\n",
    "silence_temp = []\n",
    "\n",
    "\n",
    "for index, filename in enumerate(silence_filenames):\n",
    "\n",
    "    path = join(silence_dir, filename)\n",
    "    wav_loader = tf.io.read_file(path)\n",
    "    wav_decoder = tf.audio.decode_wav(wav_loader,desired_channels=1, desired_samples=-1)\n",
    "    \n",
    "    if wav_decoder[0].shape == (16000,1):\n",
    "        silence_temp.append(filename)\n",
    "\n",
    "silence_filenames = silence_temp\n",
    "\n",
    "print('Silence Filenames: ', len(silence_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6152636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31dude_miaowing.wav\n",
      "4doing_the_dishes.wav\n"
     ]
    }
   ],
   "source": [
    "# Shuffle file names of the silence category\n",
    "# Print the first position of the list to check if it worked\n",
    "\n",
    "print(silence_filenames[0])\n",
    "random.shuffle(silence_filenames)\n",
    "print(silence_filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af181116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35484\n"
     ]
    }
   ],
   "source": [
    "# Only take 80 randomly selected files of unknown\n",
    "\n",
    "filenames_target = list(zip(filenames, y))\n",
    "random.shuffle(filenames_target)\n",
    "#print(filenames_target)\n",
    "counter = 0\n",
    "index = 0\n",
    "unknown_id = 7\n",
    "result = []\n",
    "for i in filenames_target:\n",
    "    if filenames_target[index][1] != unknown_id:\n",
    "        result.append(i)\n",
    "    if filenames_target[index][1] == unknown_id:\n",
    "        counter += 1\n",
    "        if counter <= amount_sil_un:\n",
    "            result.append(i)\n",
    "    index += 1\n",
    "filenames_target = result\n",
    "    \n",
    "print(len(filenames_target))\n",
    "#print(filenames_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3cfb8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 3427,\n",
       " 1.0: 3269,\n",
       " 2.0: 3580,\n",
       " 3.0: 3471,\n",
       " 4.0: 3563,\n",
       " 5.0: 3692,\n",
       " 6.0: 3448,\n",
       " 7.0: 80,\n",
       " 8.0: 3502,\n",
       " 9.0: 3478,\n",
       " 10.0: 3545,\n",
       " 11.0: 398,\n",
       " 12.0: 10,\n",
       " 13.0: 11,\n",
       " 14.0: 10}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the distribution fits\n",
    "\n",
    "filenames, y = zip(*filenames_target)\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24dd0bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35166\n"
     ]
    }
   ],
   "source": [
    "# Do the same for the silence category\n",
    "\n",
    "counter = 0\n",
    "index = 0\n",
    "silence_id = 11\n",
    "result = []\n",
    "for i in filenames_target:\n",
    "    if filenames_target[index][1] != silence_id:\n",
    "        result.append(i)\n",
    "    if filenames_target[index][1] == silence_id:\n",
    "        counter += 1\n",
    "        if counter <= amount_sil_un:\n",
    "            result.append(i)\n",
    "    index += 1\n",
    "filenames_target = result\n",
    "    \n",
    "print(len(filenames_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f85cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 3427,\n",
       " 1.0: 3269,\n",
       " 2.0: 3580,\n",
       " 3.0: 3471,\n",
       " 4.0: 3563,\n",
       " 5.0: 3692,\n",
       " 6.0: 3448,\n",
       " 7.0: 80,\n",
       " 8.0: 3502,\n",
       " 9.0: 3478,\n",
       " 10.0: 3545,\n",
       " 11.0: 80,\n",
       " 12.0: 10,\n",
       " 13.0: 11,\n",
       " 14.0: 10}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it worked\n",
    "\n",
    "filenames, y = zip(*filenames_target)\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1efde2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 50 random samples from every keyword besides backward, follow and forward\n",
    "\n",
    "forward_id = 12\n",
    "backward_id = 14\n",
    "follow_id = 13\n",
    "\n",
    "filenames_target_temp=[]\n",
    "\n",
    "target_amount = 50\n",
    "\n",
    "for index, target in enumerate(targets):\n",
    "    counter = 0\n",
    "    i = 0\n",
    "    for j in filenames_target:\n",
    "        if (filenames_target[i][1] == backward_id\n",
    "        or filenames_target[i][1] == forward_id\n",
    "        or filenames_target[i][1] == follow_id\n",
    "        or filenames_target[i][1] == silence_id\n",
    "        or filenames_target[i][1] == unknown_id):\n",
    "            if index == 0:\n",
    "                filenames_target_temp.append(j)\n",
    "        elif (filenames_target[i][1] == index):\n",
    "            if counter < target_amount:\n",
    "                filenames_target_temp.append(j)\n",
    "                counter += 1\n",
    "        i += 1\n",
    "    \n",
    "                \n",
    "filenames_target = filenames_target_temp\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61e5ab69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 50,\n",
       " 1.0: 50,\n",
       " 2.0: 50,\n",
       " 3.0: 50,\n",
       " 4.0: 50,\n",
       " 5.0: 50,\n",
       " 6.0: 50,\n",
       " 7.0: 80,\n",
       " 8.0: 50,\n",
       " 9.0: 50,\n",
       " 10.0: 50,\n",
       " 11.0: 80,\n",
       " 12.0: 10,\n",
       " 13.0: 11,\n",
       " 14.0: 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution\n",
    "\n",
    "filenames, y = zip(*filenames_target)\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c183c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594.0\n"
     ]
    }
   ],
   "source": [
    "# Data is split in 10% validation and 90% training\n",
    "# Compute what 10% of the data is\n",
    "\n",
    "num_samples = (len(filenames_target)) - 31\n",
    "train_amount = num_samples * 0.9\n",
    "val_amount = num_samples - train_amount\n",
    "print(train_amount)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e3783b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set\n",
    "\n",
    "filenames_target_train = []\n",
    "filenames_target_val = []\n",
    "\n",
    "activ_train_amount_per_word = 4\n",
    "train_non_edge_amount = 45\n",
    "silence_unknown_amount = 72 \n",
    "\n",
    "counter_train = 0\n",
    "counter_train_edge_back = 0\n",
    "counter_train_edge_foll = 0\n",
    "counter_train_edge_for = 0\n",
    "\n",
    "counter_off = 0\n",
    "counter_up = 0\n",
    "counter_down = 0\n",
    "counter_on = 0\n",
    "counter_stop = 0\n",
    "counter_yes = 0\n",
    "counter_right = 0\n",
    "counter_left = 0\n",
    "counter_go = 0\n",
    "counter_no = 0\n",
    "\n",
    "counter_unknown = 0\n",
    "counter_silence = 0\n",
    "\n",
    "index = 0\n",
    "forward_id = 12\n",
    "backward_id = 14\n",
    "follow_id = 13\n",
    "\n",
    "off_id = 0\n",
    "up_id = 1\n",
    "down_id = 2\n",
    "on_id = 3\n",
    "stop_id = 4\n",
    "yes_id = 5\n",
    "right_id = 6\n",
    "left_id = 8\n",
    "go_id = 9\n",
    "no_id = 10\n",
    "\n",
    "\n",
    "for i in filenames_target:\n",
    "    \n",
    "    if filenames_target[index][1] == off_id:\n",
    "        if counter_off < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_off += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "    \n",
    "    elif filenames_target[index][1] == up_id:\n",
    "        if counter_up < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_up += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == down_id:\n",
    "        if counter_down < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_down += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "\n",
    "    elif filenames_target[index][1] == on_id:\n",
    "        if counter_on < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_on += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == stop_id:\n",
    "        if counter_stop < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_stop += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "\n",
    "    elif filenames_target[index][1] == yes_id:\n",
    "        if counter_yes < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_yes += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == right_id:\n",
    "        if counter_right < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_right += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == left_id:\n",
    "        if counter_left < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_left += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == go_id:\n",
    "        if counter_go < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_go += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == no_id:\n",
    "        if counter_no < train_non_edge_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_no += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == unknown_id:\n",
    "        if counter_unknown < silence_unknown_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_unknown += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == silence_id:\n",
    "        if counter_silence < silence_unknown_amount:\n",
    "            filenames_target_train.append(i)\n",
    "            counter_silence += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == backward_id:\n",
    "        if counter_train_edge_back < activ_train_amount_per_word:\n",
    "            #filenames_target_train.append(i)\n",
    "            filenames_target_train.extend([i] * 10)\n",
    "            counter_train_edge_back += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    \n",
    "    elif filenames_target[index][1] == forward_id:\n",
    "        if counter_train_edge_for < activ_train_amount_per_word:\n",
    "            filenames_target_train.extend([i] * 10)\n",
    "            counter_train_edge_for += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "            \n",
    "    elif filenames_target[index][1] == follow_id:\n",
    "        if counter_train_edge_foll < activ_train_amount_per_word:\n",
    "            filenames_target_train.extend([i] * 10)\n",
    "            counter_train_edge_foll += 1\n",
    "        else:\n",
    "            filenames_target_val.append(i)\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7a68cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 45,\n",
       " 1.0: 45,\n",
       " 2.0: 45,\n",
       " 3.0: 45,\n",
       " 4.0: 45,\n",
       " 5.0: 45,\n",
       " 6.0: 45,\n",
       " 7.0: 72,\n",
       " 8.0: 45,\n",
       " 9.0: 45,\n",
       " 10.0: 45,\n",
       " 11.0: 72,\n",
       " 12.0: 40,\n",
       " 13.0: 40,\n",
       " 14.0: 40}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training data distribution\n",
    "\n",
    "filenames, y = zip(*filenames_target_train)\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc40507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 5,\n",
       " 1.0: 5,\n",
       " 2.0: 5,\n",
       " 3.0: 5,\n",
       " 4.0: 5,\n",
       " 5.0: 5,\n",
       " 6.0: 5,\n",
       " 7.0: 8,\n",
       " 8.0: 5,\n",
       " 9.0: 5,\n",
       " 10.0: 5,\n",
       " 11.0: 8,\n",
       " 12.0: 6,\n",
       " 13.0: 7,\n",
       " 14.0: 6}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check validation data distribution\n",
    "\n",
    "filenames, y = zip(*filenames_target_val)\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15bfad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle both sets\n",
    "\n",
    "random.shuffle(filenames_target_train)\n",
    "random.shuffle(filenames_target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51870837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 714\n",
      "Validation set size 85\n"
     ]
    }
   ],
   "source": [
    "# Split and print all sets\n",
    "\n",
    "filenames_train, y_train = zip(*filenames_target_train)\n",
    "train_files = filenames_train\n",
    "filenames_val, y_val = zip(*filenames_target_val)\n",
    "val_files = filenames_val\n",
    "\n",
    "print('Training set size', len(train_files))\n",
    "print('Validation set size', len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c48d6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 714\n",
      "Validation set size 85\n"
     ]
    }
   ],
   "source": [
    "# Does the label size match?\n",
    "\n",
    "y_train = y_train\n",
    "y_val = y_val\n",
    "\n",
    "\n",
    "print('Training set size', len(y_train))\n",
    "print('Validation set size', len(y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4fc205",
   "metadata": {},
   "source": [
    "<font size=\"5\">2. Define MFCC functions </font>\n",
    "\n",
    "In this chapter the functions for calculating the MFCCs are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a44ff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'desired_samples': 16000, 'window_size_samples': 480, 'window_stride_samples': 160, 'spectrogram_length': 98, 'fingerprint_width': 40, 'fingerprint_size': 3920}\n"
     ]
    }
   ],
   "source": [
    "# Helper function of the Akida library that helps defining the right MFCC settings \n",
    "    \n",
    "model_settings = akida_models.kws.preprocessing.prepare_model_settings(sample_rate = 16000, clip_duration_ms = 1000, window_size_ms = 30, window_stride_ms = 10, feature_bin_count = 40)\n",
    "print(model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6f6ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Create MFCC from given path\n",
    "\n",
    "def calc_mfcc(path,num_ceps):\n",
    "    \n",
    "    # Load wave file\n",
    "    \n",
    "    wav_loader = tf.io.read_file(path)\n",
    "    #wav_decoder = tf.audio.decode_wav(wav_loader,desired_channels=1, desired_samples=model_settings['desired_samples'])\n",
    "    wav_decoder = tf.audio.decode_wav(wav_loader,desired_channels=1, desired_samples=-1)\n",
    "    if wav_decoder[0].shape != (16000,1):\n",
    "        return wav_decoder.audio\n",
    "        \n",
    "    # Randomly shift position to either 100ms forward or backward \n",
    "   \n",
    "    position = random.randint(0,1)\n",
    "    if position == 0:\n",
    "        paddings = [[0, int(model_settings['desired_samples']*0.1)], [0, 0]]\n",
    "        begin = [int(model_settings['desired_samples']*0.1),0]\n",
    "    if position == 1:\n",
    "        paddings = [[int(model_settings['desired_samples']*0.1), 0], [0, 0]]\n",
    "        begin = [0,0]\n",
    "    scaled_wav_decoder = tf.multiply(wav_decoder.audio, 1)\n",
    "    padded_wav_decoder = tf.pad(scaled_wav_decoder, paddings)\n",
    "    sliced_wav_decoder = tf.slice(padded_wav_decoder, begin = begin, size = [model_settings['desired_samples'], -1])\n",
    "\n",
    "    # Take random silence file and add it to the signal in range between 0 and 0.1\n",
    "\n",
    "    rand_silence = random.randint(0,len(silence_filenames) - 1)\n",
    "    rand_amount = random.uniform(0, 0.1)\n",
    "    silence_loader = tf.io.read_file(join(silence_dir,silence_filenames[rand_silence]))\n",
    "    silence_decoder = tf.audio.decode_wav(silence_loader,desired_channels=1, desired_samples=model_settings['desired_samples'])\n",
    "    silence_padded_wav = tf.add(sliced_wav_decoder, tf.multiply(silence_decoder.audio, rand_amount))\n",
    "    silence_padded_wav = tf.squeeze(silence_padded_wav)\n",
    "    silence_padded_wav = silence_padded_wav.numpy()\n",
    "\n",
    "    # Create MFCC of the augmented signal \n",
    "\n",
    "    output = librosa.feature.mfcc(y=silence_padded_wav,sr=model_settings['desired_samples'],n_mfcc=model_settings['fingerprint_width'],n_fft=512,win_length=model_settings['window_size_samples'],hop_length=model_settings['window_stride_samples'])\n",
    "\n",
    "\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08d3e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates the MFCC and check if they have the desired length \n",
    "\n",
    "def extract_features(samples, labels, num_ceps):\n",
    "    prob_cnt = 0\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "        \n",
    "    for index, filename in enumerate(samples):\n",
    "\n",
    "        # Create path from given filename and target item\n",
    "        path = join(data_dir, targets[int(labels[index])], \n",
    "                    filename)\n",
    "\n",
    "        # Create MFCCs\n",
    "        mfccs = calc_mfcc(path,num_ceps)\n",
    "\n",
    "        if mfccs.shape[1] == num_ceps:\n",
    "            out_x.append(mfccs)\n",
    "            out_y.append(labels[index])\n",
    "        else:\n",
    "            print('Dropped:', index, mfccs.shape)\n",
    "            prob_cnt += 1\n",
    "\n",
    "    return out_x, out_y, prob_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158c6af",
   "metadata": {},
   "source": [
    "<font size=\"5\">3. Save the MFCCs </font>\n",
    "\n",
    "Save the MFCCs including their targets seperated into training and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d88e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed percentage: 0.0\n",
      "Removed percentage: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Create train and validation set\n",
    "# num_ceps is the desired length of the MFCC\n",
    "\n",
    "x_train, y_train, prob = extract_features(train_files, y_train, num_ceps)\n",
    "print('Removed percentage:', prob / len(y_train))\n",
    "x_val, y_val, prob = extract_features(val_files, y_val, num_ceps)\n",
    "print('Removed percentage:', prob / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05f6519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MFCCs and their target\n",
    "\n",
    "feature_sets_file = 'stored_files_targets_edge.npz'\n",
    "np.savez(feature_sets_file, \n",
    "         x_train=x_train, \n",
    "         y_train=y_train, \n",
    "         x_val=x_val, \n",
    "         y_val= y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f399f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_train', 'y_train', 'x_val', 'y_val']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if everything worked correctly \n",
    "\n",
    "feature_sets = np.load(feature_sets_file)\n",
    "feature_sets.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9119e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
