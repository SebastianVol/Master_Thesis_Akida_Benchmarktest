{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a256ed",
   "metadata": {},
   "source": [
    "<font size=\"5\">Power Measurement of the Akida Model</font>\n",
    "\n",
    "This notebook was run on the development kit from BrainChip, in order to evaluate the inference an power consumption of the abnormal EEG-signal detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d4138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import pathlib\n",
    "\n",
    "import akida\n",
    "from akida import FullyConnected\n",
    "from akida import evaluate_sparsity\n",
    "import cnn2snn\n",
    "from cnn2snn import check_model_compatibility\n",
    "from cnn2snn import quantize\n",
    "from cnn2snn import quantize_layer\n",
    "from cnn2snn import convert\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8f538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quantized model\n",
    "\n",
    "quantized_model = cnn2snn.load_quantized_model('quantized4_model_raw_eeg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08495717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model Summary                  \n",
      "_________________________________________________\n",
      "Input shape     Output shape  Sequences  Layers\n",
      "=================================================\n",
      "[22, 15000, 1]  [1, 1, 2]     1          3     \n",
      "_________________________________________________\n",
      "\n",
      "              SW/conv2d_4-dense_2 (Software)               \n",
      "___________________________________________________________\n",
      "Layer (type)           Output shape     Kernel shape     \n",
      "===========================================================\n",
      "conv2d_4 (InputConv.)  [14976, 22, 40]  (25, 1, 1, 40)   \n",
      "___________________________________________________________\n",
      "conv2d_5 (Conv.)       [994, 12, 40]    (1, 11, 40, 40)  \n",
      "___________________________________________________________\n",
      "dense_2 (Fully.)       [1, 1, 2]        (1, 1, 477120, 2)\n",
      "___________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Convert to an Akida model\n",
    "\n",
    "akida_model = convert(quantized_model)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60e8b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Sets:  ['x', 'y']\n"
     ]
    }
   ],
   "source": [
    "# Define directory\n",
    "\n",
    "feature_sets_filename = 'final1_eeg_data.npz'\n",
    "\n",
    "feature_sets = np.load(feature_sets_filename)\n",
    "\n",
    "print('Feature Sets: ', feature_sets.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962b9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets\n",
    "\n",
    "x_test = feature_sets['x']\n",
    "y_test = feature_sets['y']\n",
    "x_test = x_test[:10]\n",
    "y_test = y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4575cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 22, 15000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add dimension\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b86253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akida NP available : <akida.core.HardwareDevice object at 0xffff2850b3b0>\n"
     ]
    }
   ],
   "source": [
    "# Show devices\n",
    "\n",
    "devices = akida.devices()\n",
    "print('Akida NP available :', devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ace3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC.00.000.002\n"
     ]
    }
   ],
   "source": [
    "print(devices[0].version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a07144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model Summary                  \n",
      "_________________________________________________\n",
      "Input shape     Output shape  Sequences  Layers\n",
      "=================================================\n",
      "[22, 15000, 1]  [1, 1, 2]     1          3     \n",
      "_________________________________________________\n",
      "\n",
      "              SW/conv2d_4-dense_2 (Software)               \n",
      "___________________________________________________________\n",
      "Layer (type)           Output shape     Kernel shape     \n",
      "===========================================================\n",
      "conv2d_4 (InputConv.)  [14976, 22, 40]  (25, 1, 1, 40)   \n",
      "___________________________________________________________\n",
      "conv2d_5 (Conv.)       [994, 12, 40]    (1, 11, 40, 40)  \n",
      "___________________________________________________________\n",
      "dense_2 (Fully.)       [1, 1, 2]        (1, 1, 477120, 2)\n",
      "___________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Map Akida model to hardware\n",
    "\n",
    "device = devices[0]\n",
    "\n",
    "akida_model.map(device)\n",
    "\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10927b97",
   "metadata": {},
   "source": [
    "<font size=\"5\">Default</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be164ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device.soc.power_measurement_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63fd6e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor power: 908.94 mW\n",
      "\n",
      "Sequence SW/conv2d_4-dense_2\n",
      "Average framerate = 0.71 fps\n",
      "Last inference power range (mW):  Avg 908.46 / Min 908.00 / Max 910.00 / Std 0.85 \n",
      "Last inference energy consumed (mJ/frame): 1281.66\n",
      "Akida inference 10 MFCC took 14.11 s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "akida_model.forward(x_test)\n",
    "end = timer()\n",
    "# Display floor current\n",
    "floor_power = device.soc.power_meter.floor\n",
    "print(f'Floor power: {floor_power:.2f} mW')\n",
    "print(akida_model.statistics)\n",
    "print(f'Akida inference {len(x_test)} MFCC took {end-start:.2f} s.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507eb01c",
   "metadata": {},
   "source": [
    "<font size=\"5\">Clock Mode: Performance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4af88bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClockMode.Performance\n"
     ]
    }
   ],
   "source": [
    "device.soc.clock_mode = akida.soc.ClockMode.Performance\n",
    "print(device.soc.clock_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fc74405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor power: 908.94 mW\n",
      "\n",
      "Sequence SW/conv2d_4-dense_2\n",
      "Average framerate = 0.73 fps\n",
      "Last inference power range (mW):  Avg 908.73 / Min 908.00 / Max 911.00 / Std 1.14 \n",
      "Last inference energy consumed (mJ/frame): 1244.14\n",
      "Akida inference 10 MFCC took 13.69 s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "akida_model.forward(x_test)\n",
    "end = timer()\n",
    "# Display floor current\n",
    "floor_power = device.soc.power_meter.floor\n",
    "print(f'Floor power: {floor_power:.2f} mW')\n",
    "print(akida_model.statistics)\n",
    "print(f'Akida inference {len(x_test)} MFCC took {end-start:.2f} s.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83122d6",
   "metadata": {},
   "source": [
    "<font size=\"5\">Clock Mode: Economy</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212c3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClockMode.Economy\n"
     ]
    }
   ],
   "source": [
    "device.soc.clock_mode = akida.soc.ClockMode.Economy\n",
    "print(device.soc.clock_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886958fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor power: 742.85 mW\n",
      "\n",
      "Sequence SW/conv2d_4-dense_2\n",
      "Average framerate = 0.72 fps\n",
      "Last inference power range (mW):  Avg 743.45 / Min 742.00 / Max 744.00 / Std 0.90 \n",
      "Last inference energy consumed (mJ/frame): 1035.63\n",
      "Akida inference 10 MFCC took 13.93 s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "akida_model.forward(x_test)\n",
    "end = timer()\n",
    "# Display floor current\n",
    "floor_power = device.soc.power_meter.floor\n",
    "print(f'Floor power: {floor_power:.2f} mW')\n",
    "print(akida_model.statistics)\n",
    "print(f'Akida inference {len(x_test)} MFCC took {end-start:.2f} s.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19911ad5",
   "metadata": {},
   "source": [
    "<font size=\"5\">Clock Mode: LowPower</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d34ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClockMode.LowPower\n"
     ]
    }
   ],
   "source": [
    "device.soc.clock_mode = akida.soc.ClockMode.LowPower\n",
    "print(device.soc.clock_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4ad5b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor power: 662.30 mW\n",
      "\n",
      "Sequence SW/conv2d_4-dense_2\n",
      "Average framerate = 0.67 fps\n",
      "Last inference power range (mW):  Avg 662.24 / Min 662.00 / Max 664.00 / Std 0.66 \n",
      "Last inference energy consumed (mJ/frame): 991.58\n",
      "Akida inference 10 MFCC took 14.98 s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "akida_model.forward(x_test)\n",
    "end = timer()\n",
    "# Display floor current\n",
    "floor_power = device.soc.power_meter.floor\n",
    "print(f'Floor power: {floor_power:.2f} mW')\n",
    "print(akida_model.statistics)\n",
    "print(f'Akida inference {len(x_test)} MFCC took {end-start:.2f} s.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e916d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
